{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7O5WpW_8Zkws"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Data Science Class Project</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 20px;\">Project Title: Fully Connected Neural Network for Binding Affinity Prediction from Molecular Fingerprints. </span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 20px;\">Name: Daniel Eduardo Garzon Otero</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W0pVFPouZkwt"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 16px;\">The need for accurate prediction of binding affinity, which is important in drug discovery and design. By using molecular fingerprints and a fully connected neural network, I hope to improve the accuracy of binding affinity prediction compared to existing methods. Results of this project could contribute to the development of more effective drugs and therapies.</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\"> I will use the PDB_Bind database: http://www.pdbbind.org.cn/ , which contains information about protein-ligand interactions obtained from the Protein Data Bank (PDB). Specifically, PDBBind. This Data set was provided from Dr. Camille Bilodeau.</span>\n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Our goals are defined as: </span> \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">-DataSet processing: Using a class of python and the libraries Panda to set up the data set.</span>   \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">-Deep learning: With the preprocessed and engineered data, I will train a Neural Network model to predict the binding affinity between proteins and ligands. I will use the library pytorch.</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">-Hyperparameters Selection: Depending on the performance of the model, I will need to change the hyperparameters or modify the model architecture to improve their accuracy. </span>   \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">-Model evaluation: Once the models have been trained, I will evaluate their performance using metrics such as R squared, MAE, RMSE, and Pearson R. I will use Sklearn and Scipy</span>   \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">-Visualization: Data visualization to help interpret the results of your analysis I will be made using the library Matplotlib</span> \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "x0XlIRLPZkwu"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 36px;\">â€¢Methods</span>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "vH4Ah38rZkwu"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Libraries</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7x1x5rCjZkwu"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T8JP-ahnZkwu"
      },
      "source": [
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">This code block checks if a CUDA-enabled GPU is available on the system. If a GPU is available, the code sets the device to use the GPU for computations, and if not, it sets the device to use the CPU.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "6DY17IIhZkwv",
        "outputId": "d0ad3daf-b0b6-42bb-ddff-f51b9f03c7b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ///////// Running on the GPU /////////\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"\\n ///////// Running on the GPU /////////\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"\\n //////// Running on the cpu /////////\")\n",
        "\n",
        "start_time = time.time()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbx2rmeGZkwv"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Dataset</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">We used a class to create our dataset. We defined a new class PDB that inherits from the Dataset class and takes a path to a CSV file as an argument. In the init method, we read the CSV file using pandas and extract the input vectors and targets. The input vectors are all columns except the last one, and the targets are the last column. We also set the input size to the length of the first input vector. In the len method, we return the number of targets in the dataset. In the getitem method, the input vector and the target at a given index as PyTorch tensors. </span>  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MGsIcCZ7Zkwv"
      },
      "outputs": [],
      "source": [
        "class PDB(Dataset):\n",
        "    def __init__(self,path):\n",
        "\n",
        "        self.df = pd.read_csv(path)\n",
        "\n",
        "        self.input_vectors= self.df[self.df.columns[0:-1]].values\n",
        "        self.input_size = len(self.input_vectors[0]) \n",
        "        self.targets = self.df[self.df.columns[-1]].values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, index): \n",
        "        input_vector = self.input_vectors[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return torch.tensor(input_vector, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)\n",
        "    \n",
        "\n",
        "data_set = PDB('/home/vvd9fd/Documents/Bilodeau Group/Codes/2.PDB_Bind/pdbind_full_fp2.csv') \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_kaYNQRGZkwv"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Data Histogram</span>  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "qvtMc2VSZkwv",
        "outputId": "ffeda22b-1b28-448c-e3f1-1c86c1b2f547"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(4, 4), dpi=100)\n",
        "plt.hist(data_set.df[\"-logKd/Ki\"])\n",
        "plt.title('Distribution of -log($K_d/K_i$) values in the dataset')\n",
        "plt.xlabel(\"-log($K_d/K_i$)\")\n",
        "plt.ylabel(\"N\")\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5EBnae6rZkww"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Neural Network Model</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">We define a fully connected neural network (FCNN) using PyTorch. The FCNN has three fully connected layers with ReLU activation functions and two dropout layers, p1 and p2 are dropout probabilities for the first and second dropout layers, respectively.  Dropout was selected as regularization technique  to prevent overfitting. \n",
        "</span>    \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The input size, two hidden layer sizes, output size,  parameter are specified as input parameters to the class.\n",
        "The forward function defines the feedforward pass of the network by applying the linear transformations and activations of each layer. The network takes input 'x' and returns the output on the final layer.</span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fIPcLn5xZkww"
      },
      "outputs": [],
      "source": [
        "class FCNN(nn.Module): \n",
        "    \n",
        "    def __init__(self,input_size, hidden_size1, hidden_size2, output_size, p1=0.7, p2=0.5): \n",
        "        super(FCNN, self).__init__()\n",
        "\n",
        "        self.fl1 = nn.Linear(input_size, hidden_size1)\n",
        "        self.dropout = nn.Dropout(p=p1)\n",
        "        self.fl2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.dropout = nn.Dropout(p=p2)         \n",
        "        self.fl3 = nn.Linear(hidden_size2, output_size) \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.fl1(x)\n",
        "        out = F.relu(out) \n",
        "        out = self.dropout(out)\n",
        "        out = self.fl2(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.fl3(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AGTkJvjoZkww"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Train routine</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The train function defines the training loop of the fully connected neural network model. It takes as input the model to train, the device to use (CPU or GPU), the training data loader, and the optimizer. It sets the model in training mode and defines the loss function to use (in this case, L1 loss). The function then iterates through each batch of the training data loader, makes predictions on the input vectors using the model, calculates the loss between the predictions and the target values, and updates the model weights using backpropagation. It also collects the total training loss across all batches, and returns the average training loss at the end of the loop.</span>    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "EUIgpQb0Zkww"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_dataloader, optim): \n",
        "    model.train()\n",
        "\n",
        "    loss_func = torch.nn.L1Loss(reduction='sum') \n",
        "    loss_collect = 0\n",
        "\n",
        "    \n",
        "    for b_i, (input_vectors, targets) in enumerate(train_dataloader):\n",
        "\n",
        "        input_vectors, targets = input_vectors.to(device), targets.to(device)\n",
        "\n",
        "        optim.zero_grad() \n",
        "        pred_prob = model(input_vectors.float())\n",
        "\n",
        "        loss = loss_func(pred_prob, targets.view(-1,1))\n",
        "        loss.backward() \n",
        "\n",
        "        optim.step() \n",
        "        loss_collect += loss.item() \n",
        "    \n",
        "\n",
        "        if b_i % 10 == 0:\n",
        "            print('epoch: {} [{}/{} ({:.0f}%)]\\t training loss: {:.1f}'.format(\n",
        "                epoch, b_i * len(input_vectors), len(train_dataloader.dataset),\n",
        "                100 * b_i * len(input_vectors) / len(train_dataloader.dataset),\n",
        "                loss.item()))\n",
        "    loss_collect /= len(train_dataloader.dataset)\n",
        "\n",
        "    return loss_collect"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "itBLhVrTZkww"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Validation Routine</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The validate function is used to evaluate the performance of the neural network model on a validation dataset. The function takes the trained model, device on which the model should be evaluated: val_dataloader,  that contains the validation dataset, and epoch number as inputs.\n",
        "In the function, the model is set to evaluation mode by calling model.eval(). Then, the function computes the average loss over the entire validation dataset using the L1 loss function, which is defined as torch.nn.L1Loss(reduction='sum'). This loss is collected in the loss_collect variable. Finally, the function prints the overall loss and returns the average loss over the validation dataset.\n",
        "</span>    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZzEt_TbEZkww"
      },
      "outputs": [],
      "source": [
        "def validate(model, device, val_dataloader, epoch): \n",
        "\n",
        "    model.eval()\n",
        "    loss_collect = 0 \n",
        "    loss_func = torch.nn.L1Loss(reduction='sum') \n",
        "    \n",
        "    with torch.no_grad(): \n",
        "        for input_vectors, targets in val_dataloader:\n",
        "            input_vectors, targets = input_vectors.to(device), targets.to(device) \n",
        "            pred_prob = model(input_vectors)\n",
        "            loss_collect += loss_func(pred_prob, targets.view(-1,1)).item()\n",
        "  \n",
        "    loss_collect /= len(val_dataloader.dataset)\n",
        "    \n",
        "    print('\\nTest dataset: Overall Loss: {:.1f},  ({:.2f}%)\\n'.format(\n",
        "        len(val_dataloader.dataset)*loss_collect,loss_collect))\n",
        "\n",
        "    return loss_collect"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bqRSlPqtZkww"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Prediction</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The predict function takes a trained model, a device (CPU or GPU), and a dataloader containing input vectors and their corresponding target values. It returns three tensors: input_all, target_all, and pred_prob_all. The input_all is a tensor containing all the input vectors from the dataloader. target_all is a tensor containing all the corresponding target values. pred_prob_all is a tensor containing all the predicted values for the input vectors.</span>    \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The function first sets the model to evaluation mode using model.eval(). Then, it iterates through the input vectors and their target values in the dataloader. For each input vector, it uses the trained model to make a prediction. It stores the input vector, target value, and predicted value in separate tensors. Finally, it returns these three tensors concatenated along the first dimension.</span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DdHxO5wEZkwx"
      },
      "outputs": [],
      "source": [
        "def predict(model, device, dataloader):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    input_all = []\n",
        "    target_all = []\n",
        "    pred_prob_all = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for input_vector, target in dataloader:\n",
        "\n",
        "            input_vector, target = input_vector.to(device), target.to(device)\n",
        "\n",
        "            pred_prob = model(input_vector)\n",
        "\n",
        "            input_all.append(input_vector)\n",
        "            target_all.append(target)\n",
        "            pred_prob_all.append(pred_prob)\n",
        "\n",
        "    return (\n",
        "        torch.cat(input_all), \n",
        "        torch.cat(target_all), \n",
        "        torch.cat(pred_prob_all).view(-1)\n",
        "    )\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MR9vEyRUZkwx"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Data Loader</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">This code creates two data loaders: one for the training set and one for the validation set. It also splits the original data set into a training set and a validation set.The first line sets the batch size to 100, this hyperparameter was defined in order to get a reasonable computing time, sizes: 10, 50, 200 and 300 were also tested.</span>    \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The second line computes the sizes of the training and validation sets. The training set is set to be 50% of the original data set, and the validation set is set to be the remaining 50%. The torch.utils.data.random_split function is used to split the original data set into these two sets. The generator argument sets the random seed to 0, ensuring that the split is reproducible.</span> \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The third line creates a data loader for the training set using the DataLoader class from PyTorch's torch.utils.data module. The dataset argument is set to the training set, batch_size is set to the batch size specified earlier, and shuffle is set to True to ensure that the data is shuffled before each epoch.</span> \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The fourth line creates a data loader for the validation set using the same approach as for the training set.</span> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0W-JCExwZkwx"
      },
      "outputs": [],
      "source": [
        "bat_size = 50\n",
        "\n",
        "size_train = int(len(data_set) * 0.9)\n",
        "size_val = len(data_set) - size_train\n",
        "train_set, val_set = torch.utils.data.random_split(data_set, \n",
        "                    [size_train, size_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "train_loader = DataLoader(dataset = train_set,batch_size=bat_size,shuffle=True)\n",
        "\n",
        "val_loader = DataLoader(dataset = val_set,batch_size=bat_size,shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "67N7v0dcZkwx"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Run training loop</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The following code block trains the fully connected neural network (FCNN) model on the provided dataset. The FCNN has an input size equal to the input size of the dataset(described in the Data Set class), two hidden layers with 1000 and 500 nodes respectively, and an output size of 1. Before getting the size of the layers the model was trained with just one layer of 100 size. The model showed an improvement once the number of neurons was incremented. In order to avoid overfitting, the dropout was included in the model.\n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The training loop runs for 300 epochs and uses the Adam optimizer with a learning rate of 0.0001. Previousley of getting these values the model was trained for just 30 epochs, the system showed improvement once the number of epochs increased, the learning rate of 0.0001 is a tipical value used for an Adam opmitizer.</span>    \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">During each epoch, the train function is called with the FCNN model, the device to run the computations on, the training data loader, and the optimizer. The train function iterates over the training data and performs forward and backward passes through the model to update its parameters. It also collects the training loss during each iteration and returns the average training loss for the epoch.</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">After each epoch, the validate function is called with the FCNN model, the device to run the computations on, the validation data loader, and the current epoch number. The validate function evaluates the FCNN on the validation data and returns the average validation loss.\n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The training loop keeps track of the training and validation losses for each epoch and plots them using matplotlib. The training loss and validation loss both decrease and stabilize at a specific point, this may indicates an good fit</span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "W1uNmxrpZkwx",
        "outputId": "57e333e7-15d3-4ac3-a06c-fda86744bc7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 [0/8892 (0%)]\t training loss: 345.2\n",
            "epoch: 1 [500/8892 (6%)]\t training loss: 284.1\n",
            "epoch: 1 [1000/8892 (11%)]\t training loss: 241.9\n",
            "epoch: 1 [1500/8892 (17%)]\t training loss: 146.6\n",
            "epoch: 1 [2000/8892 (22%)]\t training loss: 100.8\n",
            "epoch: 1 [2500/8892 (28%)]\t training loss: 93.3\n",
            "epoch: 1 [3000/8892 (34%)]\t training loss: 73.8\n",
            "epoch: 1 [3500/8892 (39%)]\t training loss: 71.0\n",
            "epoch: 1 [4000/8892 (45%)]\t training loss: 57.5\n",
            "epoch: 1 [4500/8892 (51%)]\t training loss: 71.1\n",
            "epoch: 1 [5000/8892 (56%)]\t training loss: 65.7\n",
            "epoch: 1 [5500/8892 (62%)]\t training loss: 64.9\n",
            "epoch: 1 [6000/8892 (67%)]\t training loss: 58.5\n",
            "epoch: 1 [6500/8892 (73%)]\t training loss: 62.3\n",
            "epoch: 1 [7000/8892 (79%)]\t training loss: 54.7\n",
            "epoch: 1 [7500/8892 (84%)]\t training loss: 69.0\n",
            "epoch: 1 [8000/8892 (90%)]\t training loss: 67.3\n",
            "epoch: 1 [8500/8892 (96%)]\t training loss: 66.8\n",
            "\n",
            "Test dataset: Overall Loss: 1239.3,  (1.25%)\n",
            "\n",
            "epoch: 2 [0/8892 (0%)]\t training loss: 63.4\n",
            "epoch: 2 [500/8892 (6%)]\t training loss: 52.2\n",
            "epoch: 2 [1000/8892 (11%)]\t training loss: 54.5\n",
            "epoch: 2 [1500/8892 (17%)]\t training loss: 63.4\n",
            "epoch: 2 [2000/8892 (22%)]\t training loss: 44.3\n",
            "epoch: 2 [2500/8892 (28%)]\t training loss: 57.1\n",
            "epoch: 2 [3000/8892 (34%)]\t training loss: 52.9\n",
            "epoch: 2 [3500/8892 (39%)]\t training loss: 47.8\n",
            "epoch: 2 [4000/8892 (45%)]\t training loss: 55.1\n",
            "epoch: 2 [4500/8892 (51%)]\t training loss: 72.9\n",
            "epoch: 2 [5000/8892 (56%)]\t training loss: 62.8\n",
            "epoch: 2 [5500/8892 (62%)]\t training loss: 63.8\n",
            "epoch: 2 [6000/8892 (67%)]\t training loss: 50.9\n",
            "epoch: 2 [6500/8892 (73%)]\t training loss: 55.9\n",
            "epoch: 2 [7000/8892 (79%)]\t training loss: 58.0\n",
            "epoch: 2 [7500/8892 (84%)]\t training loss: 53.7\n",
            "epoch: 2 [8000/8892 (90%)]\t training loss: 62.4\n",
            "epoch: 2 [8500/8892 (96%)]\t training loss: 54.8\n",
            "\n",
            "Test dataset: Overall Loss: 1133.2,  (1.15%)\n",
            "\n",
            "epoch: 3 [0/8892 (0%)]\t training loss: 46.0\n",
            "epoch: 3 [500/8892 (6%)]\t training loss: 52.0\n",
            "epoch: 3 [1000/8892 (11%)]\t training loss: 70.0\n",
            "epoch: 3 [1500/8892 (17%)]\t training loss: 47.7\n",
            "epoch: 3 [2000/8892 (22%)]\t training loss: 52.3\n",
            "epoch: 3 [2500/8892 (28%)]\t training loss: 52.7\n",
            "epoch: 3 [3000/8892 (34%)]\t training loss: 63.9\n",
            "epoch: 3 [3500/8892 (39%)]\t training loss: 57.3\n",
            "epoch: 3 [4000/8892 (45%)]\t training loss: 44.3\n",
            "epoch: 3 [4500/8892 (51%)]\t training loss: 61.5\n",
            "epoch: 3 [5000/8892 (56%)]\t training loss: 55.9\n",
            "epoch: 3 [5500/8892 (62%)]\t training loss: 61.2\n",
            "epoch: 3 [6000/8892 (67%)]\t training loss: 56.2\n",
            "epoch: 3 [6500/8892 (73%)]\t training loss: 55.4\n",
            "epoch: 3 [7000/8892 (79%)]\t training loss: 58.1\n",
            "epoch: 3 [7500/8892 (84%)]\t training loss: 52.1\n",
            "epoch: 3 [8000/8892 (90%)]\t training loss: 46.5\n",
            "epoch: 3 [8500/8892 (96%)]\t training loss: 51.1\n",
            "\n",
            "Test dataset: Overall Loss: 1106.8,  (1.12%)\n",
            "\n",
            "epoch: 4 [0/8892 (0%)]\t training loss: 51.3\n",
            "epoch: 4 [500/8892 (6%)]\t training loss: 47.3\n",
            "epoch: 4 [1000/8892 (11%)]\t training loss: 46.0\n",
            "epoch: 4 [1500/8892 (17%)]\t training loss: 56.4\n",
            "epoch: 4 [2000/8892 (22%)]\t training loss: 47.8\n",
            "epoch: 4 [2500/8892 (28%)]\t training loss: 56.8\n",
            "epoch: 4 [3000/8892 (34%)]\t training loss: 60.8\n",
            "epoch: 4 [3500/8892 (39%)]\t training loss: 45.5\n",
            "epoch: 4 [4000/8892 (45%)]\t training loss: 56.2\n",
            "epoch: 4 [4500/8892 (51%)]\t training loss: 53.8\n",
            "epoch: 4 [5000/8892 (56%)]\t training loss: 61.2\n",
            "epoch: 4 [5500/8892 (62%)]\t training loss: 50.6\n",
            "epoch: 4 [6000/8892 (67%)]\t training loss: 44.4\n",
            "epoch: 4 [6500/8892 (73%)]\t training loss: 47.8\n",
            "epoch: 4 [7000/8892 (79%)]\t training loss: 48.6\n",
            "epoch: 4 [7500/8892 (84%)]\t training loss: 45.4\n",
            "epoch: 4 [8000/8892 (90%)]\t training loss: 42.6\n",
            "epoch: 4 [8500/8892 (96%)]\t training loss: 43.4\n",
            "\n",
            "Test dataset: Overall Loss: 1085.0,  (1.10%)\n",
            "\n",
            "epoch: 5 [0/8892 (0%)]\t training loss: 52.1\n",
            "epoch: 5 [500/8892 (6%)]\t training loss: 53.6\n",
            "epoch: 5 [1000/8892 (11%)]\t training loss: 46.4\n",
            "epoch: 5 [1500/8892 (17%)]\t training loss: 45.9\n",
            "epoch: 5 [2000/8892 (22%)]\t training loss: 51.0\n",
            "epoch: 5 [2500/8892 (28%)]\t training loss: 42.7\n",
            "epoch: 5 [3000/8892 (34%)]\t training loss: 42.2\n",
            "epoch: 5 [3500/8892 (39%)]\t training loss: 45.6\n",
            "epoch: 5 [4000/8892 (45%)]\t training loss: 44.7\n",
            "epoch: 5 [4500/8892 (51%)]\t training loss: 43.1\n",
            "epoch: 5 [5000/8892 (56%)]\t training loss: 38.6\n",
            "epoch: 5 [5500/8892 (62%)]\t training loss: 50.0\n",
            "epoch: 5 [6000/8892 (67%)]\t training loss: 49.3\n",
            "epoch: 5 [6500/8892 (73%)]\t training loss: 49.6\n",
            "epoch: 5 [7000/8892 (79%)]\t training loss: 54.7\n",
            "epoch: 5 [7500/8892 (84%)]\t training loss: 51.0\n",
            "epoch: 5 [8000/8892 (90%)]\t training loss: 48.8\n",
            "epoch: 5 [8500/8892 (96%)]\t training loss: 52.5\n",
            "\n",
            "Test dataset: Overall Loss: 1076.9,  (1.09%)\n",
            "\n",
            "epoch: 6 [0/8892 (0%)]\t training loss: 51.1\n",
            "epoch: 6 [500/8892 (6%)]\t training loss: 46.7\n",
            "epoch: 6 [1000/8892 (11%)]\t training loss: 43.5\n",
            "epoch: 6 [1500/8892 (17%)]\t training loss: 43.6\n",
            "epoch: 6 [2000/8892 (22%)]\t training loss: 48.3\n",
            "epoch: 6 [2500/8892 (28%)]\t training loss: 57.6\n",
            "epoch: 6 [3000/8892 (34%)]\t training loss: 42.4\n",
            "epoch: 6 [3500/8892 (39%)]\t training loss: 38.5\n",
            "epoch: 6 [4000/8892 (45%)]\t training loss: 44.1\n",
            "epoch: 6 [4500/8892 (51%)]\t training loss: 45.5\n",
            "epoch: 6 [5000/8892 (56%)]\t training loss: 54.1\n",
            "epoch: 6 [5500/8892 (62%)]\t training loss: 48.2\n",
            "epoch: 6 [6000/8892 (67%)]\t training loss: 40.3\n",
            "epoch: 6 [6500/8892 (73%)]\t training loss: 51.9\n",
            "epoch: 6 [7000/8892 (79%)]\t training loss: 44.3\n",
            "epoch: 6 [7500/8892 (84%)]\t training loss: 55.2\n",
            "epoch: 6 [8000/8892 (90%)]\t training loss: 47.5\n",
            "epoch: 6 [8500/8892 (96%)]\t training loss: 52.2\n",
            "\n",
            "Test dataset: Overall Loss: 1073.0,  (1.09%)\n",
            "\n",
            "epoch: 7 [0/8892 (0%)]\t training loss: 41.1\n",
            "epoch: 7 [500/8892 (6%)]\t training loss: 43.9\n",
            "epoch: 7 [1000/8892 (11%)]\t training loss: 43.8\n",
            "epoch: 7 [1500/8892 (17%)]\t training loss: 48.9\n",
            "epoch: 7 [2000/8892 (22%)]\t training loss: 42.4\n",
            "epoch: 7 [2500/8892 (28%)]\t training loss: 50.2\n",
            "epoch: 7 [3000/8892 (34%)]\t training loss: 52.3\n",
            "epoch: 7 [3500/8892 (39%)]\t training loss: 45.6\n",
            "epoch: 7 [4000/8892 (45%)]\t training loss: 42.0\n",
            "epoch: 7 [4500/8892 (51%)]\t training loss: 36.5\n",
            "epoch: 7 [5000/8892 (56%)]\t training loss: 42.7\n",
            "epoch: 7 [5500/8892 (62%)]\t training loss: 44.8\n",
            "epoch: 7 [6000/8892 (67%)]\t training loss: 39.0\n",
            "epoch: 7 [6500/8892 (73%)]\t training loss: 46.8\n",
            "epoch: 7 [7000/8892 (79%)]\t training loss: 43.4\n",
            "epoch: 7 [7500/8892 (84%)]\t training loss: 33.0\n",
            "epoch: 7 [8000/8892 (90%)]\t training loss: 41.5\n",
            "epoch: 7 [8500/8892 (96%)]\t training loss: 36.7\n",
            "\n",
            "Test dataset: Overall Loss: 1070.4,  (1.08%)\n",
            "\n",
            "epoch: 8 [0/8892 (0%)]\t training loss: 39.4\n",
            "epoch: 8 [500/8892 (6%)]\t training loss: 41.7\n",
            "epoch: 8 [1000/8892 (11%)]\t training loss: 48.3\n",
            "epoch: 8 [1500/8892 (17%)]\t training loss: 42.5\n",
            "epoch: 8 [2000/8892 (22%)]\t training loss: 51.1\n",
            "epoch: 8 [2500/8892 (28%)]\t training loss: 44.2\n",
            "epoch: 8 [3000/8892 (34%)]\t training loss: 40.9\n",
            "epoch: 8 [3500/8892 (39%)]\t training loss: 52.5\n",
            "epoch: 8 [4000/8892 (45%)]\t training loss: 46.3\n",
            "epoch: 8 [4500/8892 (51%)]\t training loss: 43.6\n",
            "epoch: 8 [5000/8892 (56%)]\t training loss: 46.0\n",
            "epoch: 8 [5500/8892 (62%)]\t training loss: 40.0\n",
            "epoch: 8 [6000/8892 (67%)]\t training loss: 38.2\n",
            "epoch: 8 [6500/8892 (73%)]\t training loss: 50.6\n",
            "epoch: 8 [7000/8892 (79%)]\t training loss: 48.2\n",
            "epoch: 8 [7500/8892 (84%)]\t training loss: 49.1\n",
            "epoch: 8 [8000/8892 (90%)]\t training loss: 55.3\n",
            "epoch: 8 [8500/8892 (96%)]\t training loss: 39.1\n",
            "\n",
            "Test dataset: Overall Loss: 1058.8,  (1.07%)\n",
            "\n",
            "epoch: 9 [0/8892 (0%)]\t training loss: 43.6\n",
            "epoch: 9 [500/8892 (6%)]\t training loss: 43.0\n",
            "epoch: 9 [1000/8892 (11%)]\t training loss: 34.0\n",
            "epoch: 9 [1500/8892 (17%)]\t training loss: 41.1\n",
            "epoch: 9 [2000/8892 (22%)]\t training loss: 44.3\n",
            "epoch: 9 [2500/8892 (28%)]\t training loss: 34.8\n",
            "epoch: 9 [3000/8892 (34%)]\t training loss: 40.2\n",
            "epoch: 9 [3500/8892 (39%)]\t training loss: 34.4\n",
            "epoch: 9 [4000/8892 (45%)]\t training loss: 42.6\n",
            "epoch: 9 [4500/8892 (51%)]\t training loss: 40.3\n",
            "epoch: 9 [5000/8892 (56%)]\t training loss: 38.5\n",
            "epoch: 9 [5500/8892 (62%)]\t training loss: 42.4\n",
            "epoch: 9 [6000/8892 (67%)]\t training loss: 41.2\n",
            "epoch: 9 [6500/8892 (73%)]\t training loss: 37.6\n",
            "epoch: 9 [7000/8892 (79%)]\t training loss: 43.1\n",
            "epoch: 9 [7500/8892 (84%)]\t training loss: 43.5\n",
            "epoch: 9 [8000/8892 (90%)]\t training loss: 43.1\n",
            "epoch: 9 [8500/8892 (96%)]\t training loss: 37.4\n",
            "\n",
            "Test dataset: Overall Loss: 1078.3,  (1.09%)\n",
            "\n",
            "epoch: 10 [0/8892 (0%)]\t training loss: 42.6\n",
            "epoch: 10 [500/8892 (6%)]\t training loss: 41.2\n",
            "epoch: 10 [1000/8892 (11%)]\t training loss: 42.2\n",
            "epoch: 10 [1500/8892 (17%)]\t training loss: 31.7\n",
            "epoch: 10 [2000/8892 (22%)]\t training loss: 32.5\n",
            "epoch: 10 [2500/8892 (28%)]\t training loss: 43.1\n",
            "epoch: 10 [3000/8892 (34%)]\t training loss: 36.9\n",
            "epoch: 10 [3500/8892 (39%)]\t training loss: 39.0\n",
            "epoch: 10 [4000/8892 (45%)]\t training loss: 41.9\n",
            "epoch: 10 [4500/8892 (51%)]\t training loss: 33.8\n",
            "epoch: 10 [5000/8892 (56%)]\t training loss: 45.1\n",
            "epoch: 10 [5500/8892 (62%)]\t training loss: 39.6\n",
            "epoch: 10 [6000/8892 (67%)]\t training loss: 44.8\n",
            "epoch: 10 [6500/8892 (73%)]\t training loss: 40.8\n",
            "epoch: 10 [7000/8892 (79%)]\t training loss: 41.2\n",
            "epoch: 10 [7500/8892 (84%)]\t training loss: 50.7\n",
            "epoch: 10 [8000/8892 (90%)]\t training loss: 42.6\n",
            "epoch: 10 [8500/8892 (96%)]\t training loss: 46.6\n",
            "\n",
            "Test dataset: Overall Loss: 1056.1,  (1.07%)\n",
            "\n",
            "epoch: 11 [0/8892 (0%)]\t training loss: 43.9\n",
            "epoch: 11 [500/8892 (6%)]\t training loss: 31.7\n",
            "epoch: 11 [1000/8892 (11%)]\t training loss: 45.7\n",
            "epoch: 11 [1500/8892 (17%)]\t training loss: 44.1\n",
            "epoch: 11 [2000/8892 (22%)]\t training loss: 36.2\n",
            "epoch: 11 [2500/8892 (28%)]\t training loss: 31.5\n",
            "epoch: 11 [3000/8892 (34%)]\t training loss: 43.4\n",
            "epoch: 11 [3500/8892 (39%)]\t training loss: 39.0\n",
            "epoch: 11 [4000/8892 (45%)]\t training loss: 37.7\n",
            "epoch: 11 [4500/8892 (51%)]\t training loss: 31.4\n",
            "epoch: 11 [5000/8892 (56%)]\t training loss: 46.6\n",
            "epoch: 11 [5500/8892 (62%)]\t training loss: 46.5\n",
            "epoch: 11 [6000/8892 (67%)]\t training loss: 34.5\n",
            "epoch: 11 [6500/8892 (73%)]\t training loss: 37.0\n",
            "epoch: 11 [7000/8892 (79%)]\t training loss: 39.3\n",
            "epoch: 11 [7500/8892 (84%)]\t training loss: 34.0\n",
            "epoch: 11 [8000/8892 (90%)]\t training loss: 38.9\n",
            "epoch: 11 [8500/8892 (96%)]\t training loss: 39.0\n",
            "\n",
            "Test dataset: Overall Loss: 1065.0,  (1.08%)\n",
            "\n",
            "epoch: 12 [0/8892 (0%)]\t training loss: 38.5\n",
            "epoch: 12 [500/8892 (6%)]\t training loss: 34.7\n",
            "epoch: 12 [1000/8892 (11%)]\t training loss: 44.4\n",
            "epoch: 12 [1500/8892 (17%)]\t training loss: 30.9\n",
            "epoch: 12 [2000/8892 (22%)]\t training loss: 35.3\n",
            "epoch: 12 [2500/8892 (28%)]\t training loss: 33.1\n",
            "epoch: 12 [3000/8892 (34%)]\t training loss: 37.3\n",
            "epoch: 12 [3500/8892 (39%)]\t training loss: 38.1\n",
            "epoch: 12 [4000/8892 (45%)]\t training loss: 24.4\n",
            "epoch: 12 [4500/8892 (51%)]\t training loss: 39.4\n",
            "epoch: 12 [5000/8892 (56%)]\t training loss: 32.1\n",
            "epoch: 12 [5500/8892 (62%)]\t training loss: 33.6\n",
            "epoch: 12 [6000/8892 (67%)]\t training loss: 40.6\n",
            "epoch: 12 [6500/8892 (73%)]\t training loss: 32.3\n",
            "epoch: 12 [7000/8892 (79%)]\t training loss: 49.6\n",
            "epoch: 12 [7500/8892 (84%)]\t training loss: 39.4\n",
            "epoch: 12 [8000/8892 (90%)]\t training loss: 44.6\n",
            "epoch: 12 [8500/8892 (96%)]\t training loss: 40.0\n",
            "\n",
            "Test dataset: Overall Loss: 1064.0,  (1.08%)\n",
            "\n",
            "epoch: 13 [0/8892 (0%)]\t training loss: 41.3\n",
            "epoch: 13 [500/8892 (6%)]\t training loss: 37.4\n",
            "epoch: 13 [1000/8892 (11%)]\t training loss: 32.7\n",
            "epoch: 13 [1500/8892 (17%)]\t training loss: 45.0\n",
            "epoch: 13 [2000/8892 (22%)]\t training loss: 36.8\n",
            "epoch: 13 [2500/8892 (28%)]\t training loss: 29.8\n",
            "epoch: 13 [3000/8892 (34%)]\t training loss: 36.5\n",
            "epoch: 13 [3500/8892 (39%)]\t training loss: 34.2\n",
            "epoch: 13 [4000/8892 (45%)]\t training loss: 29.7\n",
            "epoch: 13 [4500/8892 (51%)]\t training loss: 35.2\n",
            "epoch: 13 [5000/8892 (56%)]\t training loss: 47.3\n",
            "epoch: 13 [5500/8892 (62%)]\t training loss: 35.6\n",
            "epoch: 13 [6000/8892 (67%)]\t training loss: 45.1\n",
            "epoch: 13 [6500/8892 (73%)]\t training loss: 38.6\n",
            "epoch: 13 [7000/8892 (79%)]\t training loss: 40.6\n",
            "epoch: 13 [7500/8892 (84%)]\t training loss: 36.1\n",
            "epoch: 13 [8000/8892 (90%)]\t training loss: 43.4\n",
            "epoch: 13 [8500/8892 (96%)]\t training loss: 38.3\n",
            "\n",
            "Test dataset: Overall Loss: 1042.0,  (1.05%)\n",
            "\n",
            "epoch: 14 [0/8892 (0%)]\t training loss: 38.9\n",
            "epoch: 14 [500/8892 (6%)]\t training loss: 32.6\n",
            "epoch: 14 [1000/8892 (11%)]\t training loss: 35.8\n",
            "epoch: 14 [1500/8892 (17%)]\t training loss: 29.6\n",
            "epoch: 14 [2000/8892 (22%)]\t training loss: 39.0\n",
            "epoch: 14 [2500/8892 (28%)]\t training loss: 38.1\n",
            "epoch: 14 [3000/8892 (34%)]\t training loss: 32.6\n",
            "epoch: 14 [3500/8892 (39%)]\t training loss: 40.6\n",
            "epoch: 14 [4000/8892 (45%)]\t training loss: 44.2\n",
            "epoch: 14 [4500/8892 (51%)]\t training loss: 43.8\n",
            "epoch: 14 [5000/8892 (56%)]\t training loss: 41.7\n",
            "epoch: 14 [5500/8892 (62%)]\t training loss: 33.3\n",
            "epoch: 14 [6000/8892 (67%)]\t training loss: 44.0\n",
            "epoch: 14 [6500/8892 (73%)]\t training loss: 37.0\n",
            "epoch: 14 [7000/8892 (79%)]\t training loss: 39.6\n",
            "epoch: 14 [7500/8892 (84%)]\t training loss: 35.3\n",
            "epoch: 14 [8000/8892 (90%)]\t training loss: 41.9\n",
            "epoch: 14 [8500/8892 (96%)]\t training loss: 39.3\n",
            "\n",
            "Test dataset: Overall Loss: 1048.5,  (1.06%)\n",
            "\n",
            "epoch: 15 [0/8892 (0%)]\t training loss: 42.1\n",
            "epoch: 15 [500/8892 (6%)]\t training loss: 39.2\n",
            "epoch: 15 [1000/8892 (11%)]\t training loss: 42.3\n",
            "epoch: 15 [1500/8892 (17%)]\t training loss: 37.5\n",
            "epoch: 15 [2000/8892 (22%)]\t training loss: 40.8\n",
            "epoch: 15 [2500/8892 (28%)]\t training loss: 29.5\n",
            "epoch: 15 [3000/8892 (34%)]\t training loss: 33.6\n",
            "epoch: 15 [3500/8892 (39%)]\t training loss: 39.0\n",
            "epoch: 15 [4000/8892 (45%)]\t training loss: 27.9\n",
            "epoch: 15 [4500/8892 (51%)]\t training loss: 43.2\n",
            "epoch: 15 [5000/8892 (56%)]\t training loss: 37.1\n",
            "epoch: 15 [5500/8892 (62%)]\t training loss: 30.8\n",
            "epoch: 15 [6000/8892 (67%)]\t training loss: 44.6\n",
            "epoch: 15 [6500/8892 (73%)]\t training loss: 38.7\n",
            "epoch: 15 [7000/8892 (79%)]\t training loss: 30.7\n",
            "epoch: 15 [7500/8892 (84%)]\t training loss: 48.6\n",
            "epoch: 15 [8000/8892 (90%)]\t training loss: 36.2\n",
            "epoch: 15 [8500/8892 (96%)]\t training loss: 41.1\n",
            "\n",
            "Test dataset: Overall Loss: 1047.7,  (1.06%)\n",
            "\n",
            "epoch: 16 [0/8892 (0%)]\t training loss: 41.4\n",
            "epoch: 16 [500/8892 (6%)]\t training loss: 28.5\n",
            "epoch: 16 [1000/8892 (11%)]\t training loss: 35.2\n",
            "epoch: 16 [1500/8892 (17%)]\t training loss: 31.9\n",
            "epoch: 16 [2000/8892 (22%)]\t training loss: 38.0\n",
            "epoch: 16 [2500/8892 (28%)]\t training loss: 38.4\n",
            "epoch: 16 [3000/8892 (34%)]\t training loss: 36.3\n",
            "epoch: 16 [3500/8892 (39%)]\t training loss: 35.2\n",
            "epoch: 16 [4000/8892 (45%)]\t training loss: 39.5\n",
            "epoch: 16 [4500/8892 (51%)]\t training loss: 37.9\n",
            "epoch: 16 [5000/8892 (56%)]\t training loss: 43.5\n",
            "epoch: 16 [5500/8892 (62%)]\t training loss: 32.7\n",
            "epoch: 16 [6000/8892 (67%)]\t training loss: 35.2\n",
            "epoch: 16 [6500/8892 (73%)]\t training loss: 40.1\n",
            "epoch: 16 [7000/8892 (79%)]\t training loss: 37.0\n",
            "epoch: 16 [7500/8892 (84%)]\t training loss: 41.0\n",
            "epoch: 16 [8000/8892 (90%)]\t training loss: 40.3\n",
            "epoch: 16 [8500/8892 (96%)]\t training loss: 37.4\n",
            "\n",
            "Test dataset: Overall Loss: 1045.5,  (1.06%)\n",
            "\n",
            "epoch: 17 [0/8892 (0%)]\t training loss: 37.2\n",
            "epoch: 17 [500/8892 (6%)]\t training loss: 38.1\n",
            "epoch: 17 [1000/8892 (11%)]\t training loss: 33.5\n",
            "epoch: 17 [1500/8892 (17%)]\t training loss: 34.8\n",
            "epoch: 17 [2000/8892 (22%)]\t training loss: 35.4\n",
            "epoch: 17 [2500/8892 (28%)]\t training loss: 35.4\n",
            "epoch: 17 [3000/8892 (34%)]\t training loss: 43.7\n",
            "epoch: 17 [3500/8892 (39%)]\t training loss: 32.7\n",
            "epoch: 17 [4000/8892 (45%)]\t training loss: 30.6\n",
            "epoch: 17 [4500/8892 (51%)]\t training loss: 28.6\n",
            "epoch: 17 [5000/8892 (56%)]\t training loss: 37.7\n",
            "epoch: 17 [5500/8892 (62%)]\t training loss: 33.9\n",
            "epoch: 17 [6000/8892 (67%)]\t training loss: 33.4\n",
            "epoch: 17 [6500/8892 (73%)]\t training loss: 44.7\n",
            "epoch: 17 [7000/8892 (79%)]\t training loss: 42.4\n",
            "epoch: 17 [7500/8892 (84%)]\t training loss: 29.5\n",
            "epoch: 17 [8000/8892 (90%)]\t training loss: 29.6\n",
            "epoch: 17 [8500/8892 (96%)]\t training loss: 37.5\n",
            "\n",
            "Test dataset: Overall Loss: 1051.0,  (1.06%)\n",
            "\n",
            "epoch: 18 [0/8892 (0%)]\t training loss: 33.4\n",
            "epoch: 18 [500/8892 (6%)]\t training loss: 31.6\n",
            "epoch: 18 [1000/8892 (11%)]\t training loss: 40.6\n",
            "epoch: 18 [1500/8892 (17%)]\t training loss: 30.5\n",
            "epoch: 18 [2000/8892 (22%)]\t training loss: 38.4\n",
            "epoch: 18 [2500/8892 (28%)]\t training loss: 45.2\n",
            "epoch: 18 [3000/8892 (34%)]\t training loss: 35.5\n",
            "epoch: 18 [3500/8892 (39%)]\t training loss: 35.4\n",
            "epoch: 18 [4000/8892 (45%)]\t training loss: 33.5\n",
            "epoch: 18 [4500/8892 (51%)]\t training loss: 36.5\n",
            "epoch: 18 [5000/8892 (56%)]\t training loss: 43.9\n",
            "epoch: 18 [5500/8892 (62%)]\t training loss: 35.3\n",
            "epoch: 18 [6000/8892 (67%)]\t training loss: 39.6\n",
            "epoch: 18 [6500/8892 (73%)]\t training loss: 35.6\n",
            "epoch: 18 [7000/8892 (79%)]\t training loss: 32.7\n",
            "epoch: 18 [7500/8892 (84%)]\t training loss: 43.0\n",
            "epoch: 18 [8000/8892 (90%)]\t training loss: 38.6\n",
            "epoch: 18 [8500/8892 (96%)]\t training loss: 39.5\n",
            "\n",
            "Test dataset: Overall Loss: 1055.3,  (1.07%)\n",
            "\n",
            "epoch: 19 [0/8892 (0%)]\t training loss: 29.5\n",
            "epoch: 19 [500/8892 (6%)]\t training loss: 25.3\n",
            "epoch: 19 [1000/8892 (11%)]\t training loss: 33.1\n",
            "epoch: 19 [1500/8892 (17%)]\t training loss: 31.8\n",
            "epoch: 19 [2000/8892 (22%)]\t training loss: 27.3\n",
            "epoch: 19 [2500/8892 (28%)]\t training loss: 30.0\n",
            "epoch: 19 [3000/8892 (34%)]\t training loss: 35.9\n",
            "epoch: 19 [3500/8892 (39%)]\t training loss: 40.3\n",
            "epoch: 19 [4000/8892 (45%)]\t training loss: 28.2\n",
            "epoch: 19 [4500/8892 (51%)]\t training loss: 25.3\n",
            "epoch: 19 [5000/8892 (56%)]\t training loss: 35.4\n",
            "epoch: 19 [5500/8892 (62%)]\t training loss: 31.9\n",
            "epoch: 19 [6000/8892 (67%)]\t training loss: 38.3\n",
            "epoch: 19 [6500/8892 (73%)]\t training loss: 32.4\n",
            "epoch: 19 [7000/8892 (79%)]\t training loss: 34.0\n",
            "epoch: 19 [7500/8892 (84%)]\t training loss: 21.5\n",
            "epoch: 19 [8000/8892 (90%)]\t training loss: 36.3\n",
            "epoch: 19 [8500/8892 (96%)]\t training loss: 32.8\n",
            "\n",
            "Test dataset: Overall Loss: 1038.6,  (1.05%)\n",
            "\n",
            "epoch: 20 [0/8892 (0%)]\t training loss: 36.4\n",
            "epoch: 20 [500/8892 (6%)]\t training loss: 37.1\n",
            "epoch: 20 [1000/8892 (11%)]\t training loss: 34.5\n",
            "epoch: 20 [1500/8892 (17%)]\t training loss: 49.4\n",
            "epoch: 20 [2000/8892 (22%)]\t training loss: 40.7\n",
            "epoch: 20 [2500/8892 (28%)]\t training loss: 29.9\n",
            "epoch: 20 [3000/8892 (34%)]\t training loss: 37.2\n",
            "epoch: 20 [3500/8892 (39%)]\t training loss: 35.0\n",
            "epoch: 20 [4000/8892 (45%)]\t training loss: 33.3\n",
            "epoch: 20 [4500/8892 (51%)]\t training loss: 31.2\n",
            "epoch: 20 [5000/8892 (56%)]\t training loss: 33.3\n",
            "epoch: 20 [5500/8892 (62%)]\t training loss: 38.1\n",
            "epoch: 20 [6000/8892 (67%)]\t training loss: 28.7\n",
            "epoch: 20 [6500/8892 (73%)]\t training loss: 44.9\n",
            "epoch: 20 [7000/8892 (79%)]\t training loss: 36.7\n",
            "epoch: 20 [7500/8892 (84%)]\t training loss: 34.6\n",
            "epoch: 20 [8000/8892 (90%)]\t training loss: 37.9\n",
            "epoch: 20 [8500/8892 (96%)]\t training loss: 26.0\n",
            "\n",
            "Test dataset: Overall Loss: 1055.1,  (1.07%)\n",
            "\n",
            "epoch: 21 [0/8892 (0%)]\t training loss: 39.7\n",
            "epoch: 21 [500/8892 (6%)]\t training loss: 32.3\n",
            "epoch: 21 [1000/8892 (11%)]\t training loss: 29.9\n",
            "epoch: 21 [1500/8892 (17%)]\t training loss: 32.6\n",
            "epoch: 21 [2000/8892 (22%)]\t training loss: 34.7\n",
            "epoch: 21 [2500/8892 (28%)]\t training loss: 35.6\n",
            "epoch: 21 [3000/8892 (34%)]\t training loss: 23.8\n",
            "epoch: 21 [3500/8892 (39%)]\t training loss: 34.8\n",
            "epoch: 21 [4000/8892 (45%)]\t training loss: 29.8\n",
            "epoch: 21 [4500/8892 (51%)]\t training loss: 33.4\n",
            "epoch: 21 [5000/8892 (56%)]\t training loss: 35.2\n",
            "epoch: 21 [5500/8892 (62%)]\t training loss: 35.3\n",
            "epoch: 21 [6000/8892 (67%)]\t training loss: 37.8\n",
            "epoch: 21 [6500/8892 (73%)]\t training loss: 25.1\n",
            "epoch: 21 [7000/8892 (79%)]\t training loss: 29.2\n",
            "epoch: 21 [7500/8892 (84%)]\t training loss: 35.9\n",
            "epoch: 21 [8000/8892 (90%)]\t training loss: 26.4\n",
            "epoch: 21 [8500/8892 (96%)]\t training loss: 29.1\n",
            "\n",
            "Test dataset: Overall Loss: 1059.7,  (1.07%)\n",
            "\n",
            "epoch: 22 [0/8892 (0%)]\t training loss: 24.6\n",
            "epoch: 22 [500/8892 (6%)]\t training loss: 37.0\n",
            "epoch: 22 [1000/8892 (11%)]\t training loss: 35.7\n",
            "epoch: 22 [1500/8892 (17%)]\t training loss: 33.8\n",
            "epoch: 22 [2000/8892 (22%)]\t training loss: 30.8\n",
            "epoch: 22 [2500/8892 (28%)]\t training loss: 29.2\n",
            "epoch: 22 [3000/8892 (34%)]\t training loss: 35.4\n",
            "epoch: 22 [3500/8892 (39%)]\t training loss: 30.3\n",
            "epoch: 22 [4000/8892 (45%)]\t training loss: 34.9\n",
            "epoch: 22 [4500/8892 (51%)]\t training loss: 36.0\n",
            "epoch: 22 [5000/8892 (56%)]\t training loss: 29.6\n",
            "epoch: 22 [5500/8892 (62%)]\t training loss: 35.7\n",
            "epoch: 22 [6000/8892 (67%)]\t training loss: 35.0\n",
            "epoch: 22 [6500/8892 (73%)]\t training loss: 28.5\n",
            "epoch: 22 [7000/8892 (79%)]\t training loss: 40.1\n",
            "epoch: 22 [7500/8892 (84%)]\t training loss: 35.1\n",
            "epoch: 22 [8000/8892 (90%)]\t training loss: 31.9\n",
            "epoch: 22 [8500/8892 (96%)]\t training loss: 30.4\n",
            "\n",
            "Test dataset: Overall Loss: 1055.7,  (1.07%)\n",
            "\n",
            "epoch: 23 [0/8892 (0%)]\t training loss: 29.7\n",
            "epoch: 23 [500/8892 (6%)]\t training loss: 38.5\n",
            "epoch: 23 [1000/8892 (11%)]\t training loss: 30.4\n",
            "epoch: 23 [1500/8892 (17%)]\t training loss: 35.2\n",
            "epoch: 23 [2000/8892 (22%)]\t training loss: 36.9\n",
            "epoch: 23 [2500/8892 (28%)]\t training loss: 27.8\n",
            "epoch: 23 [3000/8892 (34%)]\t training loss: 37.2\n",
            "epoch: 23 [3500/8892 (39%)]\t training loss: 33.8\n",
            "epoch: 23 [4000/8892 (45%)]\t training loss: 26.9\n",
            "epoch: 23 [4500/8892 (51%)]\t training loss: 34.3\n",
            "epoch: 23 [5000/8892 (56%)]\t training loss: 35.6\n",
            "epoch: 23 [5500/8892 (62%)]\t training loss: 29.9\n",
            "epoch: 23 [6000/8892 (67%)]\t training loss: 34.3\n",
            "epoch: 23 [6500/8892 (73%)]\t training loss: 32.4\n",
            "epoch: 23 [7000/8892 (79%)]\t training loss: 34.2\n",
            "epoch: 23 [7500/8892 (84%)]\t training loss: 36.6\n",
            "epoch: 23 [8000/8892 (90%)]\t training loss: 35.4\n",
            "epoch: 23 [8500/8892 (96%)]\t training loss: 27.0\n",
            "\n",
            "Test dataset: Overall Loss: 1055.8,  (1.07%)\n",
            "\n",
            "epoch: 24 [0/8892 (0%)]\t training loss: 25.3\n",
            "epoch: 24 [500/8892 (6%)]\t training loss: 25.3\n",
            "epoch: 24 [1000/8892 (11%)]\t training loss: 37.3\n",
            "epoch: 24 [1500/8892 (17%)]\t training loss: 35.0\n",
            "epoch: 24 [2000/8892 (22%)]\t training loss: 28.6\n",
            "epoch: 24 [2500/8892 (28%)]\t training loss: 26.9\n",
            "epoch: 24 [3000/8892 (34%)]\t training loss: 30.1\n",
            "epoch: 24 [3500/8892 (39%)]\t training loss: 32.3\n",
            "epoch: 24 [4000/8892 (45%)]\t training loss: 36.1\n",
            "epoch: 24 [4500/8892 (51%)]\t training loss: 34.4\n",
            "epoch: 24 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 24 [5500/8892 (62%)]\t training loss: 35.9\n",
            "epoch: 24 [6000/8892 (67%)]\t training loss: 37.1\n",
            "epoch: 24 [6500/8892 (73%)]\t training loss: 30.7\n",
            "epoch: 24 [7000/8892 (79%)]\t training loss: 43.1\n",
            "epoch: 24 [7500/8892 (84%)]\t training loss: 39.4\n",
            "epoch: 24 [8000/8892 (90%)]\t training loss: 32.2\n",
            "epoch: 24 [8500/8892 (96%)]\t training loss: 31.4\n",
            "\n",
            "Test dataset: Overall Loss: 1039.2,  (1.05%)\n",
            "\n",
            "epoch: 25 [0/8892 (0%)]\t training loss: 32.7\n",
            "epoch: 25 [500/8892 (6%)]\t training loss: 27.2\n",
            "epoch: 25 [1000/8892 (11%)]\t training loss: 28.7\n",
            "epoch: 25 [1500/8892 (17%)]\t training loss: 28.2\n",
            "epoch: 25 [2000/8892 (22%)]\t training loss: 32.2\n",
            "epoch: 25 [2500/8892 (28%)]\t training loss: 32.5\n",
            "epoch: 25 [3000/8892 (34%)]\t training loss: 25.4\n",
            "epoch: 25 [3500/8892 (39%)]\t training loss: 39.6\n",
            "epoch: 25 [4000/8892 (45%)]\t training loss: 30.7\n",
            "epoch: 25 [4500/8892 (51%)]\t training loss: 32.0\n",
            "epoch: 25 [5000/8892 (56%)]\t training loss: 32.9\n",
            "epoch: 25 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 25 [6000/8892 (67%)]\t training loss: 27.2\n",
            "epoch: 25 [6500/8892 (73%)]\t training loss: 38.4\n",
            "epoch: 25 [7000/8892 (79%)]\t training loss: 34.1\n",
            "epoch: 25 [7500/8892 (84%)]\t training loss: 30.5\n",
            "epoch: 25 [8000/8892 (90%)]\t training loss: 24.6\n",
            "epoch: 25 [8500/8892 (96%)]\t training loss: 33.7\n",
            "\n",
            "Test dataset: Overall Loss: 1049.2,  (1.06%)\n",
            "\n",
            "epoch: 26 [0/8892 (0%)]\t training loss: 24.8\n",
            "epoch: 26 [500/8892 (6%)]\t training loss: 34.2\n",
            "epoch: 26 [1000/8892 (11%)]\t training loss: 34.4\n",
            "epoch: 26 [1500/8892 (17%)]\t training loss: 32.3\n",
            "epoch: 26 [2000/8892 (22%)]\t training loss: 31.3\n",
            "epoch: 26 [2500/8892 (28%)]\t training loss: 36.1\n",
            "epoch: 26 [3000/8892 (34%)]\t training loss: 30.3\n",
            "epoch: 26 [3500/8892 (39%)]\t training loss: 30.2\n",
            "epoch: 26 [4000/8892 (45%)]\t training loss: 29.3\n",
            "epoch: 26 [4500/8892 (51%)]\t training loss: 44.7\n",
            "epoch: 26 [5000/8892 (56%)]\t training loss: 35.3\n",
            "epoch: 26 [5500/8892 (62%)]\t training loss: 31.5\n",
            "epoch: 26 [6000/8892 (67%)]\t training loss: 38.0\n",
            "epoch: 26 [6500/8892 (73%)]\t training loss: 32.4\n",
            "epoch: 26 [7000/8892 (79%)]\t training loss: 29.0\n",
            "epoch: 26 [7500/8892 (84%)]\t training loss: 24.9\n",
            "epoch: 26 [8000/8892 (90%)]\t training loss: 26.0\n",
            "epoch: 26 [8500/8892 (96%)]\t training loss: 28.0\n",
            "\n",
            "Test dataset: Overall Loss: 1056.2,  (1.07%)\n",
            "\n",
            "epoch: 27 [0/8892 (0%)]\t training loss: 22.9\n",
            "epoch: 27 [500/8892 (6%)]\t training loss: 35.3\n",
            "epoch: 27 [1000/8892 (11%)]\t training loss: 35.8\n",
            "epoch: 27 [1500/8892 (17%)]\t training loss: 31.2\n",
            "epoch: 27 [2000/8892 (22%)]\t training loss: 32.4\n",
            "epoch: 27 [2500/8892 (28%)]\t training loss: 31.9\n",
            "epoch: 27 [3000/8892 (34%)]\t training loss: 33.6\n",
            "epoch: 27 [3500/8892 (39%)]\t training loss: 40.1\n",
            "epoch: 27 [4000/8892 (45%)]\t training loss: 26.0\n",
            "epoch: 27 [4500/8892 (51%)]\t training loss: 32.8\n",
            "epoch: 27 [5000/8892 (56%)]\t training loss: 37.5\n",
            "epoch: 27 [5500/8892 (62%)]\t training loss: 39.0\n",
            "epoch: 27 [6000/8892 (67%)]\t training loss: 34.1\n",
            "epoch: 27 [6500/8892 (73%)]\t training loss: 30.9\n",
            "epoch: 27 [7000/8892 (79%)]\t training loss: 33.1\n",
            "epoch: 27 [7500/8892 (84%)]\t training loss: 39.0\n",
            "epoch: 27 [8000/8892 (90%)]\t training loss: 35.3\n",
            "epoch: 27 [8500/8892 (96%)]\t training loss: 23.7\n",
            "\n",
            "Test dataset: Overall Loss: 1040.4,  (1.05%)\n",
            "\n",
            "epoch: 28 [0/8892 (0%)]\t training loss: 29.6\n",
            "epoch: 28 [500/8892 (6%)]\t training loss: 32.3\n",
            "epoch: 28 [1000/8892 (11%)]\t training loss: 32.6\n",
            "epoch: 28 [1500/8892 (17%)]\t training loss: 35.6\n",
            "epoch: 28 [2000/8892 (22%)]\t training loss: 37.1\n",
            "epoch: 28 [2500/8892 (28%)]\t training loss: 30.2\n",
            "epoch: 28 [3000/8892 (34%)]\t training loss: 28.7\n",
            "epoch: 28 [3500/8892 (39%)]\t training loss: 30.3\n",
            "epoch: 28 [4000/8892 (45%)]\t training loss: 35.4\n",
            "epoch: 28 [4500/8892 (51%)]\t training loss: 31.3\n",
            "epoch: 28 [5000/8892 (56%)]\t training loss: 28.8\n",
            "epoch: 28 [5500/8892 (62%)]\t training loss: 24.6\n",
            "epoch: 28 [6000/8892 (67%)]\t training loss: 35.2\n",
            "epoch: 28 [6500/8892 (73%)]\t training loss: 31.5\n",
            "epoch: 28 [7000/8892 (79%)]\t training loss: 26.4\n",
            "epoch: 28 [7500/8892 (84%)]\t training loss: 31.1\n",
            "epoch: 28 [8000/8892 (90%)]\t training loss: 33.4\n",
            "epoch: 28 [8500/8892 (96%)]\t training loss: 35.9\n",
            "\n",
            "Test dataset: Overall Loss: 1056.9,  (1.07%)\n",
            "\n",
            "epoch: 29 [0/8892 (0%)]\t training loss: 34.2\n",
            "epoch: 29 [500/8892 (6%)]\t training loss: 32.8\n",
            "epoch: 29 [1000/8892 (11%)]\t training loss: 27.4\n",
            "epoch: 29 [1500/8892 (17%)]\t training loss: 35.0\n",
            "epoch: 29 [2000/8892 (22%)]\t training loss: 32.1\n",
            "epoch: 29 [2500/8892 (28%)]\t training loss: 24.5\n",
            "epoch: 29 [3000/8892 (34%)]\t training loss: 34.4\n",
            "epoch: 29 [3500/8892 (39%)]\t training loss: 33.2\n",
            "epoch: 29 [4000/8892 (45%)]\t training loss: 26.3\n",
            "epoch: 29 [4500/8892 (51%)]\t training loss: 30.1\n",
            "epoch: 29 [5000/8892 (56%)]\t training loss: 30.5\n",
            "epoch: 29 [5500/8892 (62%)]\t training loss: 36.2\n",
            "epoch: 29 [6000/8892 (67%)]\t training loss: 43.9\n",
            "epoch: 29 [6500/8892 (73%)]\t training loss: 33.8\n",
            "epoch: 29 [7000/8892 (79%)]\t training loss: 35.3\n",
            "epoch: 29 [7500/8892 (84%)]\t training loss: 28.8\n",
            "epoch: 29 [8000/8892 (90%)]\t training loss: 27.7\n",
            "epoch: 29 [8500/8892 (96%)]\t training loss: 29.8\n",
            "\n",
            "Test dataset: Overall Loss: 1037.7,  (1.05%)\n",
            "\n",
            "epoch: 30 [0/8892 (0%)]\t training loss: 30.9\n",
            "epoch: 30 [500/8892 (6%)]\t training loss: 32.7\n",
            "epoch: 30 [1000/8892 (11%)]\t training loss: 33.8\n",
            "epoch: 30 [1500/8892 (17%)]\t training loss: 31.1\n",
            "epoch: 30 [2000/8892 (22%)]\t training loss: 34.1\n",
            "epoch: 30 [2500/8892 (28%)]\t training loss: 27.3\n",
            "epoch: 30 [3000/8892 (34%)]\t training loss: 36.6\n",
            "epoch: 30 [3500/8892 (39%)]\t training loss: 26.1\n",
            "epoch: 30 [4000/8892 (45%)]\t training loss: 25.9\n",
            "epoch: 30 [4500/8892 (51%)]\t training loss: 28.6\n",
            "epoch: 30 [5000/8892 (56%)]\t training loss: 33.7\n",
            "epoch: 30 [5500/8892 (62%)]\t training loss: 31.8\n",
            "epoch: 30 [6000/8892 (67%)]\t training loss: 35.4\n",
            "epoch: 30 [6500/8892 (73%)]\t training loss: 32.6\n",
            "epoch: 30 [7000/8892 (79%)]\t training loss: 27.7\n",
            "epoch: 30 [7500/8892 (84%)]\t training loss: 28.6\n",
            "epoch: 30 [8000/8892 (90%)]\t training loss: 33.9\n",
            "epoch: 30 [8500/8892 (96%)]\t training loss: 35.5\n",
            "\n",
            "Test dataset: Overall Loss: 1050.4,  (1.06%)\n",
            "\n",
            "epoch: 31 [0/8892 (0%)]\t training loss: 25.5\n",
            "epoch: 31 [500/8892 (6%)]\t training loss: 29.3\n",
            "epoch: 31 [1000/8892 (11%)]\t training loss: 31.2\n",
            "epoch: 31 [1500/8892 (17%)]\t training loss: 24.7\n",
            "epoch: 31 [2000/8892 (22%)]\t training loss: 26.2\n",
            "epoch: 31 [2500/8892 (28%)]\t training loss: 29.6\n",
            "epoch: 31 [3000/8892 (34%)]\t training loss: 33.0\n",
            "epoch: 31 [3500/8892 (39%)]\t training loss: 26.6\n",
            "epoch: 31 [4000/8892 (45%)]\t training loss: 29.6\n",
            "epoch: 31 [4500/8892 (51%)]\t training loss: 34.1\n",
            "epoch: 31 [5000/8892 (56%)]\t training loss: 31.5\n",
            "epoch: 31 [5500/8892 (62%)]\t training loss: 30.6\n",
            "epoch: 31 [6000/8892 (67%)]\t training loss: 35.5\n",
            "epoch: 31 [6500/8892 (73%)]\t training loss: 31.7\n",
            "epoch: 31 [7000/8892 (79%)]\t training loss: 29.9\n",
            "epoch: 31 [7500/8892 (84%)]\t training loss: 29.8\n",
            "epoch: 31 [8000/8892 (90%)]\t training loss: 27.7\n",
            "epoch: 31 [8500/8892 (96%)]\t training loss: 29.6\n",
            "\n",
            "Test dataset: Overall Loss: 1037.2,  (1.05%)\n",
            "\n",
            "epoch: 32 [0/8892 (0%)]\t training loss: 40.7\n",
            "epoch: 32 [500/8892 (6%)]\t training loss: 25.8\n",
            "epoch: 32 [1000/8892 (11%)]\t training loss: 31.5\n",
            "epoch: 32 [1500/8892 (17%)]\t training loss: 26.2\n",
            "epoch: 32 [2000/8892 (22%)]\t training loss: 30.0\n",
            "epoch: 32 [2500/8892 (28%)]\t training loss: 25.9\n",
            "epoch: 32 [3000/8892 (34%)]\t training loss: 26.6\n",
            "epoch: 32 [3500/8892 (39%)]\t training loss: 27.4\n",
            "epoch: 32 [4000/8892 (45%)]\t training loss: 25.6\n",
            "epoch: 32 [4500/8892 (51%)]\t training loss: 27.3\n",
            "epoch: 32 [5000/8892 (56%)]\t training loss: 29.3\n",
            "epoch: 32 [5500/8892 (62%)]\t training loss: 27.6\n",
            "epoch: 32 [6000/8892 (67%)]\t training loss: 34.0\n",
            "epoch: 32 [6500/8892 (73%)]\t training loss: 26.3\n",
            "epoch: 32 [7000/8892 (79%)]\t training loss: 29.7\n",
            "epoch: 32 [7500/8892 (84%)]\t training loss: 29.1\n",
            "epoch: 32 [8000/8892 (90%)]\t training loss: 35.1\n",
            "epoch: 32 [8500/8892 (96%)]\t training loss: 33.7\n",
            "\n",
            "Test dataset: Overall Loss: 1032.1,  (1.04%)\n",
            "\n",
            "epoch: 33 [0/8892 (0%)]\t training loss: 34.2\n",
            "epoch: 33 [500/8892 (6%)]\t training loss: 25.8\n",
            "epoch: 33 [1000/8892 (11%)]\t training loss: 29.9\n",
            "epoch: 33 [1500/8892 (17%)]\t training loss: 30.2\n",
            "epoch: 33 [2000/8892 (22%)]\t training loss: 31.9\n",
            "epoch: 33 [2500/8892 (28%)]\t training loss: 31.9\n",
            "epoch: 33 [3000/8892 (34%)]\t training loss: 25.3\n",
            "epoch: 33 [3500/8892 (39%)]\t training loss: 28.3\n",
            "epoch: 33 [4000/8892 (45%)]\t training loss: 36.5\n",
            "epoch: 33 [4500/8892 (51%)]\t training loss: 27.4\n",
            "epoch: 33 [5000/8892 (56%)]\t training loss: 26.8\n",
            "epoch: 33 [5500/8892 (62%)]\t training loss: 37.6\n",
            "epoch: 33 [6000/8892 (67%)]\t training loss: 37.7\n",
            "epoch: 33 [6500/8892 (73%)]\t training loss: 26.2\n",
            "epoch: 33 [7000/8892 (79%)]\t training loss: 25.3\n",
            "epoch: 33 [7500/8892 (84%)]\t training loss: 33.4\n",
            "epoch: 33 [8000/8892 (90%)]\t training loss: 27.5\n",
            "epoch: 33 [8500/8892 (96%)]\t training loss: 35.1\n",
            "\n",
            "Test dataset: Overall Loss: 1020.9,  (1.03%)\n",
            "\n",
            "epoch: 34 [0/8892 (0%)]\t training loss: 35.9\n",
            "epoch: 34 [500/8892 (6%)]\t training loss: 32.9\n",
            "epoch: 34 [1000/8892 (11%)]\t training loss: 30.8\n",
            "epoch: 34 [1500/8892 (17%)]\t training loss: 34.2\n",
            "epoch: 34 [2000/8892 (22%)]\t training loss: 32.2\n",
            "epoch: 34 [2500/8892 (28%)]\t training loss: 28.3\n",
            "epoch: 34 [3000/8892 (34%)]\t training loss: 32.9\n",
            "epoch: 34 [3500/8892 (39%)]\t training loss: 30.0\n",
            "epoch: 34 [4000/8892 (45%)]\t training loss: 34.1\n",
            "epoch: 34 [4500/8892 (51%)]\t training loss: 28.9\n",
            "epoch: 34 [5000/8892 (56%)]\t training loss: 31.2\n",
            "epoch: 34 [5500/8892 (62%)]\t training loss: 31.3\n",
            "epoch: 34 [6000/8892 (67%)]\t training loss: 32.3\n",
            "epoch: 34 [6500/8892 (73%)]\t training loss: 31.8\n",
            "epoch: 34 [7000/8892 (79%)]\t training loss: 35.3\n",
            "epoch: 34 [7500/8892 (84%)]\t training loss: 31.8\n",
            "epoch: 34 [8000/8892 (90%)]\t training loss: 23.0\n",
            "epoch: 34 [8500/8892 (96%)]\t training loss: 31.1\n",
            "\n",
            "Test dataset: Overall Loss: 1033.1,  (1.05%)\n",
            "\n",
            "epoch: 35 [0/8892 (0%)]\t training loss: 30.7\n",
            "epoch: 35 [500/8892 (6%)]\t training loss: 29.4\n",
            "epoch: 35 [1000/8892 (11%)]\t training loss: 43.4\n",
            "epoch: 35 [1500/8892 (17%)]\t training loss: 35.8\n",
            "epoch: 35 [2000/8892 (22%)]\t training loss: 25.6\n",
            "epoch: 35 [2500/8892 (28%)]\t training loss: 33.4\n",
            "epoch: 35 [3000/8892 (34%)]\t training loss: 25.7\n",
            "epoch: 35 [3500/8892 (39%)]\t training loss: 38.2\n",
            "epoch: 35 [4000/8892 (45%)]\t training loss: 36.7\n",
            "epoch: 35 [4500/8892 (51%)]\t training loss: 25.4\n",
            "epoch: 35 [5000/8892 (56%)]\t training loss: 34.1\n",
            "epoch: 35 [5500/8892 (62%)]\t training loss: 28.7\n",
            "epoch: 35 [6000/8892 (67%)]\t training loss: 29.6\n",
            "epoch: 35 [6500/8892 (73%)]\t training loss: 30.3\n",
            "epoch: 35 [7000/8892 (79%)]\t training loss: 28.4\n",
            "epoch: 35 [7500/8892 (84%)]\t training loss: 22.6\n",
            "epoch: 35 [8000/8892 (90%)]\t training loss: 30.2\n",
            "epoch: 35 [8500/8892 (96%)]\t training loss: 32.6\n",
            "\n",
            "Test dataset: Overall Loss: 1056.6,  (1.07%)\n",
            "\n",
            "epoch: 36 [0/8892 (0%)]\t training loss: 25.7\n",
            "epoch: 36 [500/8892 (6%)]\t training loss: 23.5\n",
            "epoch: 36 [1000/8892 (11%)]\t training loss: 31.6\n",
            "epoch: 36 [1500/8892 (17%)]\t training loss: 32.0\n",
            "epoch: 36 [2000/8892 (22%)]\t training loss: 23.7\n",
            "epoch: 36 [2500/8892 (28%)]\t training loss: 26.1\n",
            "epoch: 36 [3000/8892 (34%)]\t training loss: 31.5\n",
            "epoch: 36 [3500/8892 (39%)]\t training loss: 35.3\n",
            "epoch: 36 [4000/8892 (45%)]\t training loss: 25.7\n",
            "epoch: 36 [4500/8892 (51%)]\t training loss: 24.8\n",
            "epoch: 36 [5000/8892 (56%)]\t training loss: 22.2\n",
            "epoch: 36 [5500/8892 (62%)]\t training loss: 28.9\n",
            "epoch: 36 [6000/8892 (67%)]\t training loss: 27.5\n",
            "epoch: 36 [6500/8892 (73%)]\t training loss: 25.9\n",
            "epoch: 36 [7000/8892 (79%)]\t training loss: 19.6\n",
            "epoch: 36 [7500/8892 (84%)]\t training loss: 28.4\n",
            "epoch: 36 [8000/8892 (90%)]\t training loss: 33.8\n",
            "epoch: 36 [8500/8892 (96%)]\t training loss: 30.7\n",
            "\n",
            "Test dataset: Overall Loss: 1037.2,  (1.05%)\n",
            "\n",
            "epoch: 37 [0/8892 (0%)]\t training loss: 31.0\n",
            "epoch: 37 [500/8892 (6%)]\t training loss: 38.3\n",
            "epoch: 37 [1000/8892 (11%)]\t training loss: 25.7\n",
            "epoch: 37 [1500/8892 (17%)]\t training loss: 30.5\n",
            "epoch: 37 [2000/8892 (22%)]\t training loss: 24.7\n",
            "epoch: 37 [2500/8892 (28%)]\t training loss: 30.1\n",
            "epoch: 37 [3000/8892 (34%)]\t training loss: 26.5\n",
            "epoch: 37 [3500/8892 (39%)]\t training loss: 42.6\n",
            "epoch: 37 [4000/8892 (45%)]\t training loss: 28.4\n",
            "epoch: 37 [4500/8892 (51%)]\t training loss: 33.6\n",
            "epoch: 37 [5000/8892 (56%)]\t training loss: 31.1\n",
            "epoch: 37 [5500/8892 (62%)]\t training loss: 33.9\n",
            "epoch: 37 [6000/8892 (67%)]\t training loss: 40.8\n",
            "epoch: 37 [6500/8892 (73%)]\t training loss: 28.4\n",
            "epoch: 37 [7000/8892 (79%)]\t training loss: 32.7\n",
            "epoch: 37 [7500/8892 (84%)]\t training loss: 30.7\n",
            "epoch: 37 [8000/8892 (90%)]\t training loss: 30.7\n",
            "epoch: 37 [8500/8892 (96%)]\t training loss: 43.6\n",
            "\n",
            "Test dataset: Overall Loss: 1032.1,  (1.04%)\n",
            "\n",
            "epoch: 38 [0/8892 (0%)]\t training loss: 36.0\n",
            "epoch: 38 [500/8892 (6%)]\t training loss: 31.3\n",
            "epoch: 38 [1000/8892 (11%)]\t training loss: 37.0\n",
            "epoch: 38 [1500/8892 (17%)]\t training loss: 36.0\n",
            "epoch: 38 [2000/8892 (22%)]\t training loss: 26.6\n",
            "epoch: 38 [2500/8892 (28%)]\t training loss: 27.2\n",
            "epoch: 38 [3000/8892 (34%)]\t training loss: 28.7\n",
            "epoch: 38 [3500/8892 (39%)]\t training loss: 36.2\n",
            "epoch: 38 [4000/8892 (45%)]\t training loss: 28.3\n",
            "epoch: 38 [4500/8892 (51%)]\t training loss: 26.9\n",
            "epoch: 38 [5000/8892 (56%)]\t training loss: 23.2\n",
            "epoch: 38 [5500/8892 (62%)]\t training loss: 27.8\n",
            "epoch: 38 [6000/8892 (67%)]\t training loss: 27.9\n",
            "epoch: 38 [6500/8892 (73%)]\t training loss: 20.6\n",
            "epoch: 38 [7000/8892 (79%)]\t training loss: 32.5\n",
            "epoch: 38 [7500/8892 (84%)]\t training loss: 37.6\n",
            "epoch: 38 [8000/8892 (90%)]\t training loss: 28.4\n",
            "epoch: 38 [8500/8892 (96%)]\t training loss: 35.4\n",
            "\n",
            "Test dataset: Overall Loss: 1041.9,  (1.05%)\n",
            "\n",
            "epoch: 39 [0/8892 (0%)]\t training loss: 37.3\n",
            "epoch: 39 [500/8892 (6%)]\t training loss: 29.7\n",
            "epoch: 39 [1000/8892 (11%)]\t training loss: 32.4\n",
            "epoch: 39 [1500/8892 (17%)]\t training loss: 28.6\n",
            "epoch: 39 [2000/8892 (22%)]\t training loss: 38.4\n",
            "epoch: 39 [2500/8892 (28%)]\t training loss: 22.2\n",
            "epoch: 39 [3000/8892 (34%)]\t training loss: 27.5\n",
            "epoch: 39 [3500/8892 (39%)]\t training loss: 35.8\n",
            "epoch: 39 [4000/8892 (45%)]\t training loss: 25.2\n",
            "epoch: 39 [4500/8892 (51%)]\t training loss: 24.6\n",
            "epoch: 39 [5000/8892 (56%)]\t training loss: 29.6\n",
            "epoch: 39 [5500/8892 (62%)]\t training loss: 31.7\n",
            "epoch: 39 [6000/8892 (67%)]\t training loss: 26.0\n",
            "epoch: 39 [6500/8892 (73%)]\t training loss: 27.2\n",
            "epoch: 39 [7000/8892 (79%)]\t training loss: 27.8\n",
            "epoch: 39 [7500/8892 (84%)]\t training loss: 32.4\n",
            "epoch: 39 [8000/8892 (90%)]\t training loss: 32.7\n",
            "epoch: 39 [8500/8892 (96%)]\t training loss: 32.7\n",
            "\n",
            "Test dataset: Overall Loss: 1039.6,  (1.05%)\n",
            "\n",
            "epoch: 40 [0/8892 (0%)]\t training loss: 28.5\n",
            "epoch: 40 [500/8892 (6%)]\t training loss: 34.8\n",
            "epoch: 40 [1000/8892 (11%)]\t training loss: 28.9\n",
            "epoch: 40 [1500/8892 (17%)]\t training loss: 26.3\n",
            "epoch: 40 [2000/8892 (22%)]\t training loss: 27.6\n",
            "epoch: 40 [2500/8892 (28%)]\t training loss: 30.0\n",
            "epoch: 40 [3000/8892 (34%)]\t training loss: 23.4\n",
            "epoch: 40 [3500/8892 (39%)]\t training loss: 23.8\n",
            "epoch: 40 [4000/8892 (45%)]\t training loss: 37.5\n",
            "epoch: 40 [4500/8892 (51%)]\t training loss: 25.9\n",
            "epoch: 40 [5000/8892 (56%)]\t training loss: 24.4\n",
            "epoch: 40 [5500/8892 (62%)]\t training loss: 33.9\n",
            "epoch: 40 [6000/8892 (67%)]\t training loss: 42.6\n",
            "epoch: 40 [6500/8892 (73%)]\t training loss: 32.4\n",
            "epoch: 40 [7000/8892 (79%)]\t training loss: 28.0\n",
            "epoch: 40 [7500/8892 (84%)]\t training loss: 28.4\n",
            "epoch: 40 [8000/8892 (90%)]\t training loss: 25.8\n",
            "epoch: 40 [8500/8892 (96%)]\t training loss: 25.0\n",
            "\n",
            "Test dataset: Overall Loss: 1038.4,  (1.05%)\n",
            "\n",
            "epoch: 41 [0/8892 (0%)]\t training loss: 30.8\n",
            "epoch: 41 [500/8892 (6%)]\t training loss: 28.0\n",
            "epoch: 41 [1000/8892 (11%)]\t training loss: 24.1\n",
            "epoch: 41 [1500/8892 (17%)]\t training loss: 29.5\n",
            "epoch: 41 [2000/8892 (22%)]\t training loss: 28.2\n",
            "epoch: 41 [2500/8892 (28%)]\t training loss: 29.3\n",
            "epoch: 41 [3000/8892 (34%)]\t training loss: 28.9\n",
            "epoch: 41 [3500/8892 (39%)]\t training loss: 26.9\n",
            "epoch: 41 [4000/8892 (45%)]\t training loss: 33.8\n",
            "epoch: 41 [4500/8892 (51%)]\t training loss: 37.8\n",
            "epoch: 41 [5000/8892 (56%)]\t training loss: 22.0\n",
            "epoch: 41 [5500/8892 (62%)]\t training loss: 25.4\n",
            "epoch: 41 [6000/8892 (67%)]\t training loss: 29.0\n",
            "epoch: 41 [6500/8892 (73%)]\t training loss: 31.1\n",
            "epoch: 41 [7000/8892 (79%)]\t training loss: 26.8\n",
            "epoch: 41 [7500/8892 (84%)]\t training loss: 28.6\n",
            "epoch: 41 [8000/8892 (90%)]\t training loss: 34.8\n",
            "epoch: 41 [8500/8892 (96%)]\t training loss: 23.3\n",
            "\n",
            "Test dataset: Overall Loss: 1038.7,  (1.05%)\n",
            "\n",
            "epoch: 42 [0/8892 (0%)]\t training loss: 30.0\n",
            "epoch: 42 [500/8892 (6%)]\t training loss: 32.3\n",
            "epoch: 42 [1000/8892 (11%)]\t training loss: 31.1\n",
            "epoch: 42 [1500/8892 (17%)]\t training loss: 31.5\n",
            "epoch: 42 [2000/8892 (22%)]\t training loss: 29.4\n",
            "epoch: 42 [2500/8892 (28%)]\t training loss: 29.6\n",
            "epoch: 42 [3000/8892 (34%)]\t training loss: 31.9\n",
            "epoch: 42 [3500/8892 (39%)]\t training loss: 31.5\n",
            "epoch: 42 [4000/8892 (45%)]\t training loss: 29.9\n",
            "epoch: 42 [4500/8892 (51%)]\t training loss: 28.2\n",
            "epoch: 42 [5000/8892 (56%)]\t training loss: 30.9\n",
            "epoch: 42 [5500/8892 (62%)]\t training loss: 25.7\n",
            "epoch: 42 [6000/8892 (67%)]\t training loss: 35.1\n",
            "epoch: 42 [6500/8892 (73%)]\t training loss: 27.4\n",
            "epoch: 42 [7000/8892 (79%)]\t training loss: 27.7\n",
            "epoch: 42 [7500/8892 (84%)]\t training loss: 26.7\n",
            "epoch: 42 [8000/8892 (90%)]\t training loss: 39.1\n",
            "epoch: 42 [8500/8892 (96%)]\t training loss: 36.3\n",
            "\n",
            "Test dataset: Overall Loss: 1033.9,  (1.05%)\n",
            "\n",
            "epoch: 43 [0/8892 (0%)]\t training loss: 29.8\n",
            "epoch: 43 [500/8892 (6%)]\t training loss: 25.7\n",
            "epoch: 43 [1000/8892 (11%)]\t training loss: 31.8\n",
            "epoch: 43 [1500/8892 (17%)]\t training loss: 22.2\n",
            "epoch: 43 [2000/8892 (22%)]\t training loss: 25.9\n",
            "epoch: 43 [2500/8892 (28%)]\t training loss: 26.0\n",
            "epoch: 43 [3000/8892 (34%)]\t training loss: 29.0\n",
            "epoch: 43 [3500/8892 (39%)]\t training loss: 30.1\n",
            "epoch: 43 [4000/8892 (45%)]\t training loss: 26.1\n",
            "epoch: 43 [4500/8892 (51%)]\t training loss: 30.2\n",
            "epoch: 43 [5000/8892 (56%)]\t training loss: 27.6\n",
            "epoch: 43 [5500/8892 (62%)]\t training loss: 31.3\n",
            "epoch: 43 [6000/8892 (67%)]\t training loss: 25.7\n",
            "epoch: 43 [6500/8892 (73%)]\t training loss: 37.7\n",
            "epoch: 43 [7000/8892 (79%)]\t training loss: 27.8\n",
            "epoch: 43 [7500/8892 (84%)]\t training loss: 38.0\n",
            "epoch: 43 [8000/8892 (90%)]\t training loss: 27.2\n",
            "epoch: 43 [8500/8892 (96%)]\t training loss: 25.2\n",
            "\n",
            "Test dataset: Overall Loss: 1029.4,  (1.04%)\n",
            "\n",
            "epoch: 44 [0/8892 (0%)]\t training loss: 25.1\n",
            "epoch: 44 [500/8892 (6%)]\t training loss: 36.7\n",
            "epoch: 44 [1000/8892 (11%)]\t training loss: 29.1\n",
            "epoch: 44 [1500/8892 (17%)]\t training loss: 22.6\n",
            "epoch: 44 [2000/8892 (22%)]\t training loss: 31.7\n",
            "epoch: 44 [2500/8892 (28%)]\t training loss: 28.8\n",
            "epoch: 44 [3000/8892 (34%)]\t training loss: 26.9\n",
            "epoch: 44 [3500/8892 (39%)]\t training loss: 30.1\n",
            "epoch: 44 [4000/8892 (45%)]\t training loss: 27.5\n",
            "epoch: 44 [4500/8892 (51%)]\t training loss: 36.8\n",
            "epoch: 44 [5000/8892 (56%)]\t training loss: 20.9\n",
            "epoch: 44 [5500/8892 (62%)]\t training loss: 23.8\n",
            "epoch: 44 [6000/8892 (67%)]\t training loss: 35.2\n",
            "epoch: 44 [6500/8892 (73%)]\t training loss: 31.3\n",
            "epoch: 44 [7000/8892 (79%)]\t training loss: 27.3\n",
            "epoch: 44 [7500/8892 (84%)]\t training loss: 28.5\n",
            "epoch: 44 [8000/8892 (90%)]\t training loss: 32.1\n",
            "epoch: 44 [8500/8892 (96%)]\t training loss: 39.5\n",
            "\n",
            "Test dataset: Overall Loss: 1044.4,  (1.06%)\n",
            "\n",
            "epoch: 45 [0/8892 (0%)]\t training loss: 25.2\n",
            "epoch: 45 [500/8892 (6%)]\t training loss: 24.0\n",
            "epoch: 45 [1000/8892 (11%)]\t training loss: 18.0\n",
            "epoch: 45 [1500/8892 (17%)]\t training loss: 30.1\n",
            "epoch: 45 [2000/8892 (22%)]\t training loss: 29.8\n",
            "epoch: 45 [2500/8892 (28%)]\t training loss: 37.3\n",
            "epoch: 45 [3000/8892 (34%)]\t training loss: 32.1\n",
            "epoch: 45 [3500/8892 (39%)]\t training loss: 33.7\n",
            "epoch: 45 [4000/8892 (45%)]\t training loss: 28.3\n",
            "epoch: 45 [4500/8892 (51%)]\t training loss: 28.4\n",
            "epoch: 45 [5000/8892 (56%)]\t training loss: 24.4\n",
            "epoch: 45 [5500/8892 (62%)]\t training loss: 30.2\n",
            "epoch: 45 [6000/8892 (67%)]\t training loss: 25.8\n",
            "epoch: 45 [6500/8892 (73%)]\t training loss: 39.3\n",
            "epoch: 45 [7000/8892 (79%)]\t training loss: 27.0\n",
            "epoch: 45 [7500/8892 (84%)]\t training loss: 18.6\n",
            "epoch: 45 [8000/8892 (90%)]\t training loss: 23.0\n",
            "epoch: 45 [8500/8892 (96%)]\t training loss: 34.3\n",
            "\n",
            "Test dataset: Overall Loss: 1039.5,  (1.05%)\n",
            "\n",
            "epoch: 46 [0/8892 (0%)]\t training loss: 39.7\n",
            "epoch: 46 [500/8892 (6%)]\t training loss: 23.5\n",
            "epoch: 46 [1000/8892 (11%)]\t training loss: 23.5\n",
            "epoch: 46 [1500/8892 (17%)]\t training loss: 30.2\n",
            "epoch: 46 [2000/8892 (22%)]\t training loss: 28.2\n",
            "epoch: 46 [2500/8892 (28%)]\t training loss: 21.4\n",
            "epoch: 46 [3000/8892 (34%)]\t training loss: 33.6\n",
            "epoch: 46 [3500/8892 (39%)]\t training loss: 32.0\n",
            "epoch: 46 [4000/8892 (45%)]\t training loss: 21.0\n",
            "epoch: 46 [4500/8892 (51%)]\t training loss: 24.0\n",
            "epoch: 46 [5000/8892 (56%)]\t training loss: 33.9\n",
            "epoch: 46 [5500/8892 (62%)]\t training loss: 20.1\n",
            "epoch: 46 [6000/8892 (67%)]\t training loss: 35.2\n",
            "epoch: 46 [6500/8892 (73%)]\t training loss: 29.7\n",
            "epoch: 46 [7000/8892 (79%)]\t training loss: 30.5\n",
            "epoch: 46 [7500/8892 (84%)]\t training loss: 22.6\n",
            "epoch: 46 [8000/8892 (90%)]\t training loss: 24.2\n",
            "epoch: 46 [8500/8892 (96%)]\t training loss: 26.4\n",
            "\n",
            "Test dataset: Overall Loss: 1047.7,  (1.06%)\n",
            "\n",
            "epoch: 47 [0/8892 (0%)]\t training loss: 23.8\n",
            "epoch: 47 [500/8892 (6%)]\t training loss: 25.1\n",
            "epoch: 47 [1000/8892 (11%)]\t training loss: 29.0\n",
            "epoch: 47 [1500/8892 (17%)]\t training loss: 34.0\n",
            "epoch: 47 [2000/8892 (22%)]\t training loss: 27.7\n",
            "epoch: 47 [2500/8892 (28%)]\t training loss: 30.3\n",
            "epoch: 47 [3000/8892 (34%)]\t training loss: 25.0\n",
            "epoch: 47 [3500/8892 (39%)]\t training loss: 28.9\n",
            "epoch: 47 [4000/8892 (45%)]\t training loss: 28.4\n",
            "epoch: 47 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 47 [5000/8892 (56%)]\t training loss: 26.6\n",
            "epoch: 47 [5500/8892 (62%)]\t training loss: 30.2\n",
            "epoch: 47 [6000/8892 (67%)]\t training loss: 25.0\n",
            "epoch: 47 [6500/8892 (73%)]\t training loss: 28.5\n",
            "epoch: 47 [7000/8892 (79%)]\t training loss: 30.4\n",
            "epoch: 47 [7500/8892 (84%)]\t training loss: 31.2\n",
            "epoch: 47 [8000/8892 (90%)]\t training loss: 23.7\n",
            "epoch: 47 [8500/8892 (96%)]\t training loss: 27.9\n",
            "\n",
            "Test dataset: Overall Loss: 1027.2,  (1.04%)\n",
            "\n",
            "epoch: 48 [0/8892 (0%)]\t training loss: 32.5\n",
            "epoch: 48 [500/8892 (6%)]\t training loss: 37.9\n",
            "epoch: 48 [1000/8892 (11%)]\t training loss: 27.1\n",
            "epoch: 48 [1500/8892 (17%)]\t training loss: 29.7\n",
            "epoch: 48 [2000/8892 (22%)]\t training loss: 22.3\n",
            "epoch: 48 [2500/8892 (28%)]\t training loss: 26.3\n",
            "epoch: 48 [3000/8892 (34%)]\t training loss: 22.6\n",
            "epoch: 48 [3500/8892 (39%)]\t training loss: 29.4\n",
            "epoch: 48 [4000/8892 (45%)]\t training loss: 28.1\n",
            "epoch: 48 [4500/8892 (51%)]\t training loss: 27.7\n",
            "epoch: 48 [5000/8892 (56%)]\t training loss: 34.3\n",
            "epoch: 48 [5500/8892 (62%)]\t training loss: 33.3\n",
            "epoch: 48 [6000/8892 (67%)]\t training loss: 36.7\n",
            "epoch: 48 [6500/8892 (73%)]\t training loss: 27.1\n",
            "epoch: 48 [7000/8892 (79%)]\t training loss: 25.9\n",
            "epoch: 48 [7500/8892 (84%)]\t training loss: 29.4\n",
            "epoch: 48 [8000/8892 (90%)]\t training loss: 33.4\n",
            "epoch: 48 [8500/8892 (96%)]\t training loss: 33.9\n",
            "\n",
            "Test dataset: Overall Loss: 1032.0,  (1.04%)\n",
            "\n",
            "epoch: 49 [0/8892 (0%)]\t training loss: 34.0\n",
            "epoch: 49 [500/8892 (6%)]\t training loss: 35.1\n",
            "epoch: 49 [1000/8892 (11%)]\t training loss: 28.0\n",
            "epoch: 49 [1500/8892 (17%)]\t training loss: 31.1\n",
            "epoch: 49 [2000/8892 (22%)]\t training loss: 28.7\n",
            "epoch: 49 [2500/8892 (28%)]\t training loss: 34.8\n",
            "epoch: 49 [3000/8892 (34%)]\t training loss: 24.0\n",
            "epoch: 49 [3500/8892 (39%)]\t training loss: 30.8\n",
            "epoch: 49 [4000/8892 (45%)]\t training loss: 23.3\n",
            "epoch: 49 [4500/8892 (51%)]\t training loss: 28.5\n",
            "epoch: 49 [5000/8892 (56%)]\t training loss: 22.8\n",
            "epoch: 49 [5500/8892 (62%)]\t training loss: 24.3\n",
            "epoch: 49 [6000/8892 (67%)]\t training loss: 30.6\n",
            "epoch: 49 [6500/8892 (73%)]\t training loss: 29.0\n",
            "epoch: 49 [7000/8892 (79%)]\t training loss: 25.0\n",
            "epoch: 49 [7500/8892 (84%)]\t training loss: 31.2\n",
            "epoch: 49 [8000/8892 (90%)]\t training loss: 23.2\n",
            "epoch: 49 [8500/8892 (96%)]\t training loss: 28.3\n",
            "\n",
            "Test dataset: Overall Loss: 1037.5,  (1.05%)\n",
            "\n",
            "epoch: 50 [0/8892 (0%)]\t training loss: 26.0\n",
            "epoch: 50 [500/8892 (6%)]\t training loss: 26.6\n",
            "epoch: 50 [1000/8892 (11%)]\t training loss: 24.9\n",
            "epoch: 50 [1500/8892 (17%)]\t training loss: 31.0\n",
            "epoch: 50 [2000/8892 (22%)]\t training loss: 26.7\n",
            "epoch: 50 [2500/8892 (28%)]\t training loss: 26.9\n",
            "epoch: 50 [3000/8892 (34%)]\t training loss: 25.7\n",
            "epoch: 50 [3500/8892 (39%)]\t training loss: 28.8\n",
            "epoch: 50 [4000/8892 (45%)]\t training loss: 24.4\n",
            "epoch: 50 [4500/8892 (51%)]\t training loss: 31.0\n",
            "epoch: 50 [5000/8892 (56%)]\t training loss: 31.7\n",
            "epoch: 50 [5500/8892 (62%)]\t training loss: 32.7\n",
            "epoch: 50 [6000/8892 (67%)]\t training loss: 38.9\n",
            "epoch: 50 [6500/8892 (73%)]\t training loss: 26.7\n",
            "epoch: 50 [7000/8892 (79%)]\t training loss: 31.0\n",
            "epoch: 50 [7500/8892 (84%)]\t training loss: 31.2\n",
            "epoch: 50 [8000/8892 (90%)]\t training loss: 22.4\n",
            "epoch: 50 [8500/8892 (96%)]\t training loss: 24.1\n",
            "\n",
            "Test dataset: Overall Loss: 1021.7,  (1.03%)\n",
            "\n",
            "epoch: 51 [0/8892 (0%)]\t training loss: 30.9\n",
            "epoch: 51 [500/8892 (6%)]\t training loss: 29.3\n",
            "epoch: 51 [1000/8892 (11%)]\t training loss: 27.9\n",
            "epoch: 51 [1500/8892 (17%)]\t training loss: 29.3\n",
            "epoch: 51 [2000/8892 (22%)]\t training loss: 36.5\n",
            "epoch: 51 [2500/8892 (28%)]\t training loss: 25.7\n",
            "epoch: 51 [3000/8892 (34%)]\t training loss: 32.1\n",
            "epoch: 51 [3500/8892 (39%)]\t training loss: 30.5\n",
            "epoch: 51 [4000/8892 (45%)]\t training loss: 29.6\n",
            "epoch: 51 [4500/8892 (51%)]\t training loss: 31.9\n",
            "epoch: 51 [5000/8892 (56%)]\t training loss: 37.9\n",
            "epoch: 51 [5500/8892 (62%)]\t training loss: 29.5\n",
            "epoch: 51 [6000/8892 (67%)]\t training loss: 26.5\n",
            "epoch: 51 [6500/8892 (73%)]\t training loss: 32.8\n",
            "epoch: 51 [7000/8892 (79%)]\t training loss: 29.2\n",
            "epoch: 51 [7500/8892 (84%)]\t training loss: 26.8\n",
            "epoch: 51 [8000/8892 (90%)]\t training loss: 22.7\n",
            "epoch: 51 [8500/8892 (96%)]\t training loss: 19.2\n",
            "\n",
            "Test dataset: Overall Loss: 1044.1,  (1.06%)\n",
            "\n",
            "epoch: 52 [0/8892 (0%)]\t training loss: 26.1\n",
            "epoch: 52 [500/8892 (6%)]\t training loss: 29.3\n",
            "epoch: 52 [1000/8892 (11%)]\t training loss: 32.4\n",
            "epoch: 52 [1500/8892 (17%)]\t training loss: 27.3\n",
            "epoch: 52 [2000/8892 (22%)]\t training loss: 30.8\n",
            "epoch: 52 [2500/8892 (28%)]\t training loss: 32.7\n",
            "epoch: 52 [3000/8892 (34%)]\t training loss: 23.9\n",
            "epoch: 52 [3500/8892 (39%)]\t training loss: 31.9\n",
            "epoch: 52 [4000/8892 (45%)]\t training loss: 28.3\n",
            "epoch: 52 [4500/8892 (51%)]\t training loss: 26.0\n",
            "epoch: 52 [5000/8892 (56%)]\t training loss: 25.1\n",
            "epoch: 52 [5500/8892 (62%)]\t training loss: 27.8\n",
            "epoch: 52 [6000/8892 (67%)]\t training loss: 25.8\n",
            "epoch: 52 [6500/8892 (73%)]\t training loss: 31.4\n",
            "epoch: 52 [7000/8892 (79%)]\t training loss: 27.1\n",
            "epoch: 52 [7500/8892 (84%)]\t training loss: 26.8\n",
            "epoch: 52 [8000/8892 (90%)]\t training loss: 22.8\n",
            "epoch: 52 [8500/8892 (96%)]\t training loss: 29.9\n",
            "\n",
            "Test dataset: Overall Loss: 1035.1,  (1.05%)\n",
            "\n",
            "epoch: 53 [0/8892 (0%)]\t training loss: 28.0\n",
            "epoch: 53 [500/8892 (6%)]\t training loss: 35.8\n",
            "epoch: 53 [1000/8892 (11%)]\t training loss: 24.8\n",
            "epoch: 53 [1500/8892 (17%)]\t training loss: 26.9\n",
            "epoch: 53 [2000/8892 (22%)]\t training loss: 29.7\n",
            "epoch: 53 [2500/8892 (28%)]\t training loss: 25.2\n",
            "epoch: 53 [3000/8892 (34%)]\t training loss: 27.9\n",
            "epoch: 53 [3500/8892 (39%)]\t training loss: 23.0\n",
            "epoch: 53 [4000/8892 (45%)]\t training loss: 28.9\n",
            "epoch: 53 [4500/8892 (51%)]\t training loss: 33.4\n",
            "epoch: 53 [5000/8892 (56%)]\t training loss: 33.4\n",
            "epoch: 53 [5500/8892 (62%)]\t training loss: 26.2\n",
            "epoch: 53 [6000/8892 (67%)]\t training loss: 28.4\n",
            "epoch: 53 [6500/8892 (73%)]\t training loss: 27.5\n",
            "epoch: 53 [7000/8892 (79%)]\t training loss: 31.3\n",
            "epoch: 53 [7500/8892 (84%)]\t training loss: 27.5\n",
            "epoch: 53 [8000/8892 (90%)]\t training loss: 27.1\n",
            "epoch: 53 [8500/8892 (96%)]\t training loss: 26.7\n",
            "\n",
            "Test dataset: Overall Loss: 1031.2,  (1.04%)\n",
            "\n",
            "epoch: 54 [0/8892 (0%)]\t training loss: 25.9\n",
            "epoch: 54 [500/8892 (6%)]\t training loss: 26.1\n",
            "epoch: 54 [1000/8892 (11%)]\t training loss: 28.9\n",
            "epoch: 54 [1500/8892 (17%)]\t training loss: 27.7\n",
            "epoch: 54 [2000/8892 (22%)]\t training loss: 28.2\n",
            "epoch: 54 [2500/8892 (28%)]\t training loss: 26.6\n",
            "epoch: 54 [3000/8892 (34%)]\t training loss: 26.6\n",
            "epoch: 54 [3500/8892 (39%)]\t training loss: 20.8\n",
            "epoch: 54 [4000/8892 (45%)]\t training loss: 29.4\n",
            "epoch: 54 [4500/8892 (51%)]\t training loss: 34.4\n",
            "epoch: 54 [5000/8892 (56%)]\t training loss: 37.0\n",
            "epoch: 54 [5500/8892 (62%)]\t training loss: 29.4\n",
            "epoch: 54 [6000/8892 (67%)]\t training loss: 31.3\n",
            "epoch: 54 [6500/8892 (73%)]\t training loss: 34.4\n",
            "epoch: 54 [7000/8892 (79%)]\t training loss: 29.8\n",
            "epoch: 54 [7500/8892 (84%)]\t training loss: 23.7\n",
            "epoch: 54 [8000/8892 (90%)]\t training loss: 27.6\n",
            "epoch: 54 [8500/8892 (96%)]\t training loss: 36.8\n",
            "\n",
            "Test dataset: Overall Loss: 1022.0,  (1.03%)\n",
            "\n",
            "epoch: 55 [0/8892 (0%)]\t training loss: 29.8\n",
            "epoch: 55 [500/8892 (6%)]\t training loss: 30.3\n",
            "epoch: 55 [1000/8892 (11%)]\t training loss: 28.8\n",
            "epoch: 55 [1500/8892 (17%)]\t training loss: 24.4\n",
            "epoch: 55 [2000/8892 (22%)]\t training loss: 27.6\n",
            "epoch: 55 [2500/8892 (28%)]\t training loss: 24.5\n",
            "epoch: 55 [3000/8892 (34%)]\t training loss: 29.7\n",
            "epoch: 55 [3500/8892 (39%)]\t training loss: 27.8\n",
            "epoch: 55 [4000/8892 (45%)]\t training loss: 22.9\n",
            "epoch: 55 [4500/8892 (51%)]\t training loss: 26.1\n",
            "epoch: 55 [5000/8892 (56%)]\t training loss: 25.6\n",
            "epoch: 55 [5500/8892 (62%)]\t training loss: 31.4\n",
            "epoch: 55 [6000/8892 (67%)]\t training loss: 35.3\n",
            "epoch: 55 [6500/8892 (73%)]\t training loss: 36.1\n",
            "epoch: 55 [7000/8892 (79%)]\t training loss: 28.8\n",
            "epoch: 55 [7500/8892 (84%)]\t training loss: 23.8\n",
            "epoch: 55 [8000/8892 (90%)]\t training loss: 26.8\n",
            "epoch: 55 [8500/8892 (96%)]\t training loss: 27.6\n",
            "\n",
            "Test dataset: Overall Loss: 1034.0,  (1.05%)\n",
            "\n",
            "epoch: 56 [0/8892 (0%)]\t training loss: 28.5\n",
            "epoch: 56 [500/8892 (6%)]\t training loss: 27.7\n",
            "epoch: 56 [1000/8892 (11%)]\t training loss: 27.8\n",
            "epoch: 56 [1500/8892 (17%)]\t training loss: 31.1\n",
            "epoch: 56 [2000/8892 (22%)]\t training loss: 29.3\n",
            "epoch: 56 [2500/8892 (28%)]\t training loss: 25.6\n",
            "epoch: 56 [3000/8892 (34%)]\t training loss: 26.7\n",
            "epoch: 56 [3500/8892 (39%)]\t training loss: 23.1\n",
            "epoch: 56 [4000/8892 (45%)]\t training loss: 28.0\n",
            "epoch: 56 [4500/8892 (51%)]\t training loss: 26.4\n",
            "epoch: 56 [5000/8892 (56%)]\t training loss: 25.6\n",
            "epoch: 56 [5500/8892 (62%)]\t training loss: 29.3\n",
            "epoch: 56 [6000/8892 (67%)]\t training loss: 24.7\n",
            "epoch: 56 [6500/8892 (73%)]\t training loss: 30.3\n",
            "epoch: 56 [7000/8892 (79%)]\t training loss: 29.0\n",
            "epoch: 56 [7500/8892 (84%)]\t training loss: 24.7\n",
            "epoch: 56 [8000/8892 (90%)]\t training loss: 24.9\n",
            "epoch: 56 [8500/8892 (96%)]\t training loss: 20.2\n",
            "\n",
            "Test dataset: Overall Loss: 1025.2,  (1.04%)\n",
            "\n",
            "epoch: 57 [0/8892 (0%)]\t training loss: 31.2\n",
            "epoch: 57 [500/8892 (6%)]\t training loss: 26.4\n",
            "epoch: 57 [1000/8892 (11%)]\t training loss: 22.7\n",
            "epoch: 57 [1500/8892 (17%)]\t training loss: 29.9\n",
            "epoch: 57 [2000/8892 (22%)]\t training loss: 27.8\n",
            "epoch: 57 [2500/8892 (28%)]\t training loss: 26.8\n",
            "epoch: 57 [3000/8892 (34%)]\t training loss: 26.5\n",
            "epoch: 57 [3500/8892 (39%)]\t training loss: 28.3\n",
            "epoch: 57 [4000/8892 (45%)]\t training loss: 31.6\n",
            "epoch: 57 [4500/8892 (51%)]\t training loss: 30.5\n",
            "epoch: 57 [5000/8892 (56%)]\t training loss: 30.8\n",
            "epoch: 57 [5500/8892 (62%)]\t training loss: 32.8\n",
            "epoch: 57 [6000/8892 (67%)]\t training loss: 25.3\n",
            "epoch: 57 [6500/8892 (73%)]\t training loss: 26.5\n",
            "epoch: 57 [7000/8892 (79%)]\t training loss: 27.1\n",
            "epoch: 57 [7500/8892 (84%)]\t training loss: 28.3\n",
            "epoch: 57 [8000/8892 (90%)]\t training loss: 26.9\n",
            "epoch: 57 [8500/8892 (96%)]\t training loss: 30.4\n",
            "\n",
            "Test dataset: Overall Loss: 1033.1,  (1.05%)\n",
            "\n",
            "epoch: 58 [0/8892 (0%)]\t training loss: 39.4\n",
            "epoch: 58 [500/8892 (6%)]\t training loss: 23.2\n",
            "epoch: 58 [1000/8892 (11%)]\t training loss: 27.2\n",
            "epoch: 58 [1500/8892 (17%)]\t training loss: 23.3\n",
            "epoch: 58 [2000/8892 (22%)]\t training loss: 22.9\n",
            "epoch: 58 [2500/8892 (28%)]\t training loss: 32.6\n",
            "epoch: 58 [3000/8892 (34%)]\t training loss: 34.6\n",
            "epoch: 58 [3500/8892 (39%)]\t training loss: 22.7\n",
            "epoch: 58 [4000/8892 (45%)]\t training loss: 29.0\n",
            "epoch: 58 [4500/8892 (51%)]\t training loss: 37.2\n",
            "epoch: 58 [5000/8892 (56%)]\t training loss: 35.6\n",
            "epoch: 58 [5500/8892 (62%)]\t training loss: 27.1\n",
            "epoch: 58 [6000/8892 (67%)]\t training loss: 27.7\n",
            "epoch: 58 [6500/8892 (73%)]\t training loss: 31.4\n",
            "epoch: 58 [7000/8892 (79%)]\t training loss: 26.2\n",
            "epoch: 58 [7500/8892 (84%)]\t training loss: 29.1\n",
            "epoch: 58 [8000/8892 (90%)]\t training loss: 30.2\n",
            "epoch: 58 [8500/8892 (96%)]\t training loss: 26.2\n",
            "\n",
            "Test dataset: Overall Loss: 1047.0,  (1.06%)\n",
            "\n",
            "epoch: 59 [0/8892 (0%)]\t training loss: 34.6\n",
            "epoch: 59 [500/8892 (6%)]\t training loss: 28.6\n",
            "epoch: 59 [1000/8892 (11%)]\t training loss: 25.2\n",
            "epoch: 59 [1500/8892 (17%)]\t training loss: 23.9\n",
            "epoch: 59 [2000/8892 (22%)]\t training loss: 32.8\n",
            "epoch: 59 [2500/8892 (28%)]\t training loss: 26.3\n",
            "epoch: 59 [3000/8892 (34%)]\t training loss: 30.4\n",
            "epoch: 59 [3500/8892 (39%)]\t training loss: 25.8\n",
            "epoch: 59 [4000/8892 (45%)]\t training loss: 37.5\n",
            "epoch: 59 [4500/8892 (51%)]\t training loss: 32.4\n",
            "epoch: 59 [5000/8892 (56%)]\t training loss: 29.7\n",
            "epoch: 59 [5500/8892 (62%)]\t training loss: 30.4\n",
            "epoch: 59 [6000/8892 (67%)]\t training loss: 25.0\n",
            "epoch: 59 [6500/8892 (73%)]\t training loss: 34.0\n",
            "epoch: 59 [7000/8892 (79%)]\t training loss: 26.6\n",
            "epoch: 59 [7500/8892 (84%)]\t training loss: 29.2\n",
            "epoch: 59 [8000/8892 (90%)]\t training loss: 27.6\n",
            "epoch: 59 [8500/8892 (96%)]\t training loss: 30.2\n",
            "\n",
            "Test dataset: Overall Loss: 1037.8,  (1.05%)\n",
            "\n",
            "epoch: 60 [0/8892 (0%)]\t training loss: 27.2\n",
            "epoch: 60 [500/8892 (6%)]\t training loss: 30.9\n",
            "epoch: 60 [1000/8892 (11%)]\t training loss: 30.2\n",
            "epoch: 60 [1500/8892 (17%)]\t training loss: 26.8\n",
            "epoch: 60 [2000/8892 (22%)]\t training loss: 28.8\n",
            "epoch: 60 [2500/8892 (28%)]\t training loss: 21.6\n",
            "epoch: 60 [3000/8892 (34%)]\t training loss: 31.2\n",
            "epoch: 60 [3500/8892 (39%)]\t training loss: 31.3\n",
            "epoch: 60 [4000/8892 (45%)]\t training loss: 28.7\n",
            "epoch: 60 [4500/8892 (51%)]\t training loss: 27.3\n",
            "epoch: 60 [5000/8892 (56%)]\t training loss: 21.9\n",
            "epoch: 60 [5500/8892 (62%)]\t training loss: 26.3\n",
            "epoch: 60 [6000/8892 (67%)]\t training loss: 35.0\n",
            "epoch: 60 [6500/8892 (73%)]\t training loss: 27.4\n",
            "epoch: 60 [7000/8892 (79%)]\t training loss: 26.8\n",
            "epoch: 60 [7500/8892 (84%)]\t training loss: 27.1\n",
            "epoch: 60 [8000/8892 (90%)]\t training loss: 32.0\n",
            "epoch: 60 [8500/8892 (96%)]\t training loss: 31.3\n",
            "\n",
            "Test dataset: Overall Loss: 1034.4,  (1.05%)\n",
            "\n",
            "epoch: 61 [0/8892 (0%)]\t training loss: 27.1\n",
            "epoch: 61 [500/8892 (6%)]\t training loss: 24.9\n",
            "epoch: 61 [1000/8892 (11%)]\t training loss: 35.0\n",
            "epoch: 61 [1500/8892 (17%)]\t training loss: 24.5\n",
            "epoch: 61 [2000/8892 (22%)]\t training loss: 23.3\n",
            "epoch: 61 [2500/8892 (28%)]\t training loss: 27.5\n",
            "epoch: 61 [3000/8892 (34%)]\t training loss: 29.3\n",
            "epoch: 61 [3500/8892 (39%)]\t training loss: 26.6\n",
            "epoch: 61 [4000/8892 (45%)]\t training loss: 26.2\n",
            "epoch: 61 [4500/8892 (51%)]\t training loss: 26.2\n",
            "epoch: 61 [5000/8892 (56%)]\t training loss: 28.3\n",
            "epoch: 61 [5500/8892 (62%)]\t training loss: 32.3\n",
            "epoch: 61 [6000/8892 (67%)]\t training loss: 31.5\n",
            "epoch: 61 [6500/8892 (73%)]\t training loss: 31.6\n",
            "epoch: 61 [7000/8892 (79%)]\t training loss: 27.6\n",
            "epoch: 61 [7500/8892 (84%)]\t training loss: 31.3\n",
            "epoch: 61 [8000/8892 (90%)]\t training loss: 29.5\n",
            "epoch: 61 [8500/8892 (96%)]\t training loss: 29.4\n",
            "\n",
            "Test dataset: Overall Loss: 1043.5,  (1.06%)\n",
            "\n",
            "epoch: 62 [0/8892 (0%)]\t training loss: 20.8\n",
            "epoch: 62 [500/8892 (6%)]\t training loss: 22.6\n",
            "epoch: 62 [1000/8892 (11%)]\t training loss: 30.1\n",
            "epoch: 62 [1500/8892 (17%)]\t training loss: 27.5\n",
            "epoch: 62 [2000/8892 (22%)]\t training loss: 27.2\n",
            "epoch: 62 [2500/8892 (28%)]\t training loss: 32.6\n",
            "epoch: 62 [3000/8892 (34%)]\t training loss: 31.0\n",
            "epoch: 62 [3500/8892 (39%)]\t training loss: 27.3\n",
            "epoch: 62 [4000/8892 (45%)]\t training loss: 21.6\n",
            "epoch: 62 [4500/8892 (51%)]\t training loss: 35.5\n",
            "epoch: 62 [5000/8892 (56%)]\t training loss: 29.5\n",
            "epoch: 62 [5500/8892 (62%)]\t training loss: 24.6\n",
            "epoch: 62 [6000/8892 (67%)]\t training loss: 24.2\n",
            "epoch: 62 [6500/8892 (73%)]\t training loss: 30.4\n",
            "epoch: 62 [7000/8892 (79%)]\t training loss: 30.3\n",
            "epoch: 62 [7500/8892 (84%)]\t training loss: 21.6\n",
            "epoch: 62 [8000/8892 (90%)]\t training loss: 37.3\n",
            "epoch: 62 [8500/8892 (96%)]\t training loss: 30.5\n",
            "\n",
            "Test dataset: Overall Loss: 1030.4,  (1.04%)\n",
            "\n",
            "epoch: 63 [0/8892 (0%)]\t training loss: 21.2\n",
            "epoch: 63 [500/8892 (6%)]\t training loss: 27.8\n",
            "epoch: 63 [1000/8892 (11%)]\t training loss: 25.6\n",
            "epoch: 63 [1500/8892 (17%)]\t training loss: 31.3\n",
            "epoch: 63 [2000/8892 (22%)]\t training loss: 24.9\n",
            "epoch: 63 [2500/8892 (28%)]\t training loss: 23.1\n",
            "epoch: 63 [3000/8892 (34%)]\t training loss: 24.5\n",
            "epoch: 63 [3500/8892 (39%)]\t training loss: 20.1\n",
            "epoch: 63 [4000/8892 (45%)]\t training loss: 25.0\n",
            "epoch: 63 [4500/8892 (51%)]\t training loss: 30.1\n",
            "epoch: 63 [5000/8892 (56%)]\t training loss: 26.4\n",
            "epoch: 63 [5500/8892 (62%)]\t training loss: 24.8\n",
            "epoch: 63 [6000/8892 (67%)]\t training loss: 25.7\n",
            "epoch: 63 [6500/8892 (73%)]\t training loss: 31.1\n",
            "epoch: 63 [7000/8892 (79%)]\t training loss: 22.8\n",
            "epoch: 63 [7500/8892 (84%)]\t training loss: 31.4\n",
            "epoch: 63 [8000/8892 (90%)]\t training loss: 31.1\n",
            "epoch: 63 [8500/8892 (96%)]\t training loss: 31.2\n",
            "\n",
            "Test dataset: Overall Loss: 1056.6,  (1.07%)\n",
            "\n",
            "epoch: 64 [0/8892 (0%)]\t training loss: 28.9\n",
            "epoch: 64 [500/8892 (6%)]\t training loss: 31.4\n",
            "epoch: 64 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 64 [1500/8892 (17%)]\t training loss: 26.3\n",
            "epoch: 64 [2000/8892 (22%)]\t training loss: 23.7\n",
            "epoch: 64 [2500/8892 (28%)]\t training loss: 32.2\n",
            "epoch: 64 [3000/8892 (34%)]\t training loss: 22.7\n",
            "epoch: 64 [3500/8892 (39%)]\t training loss: 24.8\n",
            "epoch: 64 [4000/8892 (45%)]\t training loss: 30.0\n",
            "epoch: 64 [4500/8892 (51%)]\t training loss: 23.4\n",
            "epoch: 64 [5000/8892 (56%)]\t training loss: 31.7\n",
            "epoch: 64 [5500/8892 (62%)]\t training loss: 36.4\n",
            "epoch: 64 [6000/8892 (67%)]\t training loss: 28.0\n",
            "epoch: 64 [6500/8892 (73%)]\t training loss: 28.5\n",
            "epoch: 64 [7000/8892 (79%)]\t training loss: 30.3\n",
            "epoch: 64 [7500/8892 (84%)]\t training loss: 23.2\n",
            "epoch: 64 [8000/8892 (90%)]\t training loss: 26.9\n",
            "epoch: 64 [8500/8892 (96%)]\t training loss: 35.6\n",
            "\n",
            "Test dataset: Overall Loss: 1030.7,  (1.04%)\n",
            "\n",
            "epoch: 65 [0/8892 (0%)]\t training loss: 31.5\n",
            "epoch: 65 [500/8892 (6%)]\t training loss: 27.0\n",
            "epoch: 65 [1000/8892 (11%)]\t training loss: 29.0\n",
            "epoch: 65 [1500/8892 (17%)]\t training loss: 27.4\n",
            "epoch: 65 [2000/8892 (22%)]\t training loss: 30.7\n",
            "epoch: 65 [2500/8892 (28%)]\t training loss: 26.0\n",
            "epoch: 65 [3000/8892 (34%)]\t training loss: 21.2\n",
            "epoch: 65 [3500/8892 (39%)]\t training loss: 25.4\n",
            "epoch: 65 [4000/8892 (45%)]\t training loss: 29.3\n",
            "epoch: 65 [4500/8892 (51%)]\t training loss: 27.0\n",
            "epoch: 65 [5000/8892 (56%)]\t training loss: 31.5\n",
            "epoch: 65 [5500/8892 (62%)]\t training loss: 26.1\n",
            "epoch: 65 [6000/8892 (67%)]\t training loss: 25.5\n",
            "epoch: 65 [6500/8892 (73%)]\t training loss: 29.0\n",
            "epoch: 65 [7000/8892 (79%)]\t training loss: 24.8\n",
            "epoch: 65 [7500/8892 (84%)]\t training loss: 29.2\n",
            "epoch: 65 [8000/8892 (90%)]\t training loss: 36.3\n",
            "epoch: 65 [8500/8892 (96%)]\t training loss: 37.9\n",
            "\n",
            "Test dataset: Overall Loss: 1038.7,  (1.05%)\n",
            "\n",
            "epoch: 66 [0/8892 (0%)]\t training loss: 23.1\n",
            "epoch: 66 [500/8892 (6%)]\t training loss: 32.0\n",
            "epoch: 66 [1000/8892 (11%)]\t training loss: 23.5\n",
            "epoch: 66 [1500/8892 (17%)]\t training loss: 27.4\n",
            "epoch: 66 [2000/8892 (22%)]\t training loss: 37.2\n",
            "epoch: 66 [2500/8892 (28%)]\t training loss: 25.9\n",
            "epoch: 66 [3000/8892 (34%)]\t training loss: 23.9\n",
            "epoch: 66 [3500/8892 (39%)]\t training loss: 29.1\n",
            "epoch: 66 [4000/8892 (45%)]\t training loss: 26.3\n",
            "epoch: 66 [4500/8892 (51%)]\t training loss: 24.7\n",
            "epoch: 66 [5000/8892 (56%)]\t training loss: 33.9\n",
            "epoch: 66 [5500/8892 (62%)]\t training loss: 32.3\n",
            "epoch: 66 [6000/8892 (67%)]\t training loss: 26.7\n",
            "epoch: 66 [6500/8892 (73%)]\t training loss: 30.5\n",
            "epoch: 66 [7000/8892 (79%)]\t training loss: 21.8\n",
            "epoch: 66 [7500/8892 (84%)]\t training loss: 24.4\n",
            "epoch: 66 [8000/8892 (90%)]\t training loss: 35.6\n",
            "epoch: 66 [8500/8892 (96%)]\t training loss: 33.7\n",
            "\n",
            "Test dataset: Overall Loss: 1034.6,  (1.05%)\n",
            "\n",
            "epoch: 67 [0/8892 (0%)]\t training loss: 29.4\n",
            "epoch: 67 [500/8892 (6%)]\t training loss: 25.4\n",
            "epoch: 67 [1000/8892 (11%)]\t training loss: 29.2\n",
            "epoch: 67 [1500/8892 (17%)]\t training loss: 29.0\n",
            "epoch: 67 [2000/8892 (22%)]\t training loss: 27.8\n",
            "epoch: 67 [2500/8892 (28%)]\t training loss: 27.9\n",
            "epoch: 67 [3000/8892 (34%)]\t training loss: 27.6\n",
            "epoch: 67 [3500/8892 (39%)]\t training loss: 29.1\n",
            "epoch: 67 [4000/8892 (45%)]\t training loss: 28.4\n",
            "epoch: 67 [4500/8892 (51%)]\t training loss: 29.6\n",
            "epoch: 67 [5000/8892 (56%)]\t training loss: 25.7\n",
            "epoch: 67 [5500/8892 (62%)]\t training loss: 26.1\n",
            "epoch: 67 [6000/8892 (67%)]\t training loss: 23.8\n",
            "epoch: 67 [6500/8892 (73%)]\t training loss: 32.4\n",
            "epoch: 67 [7000/8892 (79%)]\t training loss: 20.5\n",
            "epoch: 67 [7500/8892 (84%)]\t training loss: 29.7\n",
            "epoch: 67 [8000/8892 (90%)]\t training loss: 24.6\n",
            "epoch: 67 [8500/8892 (96%)]\t training loss: 26.9\n",
            "\n",
            "Test dataset: Overall Loss: 1040.9,  (1.05%)\n",
            "\n",
            "epoch: 68 [0/8892 (0%)]\t training loss: 17.4\n",
            "epoch: 68 [500/8892 (6%)]\t training loss: 29.4\n",
            "epoch: 68 [1000/8892 (11%)]\t training loss: 26.5\n",
            "epoch: 68 [1500/8892 (17%)]\t training loss: 33.4\n",
            "epoch: 68 [2000/8892 (22%)]\t training loss: 21.5\n",
            "epoch: 68 [2500/8892 (28%)]\t training loss: 24.1\n",
            "epoch: 68 [3000/8892 (34%)]\t training loss: 31.2\n",
            "epoch: 68 [3500/8892 (39%)]\t training loss: 30.2\n",
            "epoch: 68 [4000/8892 (45%)]\t training loss: 32.1\n",
            "epoch: 68 [4500/8892 (51%)]\t training loss: 32.5\n",
            "epoch: 68 [5000/8892 (56%)]\t training loss: 33.7\n",
            "epoch: 68 [5500/8892 (62%)]\t training loss: 27.0\n",
            "epoch: 68 [6000/8892 (67%)]\t training loss: 23.0\n",
            "epoch: 68 [6500/8892 (73%)]\t training loss: 18.2\n",
            "epoch: 68 [7000/8892 (79%)]\t training loss: 21.6\n",
            "epoch: 68 [7500/8892 (84%)]\t training loss: 26.9\n",
            "epoch: 68 [8000/8892 (90%)]\t training loss: 35.1\n",
            "epoch: 68 [8500/8892 (96%)]\t training loss: 25.0\n",
            "\n",
            "Test dataset: Overall Loss: 1048.0,  (1.06%)\n",
            "\n",
            "epoch: 69 [0/8892 (0%)]\t training loss: 23.2\n",
            "epoch: 69 [500/8892 (6%)]\t training loss: 32.9\n",
            "epoch: 69 [1000/8892 (11%)]\t training loss: 24.1\n",
            "epoch: 69 [1500/8892 (17%)]\t training loss: 27.1\n",
            "epoch: 69 [2000/8892 (22%)]\t training loss: 26.0\n",
            "epoch: 69 [2500/8892 (28%)]\t training loss: 35.1\n",
            "epoch: 69 [3000/8892 (34%)]\t training loss: 19.5\n",
            "epoch: 69 [3500/8892 (39%)]\t training loss: 34.8\n",
            "epoch: 69 [4000/8892 (45%)]\t training loss: 30.2\n",
            "epoch: 69 [4500/8892 (51%)]\t training loss: 31.5\n",
            "epoch: 69 [5000/8892 (56%)]\t training loss: 25.9\n",
            "epoch: 69 [5500/8892 (62%)]\t training loss: 18.9\n",
            "epoch: 69 [6000/8892 (67%)]\t training loss: 30.6\n",
            "epoch: 69 [6500/8892 (73%)]\t training loss: 22.9\n",
            "epoch: 69 [7000/8892 (79%)]\t training loss: 24.6\n",
            "epoch: 69 [7500/8892 (84%)]\t training loss: 27.8\n",
            "epoch: 69 [8000/8892 (90%)]\t training loss: 27.2\n",
            "epoch: 69 [8500/8892 (96%)]\t training loss: 26.4\n",
            "\n",
            "Test dataset: Overall Loss: 1025.4,  (1.04%)\n",
            "\n",
            "epoch: 70 [0/8892 (0%)]\t training loss: 23.8\n",
            "epoch: 70 [500/8892 (6%)]\t training loss: 20.3\n",
            "epoch: 70 [1000/8892 (11%)]\t training loss: 29.0\n",
            "epoch: 70 [1500/8892 (17%)]\t training loss: 22.6\n",
            "epoch: 70 [2000/8892 (22%)]\t training loss: 28.4\n",
            "epoch: 70 [2500/8892 (28%)]\t training loss: 28.5\n",
            "epoch: 70 [3000/8892 (34%)]\t training loss: 26.1\n",
            "epoch: 70 [3500/8892 (39%)]\t training loss: 22.7\n",
            "epoch: 70 [4000/8892 (45%)]\t training loss: 25.4\n",
            "epoch: 70 [4500/8892 (51%)]\t training loss: 29.7\n",
            "epoch: 70 [5000/8892 (56%)]\t training loss: 32.0\n",
            "epoch: 70 [5500/8892 (62%)]\t training loss: 32.4\n",
            "epoch: 70 [6000/8892 (67%)]\t training loss: 29.5\n",
            "epoch: 70 [6500/8892 (73%)]\t training loss: 27.3\n",
            "epoch: 70 [7000/8892 (79%)]\t training loss: 30.9\n",
            "epoch: 70 [7500/8892 (84%)]\t training loss: 29.6\n",
            "epoch: 70 [8000/8892 (90%)]\t training loss: 29.5\n",
            "epoch: 70 [8500/8892 (96%)]\t training loss: 27.7\n",
            "\n",
            "Test dataset: Overall Loss: 1030.6,  (1.04%)\n",
            "\n",
            "epoch: 71 [0/8892 (0%)]\t training loss: 26.9\n",
            "epoch: 71 [500/8892 (6%)]\t training loss: 27.1\n",
            "epoch: 71 [1000/8892 (11%)]\t training loss: 27.3\n",
            "epoch: 71 [1500/8892 (17%)]\t training loss: 31.0\n",
            "epoch: 71 [2000/8892 (22%)]\t training loss: 26.2\n",
            "epoch: 71 [2500/8892 (28%)]\t training loss: 29.0\n",
            "epoch: 71 [3000/8892 (34%)]\t training loss: 28.5\n",
            "epoch: 71 [3500/8892 (39%)]\t training loss: 27.0\n",
            "epoch: 71 [4000/8892 (45%)]\t training loss: 28.3\n",
            "epoch: 71 [4500/8892 (51%)]\t training loss: 22.9\n",
            "epoch: 71 [5000/8892 (56%)]\t training loss: 22.9\n",
            "epoch: 71 [5500/8892 (62%)]\t training loss: 27.2\n",
            "epoch: 71 [6000/8892 (67%)]\t training loss: 26.9\n",
            "epoch: 71 [6500/8892 (73%)]\t training loss: 33.1\n",
            "epoch: 71 [7000/8892 (79%)]\t training loss: 32.2\n",
            "epoch: 71 [7500/8892 (84%)]\t training loss: 27.2\n",
            "epoch: 71 [8000/8892 (90%)]\t training loss: 29.5\n",
            "epoch: 71 [8500/8892 (96%)]\t training loss: 31.3\n",
            "\n",
            "Test dataset: Overall Loss: 1039.1,  (1.05%)\n",
            "\n",
            "epoch: 72 [0/8892 (0%)]\t training loss: 29.5\n",
            "epoch: 72 [500/8892 (6%)]\t training loss: 21.9\n",
            "epoch: 72 [1000/8892 (11%)]\t training loss: 24.8\n",
            "epoch: 72 [1500/8892 (17%)]\t training loss: 26.0\n",
            "epoch: 72 [2000/8892 (22%)]\t training loss: 26.5\n",
            "epoch: 72 [2500/8892 (28%)]\t training loss: 35.0\n",
            "epoch: 72 [3000/8892 (34%)]\t training loss: 35.4\n",
            "epoch: 72 [3500/8892 (39%)]\t training loss: 24.3\n",
            "epoch: 72 [4000/8892 (45%)]\t training loss: 22.6\n",
            "epoch: 72 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 72 [5000/8892 (56%)]\t training loss: 23.8\n",
            "epoch: 72 [5500/8892 (62%)]\t training loss: 28.7\n",
            "epoch: 72 [6000/8892 (67%)]\t training loss: 26.4\n",
            "epoch: 72 [6500/8892 (73%)]\t training loss: 30.6\n",
            "epoch: 72 [7000/8892 (79%)]\t training loss: 27.2\n",
            "epoch: 72 [7500/8892 (84%)]\t training loss: 24.4\n",
            "epoch: 72 [8000/8892 (90%)]\t training loss: 21.0\n",
            "epoch: 72 [8500/8892 (96%)]\t training loss: 31.1\n",
            "\n",
            "Test dataset: Overall Loss: 1033.2,  (1.05%)\n",
            "\n",
            "epoch: 73 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 73 [500/8892 (6%)]\t training loss: 29.2\n",
            "epoch: 73 [1000/8892 (11%)]\t training loss: 24.5\n",
            "epoch: 73 [1500/8892 (17%)]\t training loss: 29.2\n",
            "epoch: 73 [2000/8892 (22%)]\t training loss: 22.8\n",
            "epoch: 73 [2500/8892 (28%)]\t training loss: 30.5\n",
            "epoch: 73 [3000/8892 (34%)]\t training loss: 25.4\n",
            "epoch: 73 [3500/8892 (39%)]\t training loss: 27.7\n",
            "epoch: 73 [4000/8892 (45%)]\t training loss: 31.8\n",
            "epoch: 73 [4500/8892 (51%)]\t training loss: 22.9\n",
            "epoch: 73 [5000/8892 (56%)]\t training loss: 25.9\n",
            "epoch: 73 [5500/8892 (62%)]\t training loss: 22.1\n",
            "epoch: 73 [6000/8892 (67%)]\t training loss: 23.6\n",
            "epoch: 73 [6500/8892 (73%)]\t training loss: 26.2\n",
            "epoch: 73 [7000/8892 (79%)]\t training loss: 32.6\n",
            "epoch: 73 [7500/8892 (84%)]\t training loss: 24.0\n",
            "epoch: 73 [8000/8892 (90%)]\t training loss: 29.3\n",
            "epoch: 73 [8500/8892 (96%)]\t training loss: 22.3\n",
            "\n",
            "Test dataset: Overall Loss: 1035.4,  (1.05%)\n",
            "\n",
            "epoch: 74 [0/8892 (0%)]\t training loss: 21.2\n",
            "epoch: 74 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 74 [1000/8892 (11%)]\t training loss: 28.1\n",
            "epoch: 74 [1500/8892 (17%)]\t training loss: 27.1\n",
            "epoch: 74 [2000/8892 (22%)]\t training loss: 26.6\n",
            "epoch: 74 [2500/8892 (28%)]\t training loss: 19.3\n",
            "epoch: 74 [3000/8892 (34%)]\t training loss: 29.7\n",
            "epoch: 74 [3500/8892 (39%)]\t training loss: 31.4\n",
            "epoch: 74 [4000/8892 (45%)]\t training loss: 29.5\n",
            "epoch: 74 [4500/8892 (51%)]\t training loss: 31.3\n",
            "epoch: 74 [5000/8892 (56%)]\t training loss: 26.9\n",
            "epoch: 74 [5500/8892 (62%)]\t training loss: 36.6\n",
            "epoch: 74 [6000/8892 (67%)]\t training loss: 25.2\n",
            "epoch: 74 [6500/8892 (73%)]\t training loss: 22.3\n",
            "epoch: 74 [7000/8892 (79%)]\t training loss: 24.4\n",
            "epoch: 74 [7500/8892 (84%)]\t training loss: 25.7\n",
            "epoch: 74 [8000/8892 (90%)]\t training loss: 32.8\n",
            "epoch: 74 [8500/8892 (96%)]\t training loss: 27.2\n",
            "\n",
            "Test dataset: Overall Loss: 1038.0,  (1.05%)\n",
            "\n",
            "epoch: 75 [0/8892 (0%)]\t training loss: 21.3\n",
            "epoch: 75 [500/8892 (6%)]\t training loss: 25.1\n",
            "epoch: 75 [1000/8892 (11%)]\t training loss: 20.0\n",
            "epoch: 75 [1500/8892 (17%)]\t training loss: 24.1\n",
            "epoch: 75 [2000/8892 (22%)]\t training loss: 29.1\n",
            "epoch: 75 [2500/8892 (28%)]\t training loss: 27.8\n",
            "epoch: 75 [3000/8892 (34%)]\t training loss: 30.0\n",
            "epoch: 75 [3500/8892 (39%)]\t training loss: 26.4\n",
            "epoch: 75 [4000/8892 (45%)]\t training loss: 29.6\n",
            "epoch: 75 [4500/8892 (51%)]\t training loss: 26.2\n",
            "epoch: 75 [5000/8892 (56%)]\t training loss: 23.5\n",
            "epoch: 75 [5500/8892 (62%)]\t training loss: 31.8\n",
            "epoch: 75 [6000/8892 (67%)]\t training loss: 25.6\n",
            "epoch: 75 [6500/8892 (73%)]\t training loss: 24.8\n",
            "epoch: 75 [7000/8892 (79%)]\t training loss: 27.8\n",
            "epoch: 75 [7500/8892 (84%)]\t training loss: 29.0\n",
            "epoch: 75 [8000/8892 (90%)]\t training loss: 33.2\n",
            "epoch: 75 [8500/8892 (96%)]\t training loss: 22.2\n",
            "\n",
            "Test dataset: Overall Loss: 1035.3,  (1.05%)\n",
            "\n",
            "epoch: 76 [0/8892 (0%)]\t training loss: 22.5\n",
            "epoch: 76 [500/8892 (6%)]\t training loss: 22.8\n",
            "epoch: 76 [1000/8892 (11%)]\t training loss: 26.2\n",
            "epoch: 76 [1500/8892 (17%)]\t training loss: 26.6\n",
            "epoch: 76 [2000/8892 (22%)]\t training loss: 26.6\n",
            "epoch: 76 [2500/8892 (28%)]\t training loss: 24.9\n",
            "epoch: 76 [3000/8892 (34%)]\t training loss: 23.0\n",
            "epoch: 76 [3500/8892 (39%)]\t training loss: 24.4\n",
            "epoch: 76 [4000/8892 (45%)]\t training loss: 27.8\n",
            "epoch: 76 [4500/8892 (51%)]\t training loss: 23.7\n",
            "epoch: 76 [5000/8892 (56%)]\t training loss: 24.6\n",
            "epoch: 76 [5500/8892 (62%)]\t training loss: 25.1\n",
            "epoch: 76 [6000/8892 (67%)]\t training loss: 33.6\n",
            "epoch: 76 [6500/8892 (73%)]\t training loss: 23.4\n",
            "epoch: 76 [7000/8892 (79%)]\t training loss: 32.1\n",
            "epoch: 76 [7500/8892 (84%)]\t training loss: 31.5\n",
            "epoch: 76 [8000/8892 (90%)]\t training loss: 27.4\n",
            "epoch: 76 [8500/8892 (96%)]\t training loss: 22.4\n",
            "\n",
            "Test dataset: Overall Loss: 1039.9,  (1.05%)\n",
            "\n",
            "epoch: 77 [0/8892 (0%)]\t training loss: 20.2\n",
            "epoch: 77 [500/8892 (6%)]\t training loss: 26.8\n",
            "epoch: 77 [1000/8892 (11%)]\t training loss: 27.5\n",
            "epoch: 77 [1500/8892 (17%)]\t training loss: 24.6\n",
            "epoch: 77 [2000/8892 (22%)]\t training loss: 26.0\n",
            "epoch: 77 [2500/8892 (28%)]\t training loss: 23.8\n",
            "epoch: 77 [3000/8892 (34%)]\t training loss: 22.1\n",
            "epoch: 77 [3500/8892 (39%)]\t training loss: 27.7\n",
            "epoch: 77 [4000/8892 (45%)]\t training loss: 31.0\n",
            "epoch: 77 [4500/8892 (51%)]\t training loss: 26.1\n",
            "epoch: 77 [5000/8892 (56%)]\t training loss: 29.3\n",
            "epoch: 77 [5500/8892 (62%)]\t training loss: 25.4\n",
            "epoch: 77 [6000/8892 (67%)]\t training loss: 23.6\n",
            "epoch: 77 [6500/8892 (73%)]\t training loss: 22.1\n",
            "epoch: 77 [7000/8892 (79%)]\t training loss: 24.9\n",
            "epoch: 77 [7500/8892 (84%)]\t training loss: 36.6\n",
            "epoch: 77 [8000/8892 (90%)]\t training loss: 23.8\n",
            "epoch: 77 [8500/8892 (96%)]\t training loss: 24.0\n",
            "\n",
            "Test dataset: Overall Loss: 1039.8,  (1.05%)\n",
            "\n",
            "epoch: 78 [0/8892 (0%)]\t training loss: 23.7\n",
            "epoch: 78 [500/8892 (6%)]\t training loss: 31.8\n",
            "epoch: 78 [1000/8892 (11%)]\t training loss: 27.9\n",
            "epoch: 78 [1500/8892 (17%)]\t training loss: 19.2\n",
            "epoch: 78 [2000/8892 (22%)]\t training loss: 21.9\n",
            "epoch: 78 [2500/8892 (28%)]\t training loss: 24.7\n",
            "epoch: 78 [3000/8892 (34%)]\t training loss: 25.0\n",
            "epoch: 78 [3500/8892 (39%)]\t training loss: 22.4\n",
            "epoch: 78 [4000/8892 (45%)]\t training loss: 29.2\n",
            "epoch: 78 [4500/8892 (51%)]\t training loss: 25.7\n",
            "epoch: 78 [5000/8892 (56%)]\t training loss: 27.5\n",
            "epoch: 78 [5500/8892 (62%)]\t training loss: 28.1\n",
            "epoch: 78 [6000/8892 (67%)]\t training loss: 31.8\n",
            "epoch: 78 [6500/8892 (73%)]\t training loss: 30.4\n",
            "epoch: 78 [7000/8892 (79%)]\t training loss: 24.8\n",
            "epoch: 78 [7500/8892 (84%)]\t training loss: 27.0\n",
            "epoch: 78 [8000/8892 (90%)]\t training loss: 21.1\n",
            "epoch: 78 [8500/8892 (96%)]\t training loss: 27.1\n",
            "\n",
            "Test dataset: Overall Loss: 1029.3,  (1.04%)\n",
            "\n",
            "epoch: 79 [0/8892 (0%)]\t training loss: 24.2\n",
            "epoch: 79 [500/8892 (6%)]\t training loss: 24.3\n",
            "epoch: 79 [1000/8892 (11%)]\t training loss: 23.9\n",
            "epoch: 79 [1500/8892 (17%)]\t training loss: 25.7\n",
            "epoch: 79 [2000/8892 (22%)]\t training loss: 26.7\n",
            "epoch: 79 [2500/8892 (28%)]\t training loss: 23.7\n",
            "epoch: 79 [3000/8892 (34%)]\t training loss: 27.3\n",
            "epoch: 79 [3500/8892 (39%)]\t training loss: 36.1\n",
            "epoch: 79 [4000/8892 (45%)]\t training loss: 25.6\n",
            "epoch: 79 [4500/8892 (51%)]\t training loss: 21.6\n",
            "epoch: 79 [5000/8892 (56%)]\t training loss: 28.3\n",
            "epoch: 79 [5500/8892 (62%)]\t training loss: 29.7\n",
            "epoch: 79 [6000/8892 (67%)]\t training loss: 23.0\n",
            "epoch: 79 [6500/8892 (73%)]\t training loss: 24.1\n",
            "epoch: 79 [7000/8892 (79%)]\t training loss: 28.7\n",
            "epoch: 79 [7500/8892 (84%)]\t training loss: 26.1\n",
            "epoch: 79 [8000/8892 (90%)]\t training loss: 24.2\n",
            "epoch: 79 [8500/8892 (96%)]\t training loss: 32.2\n",
            "\n",
            "Test dataset: Overall Loss: 1042.6,  (1.06%)\n",
            "\n",
            "epoch: 80 [0/8892 (0%)]\t training loss: 21.1\n",
            "epoch: 80 [500/8892 (6%)]\t training loss: 27.8\n",
            "epoch: 80 [1000/8892 (11%)]\t training loss: 22.6\n",
            "epoch: 80 [1500/8892 (17%)]\t training loss: 21.7\n",
            "epoch: 80 [2000/8892 (22%)]\t training loss: 25.6\n",
            "epoch: 80 [2500/8892 (28%)]\t training loss: 24.1\n",
            "epoch: 80 [3000/8892 (34%)]\t training loss: 22.7\n",
            "epoch: 80 [3500/8892 (39%)]\t training loss: 30.2\n",
            "epoch: 80 [4000/8892 (45%)]\t training loss: 26.1\n",
            "epoch: 80 [4500/8892 (51%)]\t training loss: 28.9\n",
            "epoch: 80 [5000/8892 (56%)]\t training loss: 27.1\n",
            "epoch: 80 [5500/8892 (62%)]\t training loss: 30.8\n",
            "epoch: 80 [6000/8892 (67%)]\t training loss: 30.1\n",
            "epoch: 80 [6500/8892 (73%)]\t training loss: 21.8\n",
            "epoch: 80 [7000/8892 (79%)]\t training loss: 25.2\n",
            "epoch: 80 [7500/8892 (84%)]\t training loss: 32.0\n",
            "epoch: 80 [8000/8892 (90%)]\t training loss: 26.3\n",
            "epoch: 80 [8500/8892 (96%)]\t training loss: 25.8\n",
            "\n",
            "Test dataset: Overall Loss: 1035.4,  (1.05%)\n",
            "\n",
            "epoch: 81 [0/8892 (0%)]\t training loss: 25.4\n",
            "epoch: 81 [500/8892 (6%)]\t training loss: 23.5\n",
            "epoch: 81 [1000/8892 (11%)]\t training loss: 33.3\n",
            "epoch: 81 [1500/8892 (17%)]\t training loss: 25.4\n",
            "epoch: 81 [2000/8892 (22%)]\t training loss: 26.5\n",
            "epoch: 81 [2500/8892 (28%)]\t training loss: 26.0\n",
            "epoch: 81 [3000/8892 (34%)]\t training loss: 27.9\n",
            "epoch: 81 [3500/8892 (39%)]\t training loss: 26.1\n",
            "epoch: 81 [4000/8892 (45%)]\t training loss: 31.5\n",
            "epoch: 81 [4500/8892 (51%)]\t training loss: 27.9\n",
            "epoch: 81 [5000/8892 (56%)]\t training loss: 21.9\n",
            "epoch: 81 [5500/8892 (62%)]\t training loss: 23.2\n",
            "epoch: 81 [6000/8892 (67%)]\t training loss: 23.8\n",
            "epoch: 81 [6500/8892 (73%)]\t training loss: 27.2\n",
            "epoch: 81 [7000/8892 (79%)]\t training loss: 28.7\n",
            "epoch: 81 [7500/8892 (84%)]\t training loss: 33.2\n",
            "epoch: 81 [8000/8892 (90%)]\t training loss: 27.2\n",
            "epoch: 81 [8500/8892 (96%)]\t training loss: 28.3\n",
            "\n",
            "Test dataset: Overall Loss: 1040.6,  (1.05%)\n",
            "\n",
            "epoch: 82 [0/8892 (0%)]\t training loss: 21.6\n",
            "epoch: 82 [500/8892 (6%)]\t training loss: 33.2\n",
            "epoch: 82 [1000/8892 (11%)]\t training loss: 22.9\n",
            "epoch: 82 [1500/8892 (17%)]\t training loss: 25.3\n",
            "epoch: 82 [2000/8892 (22%)]\t training loss: 29.9\n",
            "epoch: 82 [2500/8892 (28%)]\t training loss: 23.2\n",
            "epoch: 82 [3000/8892 (34%)]\t training loss: 21.9\n",
            "epoch: 82 [3500/8892 (39%)]\t training loss: 31.3\n",
            "epoch: 82 [4000/8892 (45%)]\t training loss: 27.6\n",
            "epoch: 82 [4500/8892 (51%)]\t training loss: 21.5\n",
            "epoch: 82 [5000/8892 (56%)]\t training loss: 25.6\n",
            "epoch: 82 [5500/8892 (62%)]\t training loss: 26.4\n",
            "epoch: 82 [6000/8892 (67%)]\t training loss: 24.7\n",
            "epoch: 82 [6500/8892 (73%)]\t training loss: 24.7\n",
            "epoch: 82 [7000/8892 (79%)]\t training loss: 27.9\n",
            "epoch: 82 [7500/8892 (84%)]\t training loss: 25.6\n",
            "epoch: 82 [8000/8892 (90%)]\t training loss: 24.7\n",
            "epoch: 82 [8500/8892 (96%)]\t training loss: 36.4\n",
            "\n",
            "Test dataset: Overall Loss: 1031.4,  (1.04%)\n",
            "\n",
            "epoch: 83 [0/8892 (0%)]\t training loss: 24.9\n",
            "epoch: 83 [500/8892 (6%)]\t training loss: 27.9\n",
            "epoch: 83 [1000/8892 (11%)]\t training loss: 32.2\n",
            "epoch: 83 [1500/8892 (17%)]\t training loss: 22.9\n",
            "epoch: 83 [2000/8892 (22%)]\t training loss: 28.7\n",
            "epoch: 83 [2500/8892 (28%)]\t training loss: 25.2\n",
            "epoch: 83 [3000/8892 (34%)]\t training loss: 27.5\n",
            "epoch: 83 [3500/8892 (39%)]\t training loss: 23.7\n",
            "epoch: 83 [4000/8892 (45%)]\t training loss: 34.9\n",
            "epoch: 83 [4500/8892 (51%)]\t training loss: 24.1\n",
            "epoch: 83 [5000/8892 (56%)]\t training loss: 29.2\n",
            "epoch: 83 [5500/8892 (62%)]\t training loss: 29.1\n",
            "epoch: 83 [6000/8892 (67%)]\t training loss: 23.6\n",
            "epoch: 83 [6500/8892 (73%)]\t training loss: 27.9\n",
            "epoch: 83 [7000/8892 (79%)]\t training loss: 32.0\n",
            "epoch: 83 [7500/8892 (84%)]\t training loss: 22.6\n",
            "epoch: 83 [8000/8892 (90%)]\t training loss: 30.6\n",
            "epoch: 83 [8500/8892 (96%)]\t training loss: 28.6\n",
            "\n",
            "Test dataset: Overall Loss: 1042.0,  (1.05%)\n",
            "\n",
            "epoch: 84 [0/8892 (0%)]\t training loss: 26.8\n",
            "epoch: 84 [500/8892 (6%)]\t training loss: 24.4\n",
            "epoch: 84 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 84 [1500/8892 (17%)]\t training loss: 24.7\n",
            "epoch: 84 [2000/8892 (22%)]\t training loss: 42.8\n",
            "epoch: 84 [2500/8892 (28%)]\t training loss: 24.8\n",
            "epoch: 84 [3000/8892 (34%)]\t training loss: 23.6\n",
            "epoch: 84 [3500/8892 (39%)]\t training loss: 24.8\n",
            "epoch: 84 [4000/8892 (45%)]\t training loss: 21.7\n",
            "epoch: 84 [4500/8892 (51%)]\t training loss: 28.8\n",
            "epoch: 84 [5000/8892 (56%)]\t training loss: 22.2\n",
            "epoch: 84 [5500/8892 (62%)]\t training loss: 25.4\n",
            "epoch: 84 [6000/8892 (67%)]\t training loss: 25.4\n",
            "epoch: 84 [6500/8892 (73%)]\t training loss: 33.3\n",
            "epoch: 84 [7000/8892 (79%)]\t training loss: 25.5\n",
            "epoch: 84 [7500/8892 (84%)]\t training loss: 26.8\n",
            "epoch: 84 [8000/8892 (90%)]\t training loss: 25.8\n",
            "epoch: 84 [8500/8892 (96%)]\t training loss: 20.4\n",
            "\n",
            "Test dataset: Overall Loss: 1040.4,  (1.05%)\n",
            "\n",
            "epoch: 85 [0/8892 (0%)]\t training loss: 27.0\n",
            "epoch: 85 [500/8892 (6%)]\t training loss: 24.8\n",
            "epoch: 85 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 85 [1500/8892 (17%)]\t training loss: 28.2\n",
            "epoch: 85 [2000/8892 (22%)]\t training loss: 17.7\n",
            "epoch: 85 [2500/8892 (28%)]\t training loss: 25.0\n",
            "epoch: 85 [3000/8892 (34%)]\t training loss: 22.5\n",
            "epoch: 85 [3500/8892 (39%)]\t training loss: 32.7\n",
            "epoch: 85 [4000/8892 (45%)]\t training loss: 25.3\n",
            "epoch: 85 [4500/8892 (51%)]\t training loss: 27.5\n",
            "epoch: 85 [5000/8892 (56%)]\t training loss: 31.5\n",
            "epoch: 85 [5500/8892 (62%)]\t training loss: 25.0\n",
            "epoch: 85 [6000/8892 (67%)]\t training loss: 21.9\n",
            "epoch: 85 [6500/8892 (73%)]\t training loss: 33.0\n",
            "epoch: 85 [7000/8892 (79%)]\t training loss: 27.4\n",
            "epoch: 85 [7500/8892 (84%)]\t training loss: 32.6\n",
            "epoch: 85 [8000/8892 (90%)]\t training loss: 24.1\n",
            "epoch: 85 [8500/8892 (96%)]\t training loss: 27.0\n",
            "\n",
            "Test dataset: Overall Loss: 1034.2,  (1.05%)\n",
            "\n",
            "epoch: 86 [0/8892 (0%)]\t training loss: 29.7\n",
            "epoch: 86 [500/8892 (6%)]\t training loss: 29.9\n",
            "epoch: 86 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 86 [1500/8892 (17%)]\t training loss: 28.6\n",
            "epoch: 86 [2000/8892 (22%)]\t training loss: 30.8\n",
            "epoch: 86 [2500/8892 (28%)]\t training loss: 23.5\n",
            "epoch: 86 [3000/8892 (34%)]\t training loss: 23.2\n",
            "epoch: 86 [3500/8892 (39%)]\t training loss: 25.3\n",
            "epoch: 86 [4000/8892 (45%)]\t training loss: 23.7\n",
            "epoch: 86 [4500/8892 (51%)]\t training loss: 28.5\n",
            "epoch: 86 [5000/8892 (56%)]\t training loss: 27.6\n",
            "epoch: 86 [5500/8892 (62%)]\t training loss: 23.0\n",
            "epoch: 86 [6000/8892 (67%)]\t training loss: 29.6\n",
            "epoch: 86 [6500/8892 (73%)]\t training loss: 34.0\n",
            "epoch: 86 [7000/8892 (79%)]\t training loss: 25.8\n",
            "epoch: 86 [7500/8892 (84%)]\t training loss: 28.5\n",
            "epoch: 86 [8000/8892 (90%)]\t training loss: 28.0\n",
            "epoch: 86 [8500/8892 (96%)]\t training loss: 35.2\n",
            "\n",
            "Test dataset: Overall Loss: 1033.1,  (1.05%)\n",
            "\n",
            "epoch: 87 [0/8892 (0%)]\t training loss: 28.1\n",
            "epoch: 87 [500/8892 (6%)]\t training loss: 25.5\n",
            "epoch: 87 [1000/8892 (11%)]\t training loss: 21.4\n",
            "epoch: 87 [1500/8892 (17%)]\t training loss: 24.7\n",
            "epoch: 87 [2000/8892 (22%)]\t training loss: 26.6\n",
            "epoch: 87 [2500/8892 (28%)]\t training loss: 23.2\n",
            "epoch: 87 [3000/8892 (34%)]\t training loss: 26.0\n",
            "epoch: 87 [3500/8892 (39%)]\t training loss: 21.0\n",
            "epoch: 87 [4000/8892 (45%)]\t training loss: 32.0\n",
            "epoch: 87 [4500/8892 (51%)]\t training loss: 28.1\n",
            "epoch: 87 [5000/8892 (56%)]\t training loss: 26.7\n",
            "epoch: 87 [5500/8892 (62%)]\t training loss: 32.1\n",
            "epoch: 87 [6000/8892 (67%)]\t training loss: 26.0\n",
            "epoch: 87 [6500/8892 (73%)]\t training loss: 27.2\n",
            "epoch: 87 [7000/8892 (79%)]\t training loss: 25.1\n",
            "epoch: 87 [7500/8892 (84%)]\t training loss: 22.3\n",
            "epoch: 87 [8000/8892 (90%)]\t training loss: 25.4\n",
            "epoch: 87 [8500/8892 (96%)]\t training loss: 21.3\n",
            "\n",
            "Test dataset: Overall Loss: 1023.5,  (1.04%)\n",
            "\n",
            "epoch: 88 [0/8892 (0%)]\t training loss: 21.0\n",
            "epoch: 88 [500/8892 (6%)]\t training loss: 21.7\n",
            "epoch: 88 [1000/8892 (11%)]\t training loss: 20.4\n",
            "epoch: 88 [1500/8892 (17%)]\t training loss: 33.2\n",
            "epoch: 88 [2000/8892 (22%)]\t training loss: 25.5\n",
            "epoch: 88 [2500/8892 (28%)]\t training loss: 24.8\n",
            "epoch: 88 [3000/8892 (34%)]\t training loss: 31.9\n",
            "epoch: 88 [3500/8892 (39%)]\t training loss: 18.6\n",
            "epoch: 88 [4000/8892 (45%)]\t training loss: 17.5\n",
            "epoch: 88 [4500/8892 (51%)]\t training loss: 26.2\n",
            "epoch: 88 [5000/8892 (56%)]\t training loss: 29.7\n",
            "epoch: 88 [5500/8892 (62%)]\t training loss: 26.3\n",
            "epoch: 88 [6000/8892 (67%)]\t training loss: 28.4\n",
            "epoch: 88 [6500/8892 (73%)]\t training loss: 32.7\n",
            "epoch: 88 [7000/8892 (79%)]\t training loss: 22.3\n",
            "epoch: 88 [7500/8892 (84%)]\t training loss: 22.2\n",
            "epoch: 88 [8000/8892 (90%)]\t training loss: 23.9\n",
            "epoch: 88 [8500/8892 (96%)]\t training loss: 27.2\n",
            "\n",
            "Test dataset: Overall Loss: 1046.2,  (1.06%)\n",
            "\n",
            "epoch: 89 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 89 [500/8892 (6%)]\t training loss: 25.3\n",
            "epoch: 89 [1000/8892 (11%)]\t training loss: 33.7\n",
            "epoch: 89 [1500/8892 (17%)]\t training loss: 24.5\n",
            "epoch: 89 [2000/8892 (22%)]\t training loss: 28.3\n",
            "epoch: 89 [2500/8892 (28%)]\t training loss: 22.3\n",
            "epoch: 89 [3000/8892 (34%)]\t training loss: 25.3\n",
            "epoch: 89 [3500/8892 (39%)]\t training loss: 25.6\n",
            "epoch: 89 [4000/8892 (45%)]\t training loss: 27.8\n",
            "epoch: 89 [4500/8892 (51%)]\t training loss: 29.8\n",
            "epoch: 89 [5000/8892 (56%)]\t training loss: 30.7\n",
            "epoch: 89 [5500/8892 (62%)]\t training loss: 25.0\n",
            "epoch: 89 [6000/8892 (67%)]\t training loss: 24.1\n",
            "epoch: 89 [6500/8892 (73%)]\t training loss: 28.7\n",
            "epoch: 89 [7000/8892 (79%)]\t training loss: 25.6\n",
            "epoch: 89 [7500/8892 (84%)]\t training loss: 22.7\n",
            "epoch: 89 [8000/8892 (90%)]\t training loss: 29.4\n",
            "epoch: 89 [8500/8892 (96%)]\t training loss: 25.8\n",
            "\n",
            "Test dataset: Overall Loss: 1029.5,  (1.04%)\n",
            "\n",
            "epoch: 90 [0/8892 (0%)]\t training loss: 22.6\n",
            "epoch: 90 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 90 [1000/8892 (11%)]\t training loss: 22.6\n",
            "epoch: 90 [1500/8892 (17%)]\t training loss: 24.6\n",
            "epoch: 90 [2000/8892 (22%)]\t training loss: 26.8\n",
            "epoch: 90 [2500/8892 (28%)]\t training loss: 25.6\n",
            "epoch: 90 [3000/8892 (34%)]\t training loss: 20.4\n",
            "epoch: 90 [3500/8892 (39%)]\t training loss: 25.0\n",
            "epoch: 90 [4000/8892 (45%)]\t training loss: 28.4\n",
            "epoch: 90 [4500/8892 (51%)]\t training loss: 29.4\n",
            "epoch: 90 [5000/8892 (56%)]\t training loss: 24.1\n",
            "epoch: 90 [5500/8892 (62%)]\t training loss: 25.3\n",
            "epoch: 90 [6000/8892 (67%)]\t training loss: 17.7\n",
            "epoch: 90 [6500/8892 (73%)]\t training loss: 19.6\n",
            "epoch: 90 [7000/8892 (79%)]\t training loss: 27.4\n",
            "epoch: 90 [7500/8892 (84%)]\t training loss: 27.8\n",
            "epoch: 90 [8000/8892 (90%)]\t training loss: 26.7\n",
            "epoch: 90 [8500/8892 (96%)]\t training loss: 29.5\n",
            "\n",
            "Test dataset: Overall Loss: 1033.7,  (1.05%)\n",
            "\n",
            "epoch: 91 [0/8892 (0%)]\t training loss: 30.5\n",
            "epoch: 91 [500/8892 (6%)]\t training loss: 22.3\n",
            "epoch: 91 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 91 [1500/8892 (17%)]\t training loss: 25.6\n",
            "epoch: 91 [2000/8892 (22%)]\t training loss: 25.3\n",
            "epoch: 91 [2500/8892 (28%)]\t training loss: 24.5\n",
            "epoch: 91 [3000/8892 (34%)]\t training loss: 26.4\n",
            "epoch: 91 [3500/8892 (39%)]\t training loss: 28.5\n",
            "epoch: 91 [4000/8892 (45%)]\t training loss: 29.8\n",
            "epoch: 91 [4500/8892 (51%)]\t training loss: 24.1\n",
            "epoch: 91 [5000/8892 (56%)]\t training loss: 25.6\n",
            "epoch: 91 [5500/8892 (62%)]\t training loss: 23.4\n",
            "epoch: 91 [6000/8892 (67%)]\t training loss: 22.2\n",
            "epoch: 91 [6500/8892 (73%)]\t training loss: 22.9\n",
            "epoch: 91 [7000/8892 (79%)]\t training loss: 28.1\n",
            "epoch: 91 [7500/8892 (84%)]\t training loss: 24.3\n",
            "epoch: 91 [8000/8892 (90%)]\t training loss: 26.1\n",
            "epoch: 91 [8500/8892 (96%)]\t training loss: 32.4\n",
            "\n",
            "Test dataset: Overall Loss: 1035.2,  (1.05%)\n",
            "\n",
            "epoch: 92 [0/8892 (0%)]\t training loss: 21.0\n",
            "epoch: 92 [500/8892 (6%)]\t training loss: 30.5\n",
            "epoch: 92 [1000/8892 (11%)]\t training loss: 20.5\n",
            "epoch: 92 [1500/8892 (17%)]\t training loss: 23.7\n",
            "epoch: 92 [2000/8892 (22%)]\t training loss: 25.8\n",
            "epoch: 92 [2500/8892 (28%)]\t training loss: 26.2\n",
            "epoch: 92 [3000/8892 (34%)]\t training loss: 27.8\n",
            "epoch: 92 [3500/8892 (39%)]\t training loss: 21.0\n",
            "epoch: 92 [4000/8892 (45%)]\t training loss: 23.9\n",
            "epoch: 92 [4500/8892 (51%)]\t training loss: 29.2\n",
            "epoch: 92 [5000/8892 (56%)]\t training loss: 31.0\n",
            "epoch: 92 [5500/8892 (62%)]\t training loss: 30.1\n",
            "epoch: 92 [6000/8892 (67%)]\t training loss: 31.6\n",
            "epoch: 92 [6500/8892 (73%)]\t training loss: 23.1\n",
            "epoch: 92 [7000/8892 (79%)]\t training loss: 27.7\n",
            "epoch: 92 [7500/8892 (84%)]\t training loss: 27.4\n",
            "epoch: 92 [8000/8892 (90%)]\t training loss: 27.2\n",
            "epoch: 92 [8500/8892 (96%)]\t training loss: 35.1\n",
            "\n",
            "Test dataset: Overall Loss: 1037.4,  (1.05%)\n",
            "\n",
            "epoch: 93 [0/8892 (0%)]\t training loss: 20.1\n",
            "epoch: 93 [500/8892 (6%)]\t training loss: 26.7\n",
            "epoch: 93 [1000/8892 (11%)]\t training loss: 24.8\n",
            "epoch: 93 [1500/8892 (17%)]\t training loss: 22.5\n",
            "epoch: 93 [2000/8892 (22%)]\t training loss: 31.7\n",
            "epoch: 93 [2500/8892 (28%)]\t training loss: 26.6\n",
            "epoch: 93 [3000/8892 (34%)]\t training loss: 36.4\n",
            "epoch: 93 [3500/8892 (39%)]\t training loss: 28.8\n",
            "epoch: 93 [4000/8892 (45%)]\t training loss: 31.6\n",
            "epoch: 93 [4500/8892 (51%)]\t training loss: 23.7\n",
            "epoch: 93 [5000/8892 (56%)]\t training loss: 23.7\n",
            "epoch: 93 [5500/8892 (62%)]\t training loss: 25.0\n",
            "epoch: 93 [6000/8892 (67%)]\t training loss: 31.6\n",
            "epoch: 93 [6500/8892 (73%)]\t training loss: 28.6\n",
            "epoch: 93 [7000/8892 (79%)]\t training loss: 22.7\n",
            "epoch: 93 [7500/8892 (84%)]\t training loss: 25.3\n",
            "epoch: 93 [8000/8892 (90%)]\t training loss: 35.0\n",
            "epoch: 93 [8500/8892 (96%)]\t training loss: 28.0\n",
            "\n",
            "Test dataset: Overall Loss: 1039.8,  (1.05%)\n",
            "\n",
            "epoch: 94 [0/8892 (0%)]\t training loss: 30.6\n",
            "epoch: 94 [500/8892 (6%)]\t training loss: 28.5\n",
            "epoch: 94 [1000/8892 (11%)]\t training loss: 22.8\n",
            "epoch: 94 [1500/8892 (17%)]\t training loss: 25.8\n",
            "epoch: 94 [2000/8892 (22%)]\t training loss: 24.8\n",
            "epoch: 94 [2500/8892 (28%)]\t training loss: 19.9\n",
            "epoch: 94 [3000/8892 (34%)]\t training loss: 27.2\n",
            "epoch: 94 [3500/8892 (39%)]\t training loss: 22.6\n",
            "epoch: 94 [4000/8892 (45%)]\t training loss: 31.3\n",
            "epoch: 94 [4500/8892 (51%)]\t training loss: 31.3\n",
            "epoch: 94 [5000/8892 (56%)]\t training loss: 21.7\n",
            "epoch: 94 [5500/8892 (62%)]\t training loss: 27.9\n",
            "epoch: 94 [6000/8892 (67%)]\t training loss: 27.4\n",
            "epoch: 94 [6500/8892 (73%)]\t training loss: 28.0\n",
            "epoch: 94 [7000/8892 (79%)]\t training loss: 25.0\n",
            "epoch: 94 [7500/8892 (84%)]\t training loss: 37.0\n",
            "epoch: 94 [8000/8892 (90%)]\t training loss: 23.9\n",
            "epoch: 94 [8500/8892 (96%)]\t training loss: 22.2\n",
            "\n",
            "Test dataset: Overall Loss: 1018.6,  (1.03%)\n",
            "\n",
            "epoch: 95 [0/8892 (0%)]\t training loss: 26.2\n",
            "epoch: 95 [500/8892 (6%)]\t training loss: 23.9\n",
            "epoch: 95 [1000/8892 (11%)]\t training loss: 23.0\n",
            "epoch: 95 [1500/8892 (17%)]\t training loss: 16.4\n",
            "epoch: 95 [2000/8892 (22%)]\t training loss: 31.0\n",
            "epoch: 95 [2500/8892 (28%)]\t training loss: 24.7\n",
            "epoch: 95 [3000/8892 (34%)]\t training loss: 21.8\n",
            "epoch: 95 [3500/8892 (39%)]\t training loss: 19.0\n",
            "epoch: 95 [4000/8892 (45%)]\t training loss: 23.2\n",
            "epoch: 95 [4500/8892 (51%)]\t training loss: 26.4\n",
            "epoch: 95 [5000/8892 (56%)]\t training loss: 24.5\n",
            "epoch: 95 [5500/8892 (62%)]\t training loss: 26.4\n",
            "epoch: 95 [6000/8892 (67%)]\t training loss: 29.1\n",
            "epoch: 95 [6500/8892 (73%)]\t training loss: 26.3\n",
            "epoch: 95 [7000/8892 (79%)]\t training loss: 32.9\n",
            "epoch: 95 [7500/8892 (84%)]\t training loss: 30.0\n",
            "epoch: 95 [8000/8892 (90%)]\t training loss: 25.7\n",
            "epoch: 95 [8500/8892 (96%)]\t training loss: 27.3\n",
            "\n",
            "Test dataset: Overall Loss: 1038.7,  (1.05%)\n",
            "\n",
            "epoch: 96 [0/8892 (0%)]\t training loss: 25.1\n",
            "epoch: 96 [500/8892 (6%)]\t training loss: 27.1\n",
            "epoch: 96 [1000/8892 (11%)]\t training loss: 33.1\n",
            "epoch: 96 [1500/8892 (17%)]\t training loss: 18.5\n",
            "epoch: 96 [2000/8892 (22%)]\t training loss: 23.5\n",
            "epoch: 96 [2500/8892 (28%)]\t training loss: 24.5\n",
            "epoch: 96 [3000/8892 (34%)]\t training loss: 26.5\n",
            "epoch: 96 [3500/8892 (39%)]\t training loss: 20.3\n",
            "epoch: 96 [4000/8892 (45%)]\t training loss: 26.2\n",
            "epoch: 96 [4500/8892 (51%)]\t training loss: 24.9\n",
            "epoch: 96 [5000/8892 (56%)]\t training loss: 28.1\n",
            "epoch: 96 [5500/8892 (62%)]\t training loss: 21.7\n",
            "epoch: 96 [6000/8892 (67%)]\t training loss: 30.4\n",
            "epoch: 96 [6500/8892 (73%)]\t training loss: 25.5\n",
            "epoch: 96 [7000/8892 (79%)]\t training loss: 24.3\n",
            "epoch: 96 [7500/8892 (84%)]\t training loss: 25.2\n",
            "epoch: 96 [8000/8892 (90%)]\t training loss: 30.5\n",
            "epoch: 96 [8500/8892 (96%)]\t training loss: 22.0\n",
            "\n",
            "Test dataset: Overall Loss: 1031.3,  (1.04%)\n",
            "\n",
            "epoch: 97 [0/8892 (0%)]\t training loss: 28.1\n",
            "epoch: 97 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 97 [1000/8892 (11%)]\t training loss: 23.7\n",
            "epoch: 97 [1500/8892 (17%)]\t training loss: 24.0\n",
            "epoch: 97 [2000/8892 (22%)]\t training loss: 25.6\n",
            "epoch: 97 [2500/8892 (28%)]\t training loss: 24.2\n",
            "epoch: 97 [3000/8892 (34%)]\t training loss: 23.7\n",
            "epoch: 97 [3500/8892 (39%)]\t training loss: 18.5\n",
            "epoch: 97 [4000/8892 (45%)]\t training loss: 25.5\n",
            "epoch: 97 [4500/8892 (51%)]\t training loss: 23.8\n",
            "epoch: 97 [5000/8892 (56%)]\t training loss: 25.8\n",
            "epoch: 97 [5500/8892 (62%)]\t training loss: 18.0\n",
            "epoch: 97 [6000/8892 (67%)]\t training loss: 33.8\n",
            "epoch: 97 [6500/8892 (73%)]\t training loss: 30.7\n",
            "epoch: 97 [7000/8892 (79%)]\t training loss: 28.8\n",
            "epoch: 97 [7500/8892 (84%)]\t training loss: 33.2\n",
            "epoch: 97 [8000/8892 (90%)]\t training loss: 21.7\n",
            "epoch: 97 [8500/8892 (96%)]\t training loss: 27.9\n",
            "\n",
            "Test dataset: Overall Loss: 1035.4,  (1.05%)\n",
            "\n",
            "epoch: 98 [0/8892 (0%)]\t training loss: 28.6\n",
            "epoch: 98 [500/8892 (6%)]\t training loss: 25.6\n",
            "epoch: 98 [1000/8892 (11%)]\t training loss: 32.5\n",
            "epoch: 98 [1500/8892 (17%)]\t training loss: 34.0\n",
            "epoch: 98 [2000/8892 (22%)]\t training loss: 28.1\n",
            "epoch: 98 [2500/8892 (28%)]\t training loss: 28.5\n",
            "epoch: 98 [3000/8892 (34%)]\t training loss: 25.9\n",
            "epoch: 98 [3500/8892 (39%)]\t training loss: 27.9\n",
            "epoch: 98 [4000/8892 (45%)]\t training loss: 22.3\n",
            "epoch: 98 [4500/8892 (51%)]\t training loss: 34.9\n",
            "epoch: 98 [5000/8892 (56%)]\t training loss: 25.1\n",
            "epoch: 98 [5500/8892 (62%)]\t training loss: 23.3\n",
            "epoch: 98 [6000/8892 (67%)]\t training loss: 25.6\n",
            "epoch: 98 [6500/8892 (73%)]\t training loss: 32.1\n",
            "epoch: 98 [7000/8892 (79%)]\t training loss: 26.8\n",
            "epoch: 98 [7500/8892 (84%)]\t training loss: 21.7\n",
            "epoch: 98 [8000/8892 (90%)]\t training loss: 20.6\n",
            "epoch: 98 [8500/8892 (96%)]\t training loss: 21.2\n",
            "\n",
            "Test dataset: Overall Loss: 1030.6,  (1.04%)\n",
            "\n",
            "epoch: 99 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 99 [500/8892 (6%)]\t training loss: 27.6\n",
            "epoch: 99 [1000/8892 (11%)]\t training loss: 27.3\n",
            "epoch: 99 [1500/8892 (17%)]\t training loss: 26.6\n",
            "epoch: 99 [2000/8892 (22%)]\t training loss: 23.5\n",
            "epoch: 99 [2500/8892 (28%)]\t training loss: 23.0\n",
            "epoch: 99 [3000/8892 (34%)]\t training loss: 19.7\n",
            "epoch: 99 [3500/8892 (39%)]\t training loss: 31.5\n",
            "epoch: 99 [4000/8892 (45%)]\t training loss: 28.4\n",
            "epoch: 99 [4500/8892 (51%)]\t training loss: 21.0\n",
            "epoch: 99 [5000/8892 (56%)]\t training loss: 21.5\n",
            "epoch: 99 [5500/8892 (62%)]\t training loss: 28.9\n",
            "epoch: 99 [6000/8892 (67%)]\t training loss: 25.9\n",
            "epoch: 99 [6500/8892 (73%)]\t training loss: 27.2\n",
            "epoch: 99 [7000/8892 (79%)]\t training loss: 27.3\n",
            "epoch: 99 [7500/8892 (84%)]\t training loss: 26.9\n",
            "epoch: 99 [8000/8892 (90%)]\t training loss: 28.0\n",
            "epoch: 99 [8500/8892 (96%)]\t training loss: 28.0\n",
            "\n",
            "Test dataset: Overall Loss: 1032.4,  (1.04%)\n",
            "\n",
            "epoch: 100 [0/8892 (0%)]\t training loss: 28.3\n",
            "epoch: 100 [500/8892 (6%)]\t training loss: 23.7\n",
            "epoch: 100 [1000/8892 (11%)]\t training loss: 26.9\n",
            "epoch: 100 [1500/8892 (17%)]\t training loss: 21.2\n",
            "epoch: 100 [2000/8892 (22%)]\t training loss: 25.5\n",
            "epoch: 100 [2500/8892 (28%)]\t training loss: 25.2\n",
            "epoch: 100 [3000/8892 (34%)]\t training loss: 20.6\n",
            "epoch: 100 [3500/8892 (39%)]\t training loss: 23.2\n",
            "epoch: 100 [4000/8892 (45%)]\t training loss: 32.1\n",
            "epoch: 100 [4500/8892 (51%)]\t training loss: 25.9\n",
            "epoch: 100 [5000/8892 (56%)]\t training loss: 30.2\n",
            "epoch: 100 [5500/8892 (62%)]\t training loss: 31.2\n",
            "epoch: 100 [6000/8892 (67%)]\t training loss: 26.1\n",
            "epoch: 100 [6500/8892 (73%)]\t training loss: 25.9\n",
            "epoch: 100 [7000/8892 (79%)]\t training loss: 23.0\n",
            "epoch: 100 [7500/8892 (84%)]\t training loss: 30.7\n",
            "epoch: 100 [8000/8892 (90%)]\t training loss: 24.8\n",
            "epoch: 100 [8500/8892 (96%)]\t training loss: 24.6\n",
            "\n",
            "Test dataset: Overall Loss: 1035.0,  (1.05%)\n",
            "\n",
            "epoch: 101 [0/8892 (0%)]\t training loss: 27.0\n",
            "epoch: 101 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 101 [1000/8892 (11%)]\t training loss: 22.7\n",
            "epoch: 101 [1500/8892 (17%)]\t training loss: 32.8\n",
            "epoch: 101 [2000/8892 (22%)]\t training loss: 24.7\n",
            "epoch: 101 [2500/8892 (28%)]\t training loss: 34.7\n",
            "epoch: 101 [3000/8892 (34%)]\t training loss: 26.2\n",
            "epoch: 101 [3500/8892 (39%)]\t training loss: 24.6\n",
            "epoch: 101 [4000/8892 (45%)]\t training loss: 22.6\n",
            "epoch: 101 [4500/8892 (51%)]\t training loss: 29.6\n",
            "epoch: 101 [5000/8892 (56%)]\t training loss: 22.6\n",
            "epoch: 101 [5500/8892 (62%)]\t training loss: 27.7\n",
            "epoch: 101 [6000/8892 (67%)]\t training loss: 34.0\n",
            "epoch: 101 [6500/8892 (73%)]\t training loss: 29.0\n",
            "epoch: 101 [7000/8892 (79%)]\t training loss: 28.8\n",
            "epoch: 101 [7500/8892 (84%)]\t training loss: 36.3\n",
            "epoch: 101 [8000/8892 (90%)]\t training loss: 28.7\n",
            "epoch: 101 [8500/8892 (96%)]\t training loss: 24.1\n",
            "\n",
            "Test dataset: Overall Loss: 1032.1,  (1.04%)\n",
            "\n",
            "epoch: 102 [0/8892 (0%)]\t training loss: 24.7\n",
            "epoch: 102 [500/8892 (6%)]\t training loss: 29.1\n",
            "epoch: 102 [1000/8892 (11%)]\t training loss: 27.6\n",
            "epoch: 102 [1500/8892 (17%)]\t training loss: 24.9\n",
            "epoch: 102 [2000/8892 (22%)]\t training loss: 28.5\n",
            "epoch: 102 [2500/8892 (28%)]\t training loss: 27.6\n",
            "epoch: 102 [3000/8892 (34%)]\t training loss: 37.6\n",
            "epoch: 102 [3500/8892 (39%)]\t training loss: 23.8\n",
            "epoch: 102 [4000/8892 (45%)]\t training loss: 28.1\n",
            "epoch: 102 [4500/8892 (51%)]\t training loss: 28.6\n",
            "epoch: 102 [5000/8892 (56%)]\t training loss: 30.9\n",
            "epoch: 102 [5500/8892 (62%)]\t training loss: 27.0\n",
            "epoch: 102 [6000/8892 (67%)]\t training loss: 27.1\n",
            "epoch: 102 [6500/8892 (73%)]\t training loss: 21.4\n",
            "epoch: 102 [7000/8892 (79%)]\t training loss: 31.2\n",
            "epoch: 102 [7500/8892 (84%)]\t training loss: 25.5\n",
            "epoch: 102 [8000/8892 (90%)]\t training loss: 21.8\n",
            "epoch: 102 [8500/8892 (96%)]\t training loss: 25.9\n",
            "\n",
            "Test dataset: Overall Loss: 1029.7,  (1.04%)\n",
            "\n",
            "epoch: 103 [0/8892 (0%)]\t training loss: 26.1\n",
            "epoch: 103 [500/8892 (6%)]\t training loss: 26.0\n",
            "epoch: 103 [1000/8892 (11%)]\t training loss: 17.8\n",
            "epoch: 103 [1500/8892 (17%)]\t training loss: 30.5\n",
            "epoch: 103 [2000/8892 (22%)]\t training loss: 27.2\n",
            "epoch: 103 [2500/8892 (28%)]\t training loss: 34.3\n",
            "epoch: 103 [3000/8892 (34%)]\t training loss: 20.6\n",
            "epoch: 103 [3500/8892 (39%)]\t training loss: 29.7\n",
            "epoch: 103 [4000/8892 (45%)]\t training loss: 26.7\n",
            "epoch: 103 [4500/8892 (51%)]\t training loss: 20.7\n",
            "epoch: 103 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 103 [5500/8892 (62%)]\t training loss: 21.6\n",
            "epoch: 103 [6000/8892 (67%)]\t training loss: 28.8\n",
            "epoch: 103 [6500/8892 (73%)]\t training loss: 32.9\n",
            "epoch: 103 [7000/8892 (79%)]\t training loss: 21.0\n",
            "epoch: 103 [7500/8892 (84%)]\t training loss: 26.9\n",
            "epoch: 103 [8000/8892 (90%)]\t training loss: 29.5\n",
            "epoch: 103 [8500/8892 (96%)]\t training loss: 26.3\n",
            "\n",
            "Test dataset: Overall Loss: 1029.1,  (1.04%)\n",
            "\n",
            "epoch: 104 [0/8892 (0%)]\t training loss: 27.7\n",
            "epoch: 104 [500/8892 (6%)]\t training loss: 25.7\n",
            "epoch: 104 [1000/8892 (11%)]\t training loss: 33.2\n",
            "epoch: 104 [1500/8892 (17%)]\t training loss: 25.5\n",
            "epoch: 104 [2000/8892 (22%)]\t training loss: 27.1\n",
            "epoch: 104 [2500/8892 (28%)]\t training loss: 25.0\n",
            "epoch: 104 [3000/8892 (34%)]\t training loss: 22.5\n",
            "epoch: 104 [3500/8892 (39%)]\t training loss: 27.5\n",
            "epoch: 104 [4000/8892 (45%)]\t training loss: 29.5\n",
            "epoch: 104 [4500/8892 (51%)]\t training loss: 22.8\n",
            "epoch: 104 [5000/8892 (56%)]\t training loss: 23.0\n",
            "epoch: 104 [5500/8892 (62%)]\t training loss: 28.4\n",
            "epoch: 104 [6000/8892 (67%)]\t training loss: 25.6\n",
            "epoch: 104 [6500/8892 (73%)]\t training loss: 20.3\n",
            "epoch: 104 [7000/8892 (79%)]\t training loss: 20.3\n",
            "epoch: 104 [7500/8892 (84%)]\t training loss: 29.4\n",
            "epoch: 104 [8000/8892 (90%)]\t training loss: 26.5\n",
            "epoch: 104 [8500/8892 (96%)]\t training loss: 28.6\n",
            "\n",
            "Test dataset: Overall Loss: 1032.3,  (1.04%)\n",
            "\n",
            "epoch: 105 [0/8892 (0%)]\t training loss: 27.5\n",
            "epoch: 105 [500/8892 (6%)]\t training loss: 20.4\n",
            "epoch: 105 [1000/8892 (11%)]\t training loss: 21.7\n",
            "epoch: 105 [1500/8892 (17%)]\t training loss: 21.4\n",
            "epoch: 105 [2000/8892 (22%)]\t training loss: 31.7\n",
            "epoch: 105 [2500/8892 (28%)]\t training loss: 29.1\n",
            "epoch: 105 [3000/8892 (34%)]\t training loss: 26.4\n",
            "epoch: 105 [3500/8892 (39%)]\t training loss: 24.9\n",
            "epoch: 105 [4000/8892 (45%)]\t training loss: 24.7\n",
            "epoch: 105 [4500/8892 (51%)]\t training loss: 28.4\n",
            "epoch: 105 [5000/8892 (56%)]\t training loss: 27.6\n",
            "epoch: 105 [5500/8892 (62%)]\t training loss: 26.4\n",
            "epoch: 105 [6000/8892 (67%)]\t training loss: 21.8\n",
            "epoch: 105 [6500/8892 (73%)]\t training loss: 24.4\n",
            "epoch: 105 [7000/8892 (79%)]\t training loss: 25.0\n",
            "epoch: 105 [7500/8892 (84%)]\t training loss: 20.5\n",
            "epoch: 105 [8000/8892 (90%)]\t training loss: 28.8\n",
            "epoch: 105 [8500/8892 (96%)]\t training loss: 22.5\n",
            "\n",
            "Test dataset: Overall Loss: 1037.5,  (1.05%)\n",
            "\n",
            "epoch: 106 [0/8892 (0%)]\t training loss: 27.5\n",
            "epoch: 106 [500/8892 (6%)]\t training loss: 23.3\n",
            "epoch: 106 [1000/8892 (11%)]\t training loss: 25.1\n",
            "epoch: 106 [1500/8892 (17%)]\t training loss: 24.8\n",
            "epoch: 106 [2000/8892 (22%)]\t training loss: 22.2\n",
            "epoch: 106 [2500/8892 (28%)]\t training loss: 31.2\n",
            "epoch: 106 [3000/8892 (34%)]\t training loss: 29.2\n",
            "epoch: 106 [3500/8892 (39%)]\t training loss: 27.9\n",
            "epoch: 106 [4000/8892 (45%)]\t training loss: 25.0\n",
            "epoch: 106 [4500/8892 (51%)]\t training loss: 26.2\n",
            "epoch: 106 [5000/8892 (56%)]\t training loss: 21.9\n",
            "epoch: 106 [5500/8892 (62%)]\t training loss: 18.5\n",
            "epoch: 106 [6000/8892 (67%)]\t training loss: 22.5\n",
            "epoch: 106 [6500/8892 (73%)]\t training loss: 19.8\n",
            "epoch: 106 [7000/8892 (79%)]\t training loss: 32.8\n",
            "epoch: 106 [7500/8892 (84%)]\t training loss: 16.8\n",
            "epoch: 106 [8000/8892 (90%)]\t training loss: 26.5\n",
            "epoch: 106 [8500/8892 (96%)]\t training loss: 22.9\n",
            "\n",
            "Test dataset: Overall Loss: 1039.6,  (1.05%)\n",
            "\n",
            "epoch: 107 [0/8892 (0%)]\t training loss: 24.9\n",
            "epoch: 107 [500/8892 (6%)]\t training loss: 28.6\n",
            "epoch: 107 [1000/8892 (11%)]\t training loss: 24.4\n",
            "epoch: 107 [1500/8892 (17%)]\t training loss: 31.7\n",
            "epoch: 107 [2000/8892 (22%)]\t training loss: 31.4\n",
            "epoch: 107 [2500/8892 (28%)]\t training loss: 27.0\n",
            "epoch: 107 [3000/8892 (34%)]\t training loss: 25.0\n",
            "epoch: 107 [3500/8892 (39%)]\t training loss: 22.3\n",
            "epoch: 107 [4000/8892 (45%)]\t training loss: 29.6\n",
            "epoch: 107 [4500/8892 (51%)]\t training loss: 29.2\n",
            "epoch: 107 [5000/8892 (56%)]\t training loss: 26.7\n",
            "epoch: 107 [5500/8892 (62%)]\t training loss: 17.6\n",
            "epoch: 107 [6000/8892 (67%)]\t training loss: 22.8\n",
            "epoch: 107 [6500/8892 (73%)]\t training loss: 34.1\n",
            "epoch: 107 [7000/8892 (79%)]\t training loss: 22.8\n",
            "epoch: 107 [7500/8892 (84%)]\t training loss: 28.8\n",
            "epoch: 107 [8000/8892 (90%)]\t training loss: 26.1\n",
            "epoch: 107 [8500/8892 (96%)]\t training loss: 20.0\n",
            "\n",
            "Test dataset: Overall Loss: 1035.9,  (1.05%)\n",
            "\n",
            "epoch: 108 [0/8892 (0%)]\t training loss: 28.4\n",
            "epoch: 108 [500/8892 (6%)]\t training loss: 20.8\n",
            "epoch: 108 [1000/8892 (11%)]\t training loss: 20.5\n",
            "epoch: 108 [1500/8892 (17%)]\t training loss: 23.5\n",
            "epoch: 108 [2000/8892 (22%)]\t training loss: 21.6\n",
            "epoch: 108 [2500/8892 (28%)]\t training loss: 27.4\n",
            "epoch: 108 [3000/8892 (34%)]\t training loss: 17.7\n",
            "epoch: 108 [3500/8892 (39%)]\t training loss: 31.6\n",
            "epoch: 108 [4000/8892 (45%)]\t training loss: 28.6\n",
            "epoch: 108 [4500/8892 (51%)]\t training loss: 28.4\n",
            "epoch: 108 [5000/8892 (56%)]\t training loss: 34.9\n",
            "epoch: 108 [5500/8892 (62%)]\t training loss: 21.7\n",
            "epoch: 108 [6000/8892 (67%)]\t training loss: 32.5\n",
            "epoch: 108 [6500/8892 (73%)]\t training loss: 25.1\n",
            "epoch: 108 [7000/8892 (79%)]\t training loss: 28.1\n",
            "epoch: 108 [7500/8892 (84%)]\t training loss: 29.5\n",
            "epoch: 108 [8000/8892 (90%)]\t training loss: 23.3\n",
            "epoch: 108 [8500/8892 (96%)]\t training loss: 20.8\n",
            "\n",
            "Test dataset: Overall Loss: 1041.6,  (1.05%)\n",
            "\n",
            "epoch: 109 [0/8892 (0%)]\t training loss: 27.7\n",
            "epoch: 109 [500/8892 (6%)]\t training loss: 29.1\n",
            "epoch: 109 [1000/8892 (11%)]\t training loss: 22.3\n",
            "epoch: 109 [1500/8892 (17%)]\t training loss: 26.8\n",
            "epoch: 109 [2000/8892 (22%)]\t training loss: 24.2\n",
            "epoch: 109 [2500/8892 (28%)]\t training loss: 28.4\n",
            "epoch: 109 [3000/8892 (34%)]\t training loss: 25.7\n",
            "epoch: 109 [3500/8892 (39%)]\t training loss: 30.2\n",
            "epoch: 109 [4000/8892 (45%)]\t training loss: 21.8\n",
            "epoch: 109 [4500/8892 (51%)]\t training loss: 25.3\n",
            "epoch: 109 [5000/8892 (56%)]\t training loss: 29.3\n",
            "epoch: 109 [5500/8892 (62%)]\t training loss: 26.7\n",
            "epoch: 109 [6000/8892 (67%)]\t training loss: 29.5\n",
            "epoch: 109 [6500/8892 (73%)]\t training loss: 28.8\n",
            "epoch: 109 [7000/8892 (79%)]\t training loss: 28.9\n",
            "epoch: 109 [7500/8892 (84%)]\t training loss: 21.3\n",
            "epoch: 109 [8000/8892 (90%)]\t training loss: 26.4\n",
            "epoch: 109 [8500/8892 (96%)]\t training loss: 32.0\n",
            "\n",
            "Test dataset: Overall Loss: 1037.6,  (1.05%)\n",
            "\n",
            "epoch: 110 [0/8892 (0%)]\t training loss: 27.5\n",
            "epoch: 110 [500/8892 (6%)]\t training loss: 26.8\n",
            "epoch: 110 [1000/8892 (11%)]\t training loss: 25.1\n",
            "epoch: 110 [1500/8892 (17%)]\t training loss: 22.1\n",
            "epoch: 110 [2000/8892 (22%)]\t training loss: 30.7\n",
            "epoch: 110 [2500/8892 (28%)]\t training loss: 30.1\n",
            "epoch: 110 [3000/8892 (34%)]\t training loss: 26.6\n",
            "epoch: 110 [3500/8892 (39%)]\t training loss: 26.5\n",
            "epoch: 110 [4000/8892 (45%)]\t training loss: 23.5\n",
            "epoch: 110 [4500/8892 (51%)]\t training loss: 25.4\n",
            "epoch: 110 [5000/8892 (56%)]\t training loss: 24.6\n",
            "epoch: 110 [5500/8892 (62%)]\t training loss: 26.4\n",
            "epoch: 110 [6000/8892 (67%)]\t training loss: 30.1\n",
            "epoch: 110 [6500/8892 (73%)]\t training loss: 21.3\n",
            "epoch: 110 [7000/8892 (79%)]\t training loss: 28.8\n",
            "epoch: 110 [7500/8892 (84%)]\t training loss: 24.6\n",
            "epoch: 110 [8000/8892 (90%)]\t training loss: 22.9\n",
            "epoch: 110 [8500/8892 (96%)]\t training loss: 26.9\n",
            "\n",
            "Test dataset: Overall Loss: 1030.8,  (1.04%)\n",
            "\n",
            "epoch: 111 [0/8892 (0%)]\t training loss: 26.1\n",
            "epoch: 111 [500/8892 (6%)]\t training loss: 27.3\n",
            "epoch: 111 [1000/8892 (11%)]\t training loss: 22.6\n",
            "epoch: 111 [1500/8892 (17%)]\t training loss: 26.5\n",
            "epoch: 111 [2000/8892 (22%)]\t training loss: 23.8\n",
            "epoch: 111 [2500/8892 (28%)]\t training loss: 31.5\n",
            "epoch: 111 [3000/8892 (34%)]\t training loss: 29.1\n",
            "epoch: 111 [3500/8892 (39%)]\t training loss: 20.9\n",
            "epoch: 111 [4000/8892 (45%)]\t training loss: 18.4\n",
            "epoch: 111 [4500/8892 (51%)]\t training loss: 18.3\n",
            "epoch: 111 [5000/8892 (56%)]\t training loss: 28.4\n",
            "epoch: 111 [5500/8892 (62%)]\t training loss: 33.6\n",
            "epoch: 111 [6000/8892 (67%)]\t training loss: 31.6\n",
            "epoch: 111 [6500/8892 (73%)]\t training loss: 32.7\n",
            "epoch: 111 [7000/8892 (79%)]\t training loss: 27.6\n",
            "epoch: 111 [7500/8892 (84%)]\t training loss: 21.8\n",
            "epoch: 111 [8000/8892 (90%)]\t training loss: 27.8\n",
            "epoch: 111 [8500/8892 (96%)]\t training loss: 25.3\n",
            "\n",
            "Test dataset: Overall Loss: 1039.8,  (1.05%)\n",
            "\n",
            "epoch: 112 [0/8892 (0%)]\t training loss: 23.0\n",
            "epoch: 112 [500/8892 (6%)]\t training loss: 31.7\n",
            "epoch: 112 [1000/8892 (11%)]\t training loss: 26.2\n",
            "epoch: 112 [1500/8892 (17%)]\t training loss: 27.3\n",
            "epoch: 112 [2000/8892 (22%)]\t training loss: 29.1\n",
            "epoch: 112 [2500/8892 (28%)]\t training loss: 22.9\n",
            "epoch: 112 [3000/8892 (34%)]\t training loss: 27.3\n",
            "epoch: 112 [3500/8892 (39%)]\t training loss: 27.6\n",
            "epoch: 112 [4000/8892 (45%)]\t training loss: 26.3\n",
            "epoch: 112 [4500/8892 (51%)]\t training loss: 30.3\n",
            "epoch: 112 [5000/8892 (56%)]\t training loss: 18.7\n",
            "epoch: 112 [5500/8892 (62%)]\t training loss: 27.7\n",
            "epoch: 112 [6000/8892 (67%)]\t training loss: 25.3\n",
            "epoch: 112 [6500/8892 (73%)]\t training loss: 24.7\n",
            "epoch: 112 [7000/8892 (79%)]\t training loss: 24.8\n",
            "epoch: 112 [7500/8892 (84%)]\t training loss: 26.0\n",
            "epoch: 112 [8000/8892 (90%)]\t training loss: 23.6\n",
            "epoch: 112 [8500/8892 (96%)]\t training loss: 22.1\n",
            "\n",
            "Test dataset: Overall Loss: 1031.6,  (1.04%)\n",
            "\n",
            "epoch: 113 [0/8892 (0%)]\t training loss: 32.3\n",
            "epoch: 113 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 113 [1000/8892 (11%)]\t training loss: 25.4\n",
            "epoch: 113 [1500/8892 (17%)]\t training loss: 31.2\n",
            "epoch: 113 [2000/8892 (22%)]\t training loss: 23.5\n",
            "epoch: 113 [2500/8892 (28%)]\t training loss: 19.4\n",
            "epoch: 113 [3000/8892 (34%)]\t training loss: 27.4\n",
            "epoch: 113 [3500/8892 (39%)]\t training loss: 20.9\n",
            "epoch: 113 [4000/8892 (45%)]\t training loss: 27.1\n",
            "epoch: 113 [4500/8892 (51%)]\t training loss: 31.4\n",
            "epoch: 113 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 113 [5500/8892 (62%)]\t training loss: 23.1\n",
            "epoch: 113 [6000/8892 (67%)]\t training loss: 26.2\n",
            "epoch: 113 [6500/8892 (73%)]\t training loss: 24.4\n",
            "epoch: 113 [7000/8892 (79%)]\t training loss: 22.1\n",
            "epoch: 113 [7500/8892 (84%)]\t training loss: 24.7\n",
            "epoch: 113 [8000/8892 (90%)]\t training loss: 23.6\n",
            "epoch: 113 [8500/8892 (96%)]\t training loss: 28.7\n",
            "\n",
            "Test dataset: Overall Loss: 1026.4,  (1.04%)\n",
            "\n",
            "epoch: 114 [0/8892 (0%)]\t training loss: 25.8\n",
            "epoch: 114 [500/8892 (6%)]\t training loss: 22.6\n",
            "epoch: 114 [1000/8892 (11%)]\t training loss: 19.7\n",
            "epoch: 114 [1500/8892 (17%)]\t training loss: 21.5\n",
            "epoch: 114 [2000/8892 (22%)]\t training loss: 24.7\n",
            "epoch: 114 [2500/8892 (28%)]\t training loss: 23.5\n",
            "epoch: 114 [3000/8892 (34%)]\t training loss: 23.8\n",
            "epoch: 114 [3500/8892 (39%)]\t training loss: 24.5\n",
            "epoch: 114 [4000/8892 (45%)]\t training loss: 24.1\n",
            "epoch: 114 [4500/8892 (51%)]\t training loss: 24.8\n",
            "epoch: 114 [5000/8892 (56%)]\t training loss: 29.5\n",
            "epoch: 114 [5500/8892 (62%)]\t training loss: 18.8\n",
            "epoch: 114 [6000/8892 (67%)]\t training loss: 25.9\n",
            "epoch: 114 [6500/8892 (73%)]\t training loss: 23.9\n",
            "epoch: 114 [7000/8892 (79%)]\t training loss: 27.5\n",
            "epoch: 114 [7500/8892 (84%)]\t training loss: 22.1\n",
            "epoch: 114 [8000/8892 (90%)]\t training loss: 26.0\n",
            "epoch: 114 [8500/8892 (96%)]\t training loss: 27.1\n",
            "\n",
            "Test dataset: Overall Loss: 1036.9,  (1.05%)\n",
            "\n",
            "epoch: 115 [0/8892 (0%)]\t training loss: 22.1\n",
            "epoch: 115 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 115 [1000/8892 (11%)]\t training loss: 30.0\n",
            "epoch: 115 [1500/8892 (17%)]\t training loss: 24.8\n",
            "epoch: 115 [2000/8892 (22%)]\t training loss: 30.0\n",
            "epoch: 115 [2500/8892 (28%)]\t training loss: 21.8\n",
            "epoch: 115 [3000/8892 (34%)]\t training loss: 27.9\n",
            "epoch: 115 [3500/8892 (39%)]\t training loss: 28.4\n",
            "epoch: 115 [4000/8892 (45%)]\t training loss: 27.4\n",
            "epoch: 115 [4500/8892 (51%)]\t training loss: 24.9\n",
            "epoch: 115 [5000/8892 (56%)]\t training loss: 25.0\n",
            "epoch: 115 [5500/8892 (62%)]\t training loss: 25.3\n",
            "epoch: 115 [6000/8892 (67%)]\t training loss: 29.7\n",
            "epoch: 115 [6500/8892 (73%)]\t training loss: 16.8\n",
            "epoch: 115 [7000/8892 (79%)]\t training loss: 29.2\n",
            "epoch: 115 [7500/8892 (84%)]\t training loss: 26.2\n",
            "epoch: 115 [8000/8892 (90%)]\t training loss: 25.2\n",
            "epoch: 115 [8500/8892 (96%)]\t training loss: 26.3\n",
            "\n",
            "Test dataset: Overall Loss: 1041.9,  (1.05%)\n",
            "\n",
            "epoch: 116 [0/8892 (0%)]\t training loss: 24.7\n",
            "epoch: 116 [500/8892 (6%)]\t training loss: 21.0\n",
            "epoch: 116 [1000/8892 (11%)]\t training loss: 32.2\n",
            "epoch: 116 [1500/8892 (17%)]\t training loss: 34.2\n",
            "epoch: 116 [2000/8892 (22%)]\t training loss: 24.7\n",
            "epoch: 116 [2500/8892 (28%)]\t training loss: 26.8\n",
            "epoch: 116 [3000/8892 (34%)]\t training loss: 29.4\n",
            "epoch: 116 [3500/8892 (39%)]\t training loss: 26.3\n",
            "epoch: 116 [4000/8892 (45%)]\t training loss: 19.3\n",
            "epoch: 116 [4500/8892 (51%)]\t training loss: 25.3\n",
            "epoch: 116 [5000/8892 (56%)]\t training loss: 26.4\n",
            "epoch: 116 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 116 [6000/8892 (67%)]\t training loss: 37.8\n",
            "epoch: 116 [6500/8892 (73%)]\t training loss: 22.3\n",
            "epoch: 116 [7000/8892 (79%)]\t training loss: 23.6\n",
            "epoch: 116 [7500/8892 (84%)]\t training loss: 32.5\n",
            "epoch: 116 [8000/8892 (90%)]\t training loss: 23.0\n",
            "epoch: 116 [8500/8892 (96%)]\t training loss: 22.9\n",
            "\n",
            "Test dataset: Overall Loss: 1025.7,  (1.04%)\n",
            "\n",
            "epoch: 117 [0/8892 (0%)]\t training loss: 27.2\n",
            "epoch: 117 [500/8892 (6%)]\t training loss: 30.2\n",
            "epoch: 117 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 117 [1500/8892 (17%)]\t training loss: 23.5\n",
            "epoch: 117 [2000/8892 (22%)]\t training loss: 22.6\n",
            "epoch: 117 [2500/8892 (28%)]\t training loss: 22.3\n",
            "epoch: 117 [3000/8892 (34%)]\t training loss: 24.6\n",
            "epoch: 117 [3500/8892 (39%)]\t training loss: 20.5\n",
            "epoch: 117 [4000/8892 (45%)]\t training loss: 24.0\n",
            "epoch: 117 [4500/8892 (51%)]\t training loss: 17.5\n",
            "epoch: 117 [5000/8892 (56%)]\t training loss: 24.1\n",
            "epoch: 117 [5500/8892 (62%)]\t training loss: 22.4\n",
            "epoch: 117 [6000/8892 (67%)]\t training loss: 23.3\n",
            "epoch: 117 [6500/8892 (73%)]\t training loss: 23.7\n",
            "epoch: 117 [7000/8892 (79%)]\t training loss: 28.0\n",
            "epoch: 117 [7500/8892 (84%)]\t training loss: 24.1\n",
            "epoch: 117 [8000/8892 (90%)]\t training loss: 25.9\n",
            "epoch: 117 [8500/8892 (96%)]\t training loss: 25.2\n",
            "\n",
            "Test dataset: Overall Loss: 1022.2,  (1.03%)\n",
            "\n",
            "epoch: 118 [0/8892 (0%)]\t training loss: 21.1\n",
            "epoch: 118 [500/8892 (6%)]\t training loss: 23.8\n",
            "epoch: 118 [1000/8892 (11%)]\t training loss: 23.1\n",
            "epoch: 118 [1500/8892 (17%)]\t training loss: 28.0\n",
            "epoch: 118 [2000/8892 (22%)]\t training loss: 25.4\n",
            "epoch: 118 [2500/8892 (28%)]\t training loss: 23.8\n",
            "epoch: 118 [3000/8892 (34%)]\t training loss: 19.9\n",
            "epoch: 118 [3500/8892 (39%)]\t training loss: 30.4\n",
            "epoch: 118 [4000/8892 (45%)]\t training loss: 25.5\n",
            "epoch: 118 [4500/8892 (51%)]\t training loss: 22.7\n",
            "epoch: 118 [5000/8892 (56%)]\t training loss: 21.6\n",
            "epoch: 118 [5500/8892 (62%)]\t training loss: 30.5\n",
            "epoch: 118 [6000/8892 (67%)]\t training loss: 22.1\n",
            "epoch: 118 [6500/8892 (73%)]\t training loss: 29.9\n",
            "epoch: 118 [7000/8892 (79%)]\t training loss: 24.5\n",
            "epoch: 118 [7500/8892 (84%)]\t training loss: 20.6\n",
            "epoch: 118 [8000/8892 (90%)]\t training loss: 24.5\n",
            "epoch: 118 [8500/8892 (96%)]\t training loss: 22.0\n",
            "\n",
            "Test dataset: Overall Loss: 1030.0,  (1.04%)\n",
            "\n",
            "epoch: 119 [0/8892 (0%)]\t training loss: 27.3\n",
            "epoch: 119 [500/8892 (6%)]\t training loss: 25.5\n",
            "epoch: 119 [1000/8892 (11%)]\t training loss: 27.0\n",
            "epoch: 119 [1500/8892 (17%)]\t training loss: 25.9\n",
            "epoch: 119 [2000/8892 (22%)]\t training loss: 29.7\n",
            "epoch: 119 [2500/8892 (28%)]\t training loss: 28.3\n",
            "epoch: 119 [3000/8892 (34%)]\t training loss: 22.5\n",
            "epoch: 119 [3500/8892 (39%)]\t training loss: 19.7\n",
            "epoch: 119 [4000/8892 (45%)]\t training loss: 30.1\n",
            "epoch: 119 [4500/8892 (51%)]\t training loss: 20.0\n",
            "epoch: 119 [5000/8892 (56%)]\t training loss: 23.2\n",
            "epoch: 119 [5500/8892 (62%)]\t training loss: 24.2\n",
            "epoch: 119 [6000/8892 (67%)]\t training loss: 30.5\n",
            "epoch: 119 [6500/8892 (73%)]\t training loss: 29.8\n",
            "epoch: 119 [7000/8892 (79%)]\t training loss: 23.4\n",
            "epoch: 119 [7500/8892 (84%)]\t training loss: 21.8\n",
            "epoch: 119 [8000/8892 (90%)]\t training loss: 21.3\n",
            "epoch: 119 [8500/8892 (96%)]\t training loss: 27.1\n",
            "\n",
            "Test dataset: Overall Loss: 1036.5,  (1.05%)\n",
            "\n",
            "epoch: 120 [0/8892 (0%)]\t training loss: 24.3\n",
            "epoch: 120 [500/8892 (6%)]\t training loss: 24.2\n",
            "epoch: 120 [1000/8892 (11%)]\t training loss: 20.1\n",
            "epoch: 120 [1500/8892 (17%)]\t training loss: 28.0\n",
            "epoch: 120 [2000/8892 (22%)]\t training loss: 26.2\n",
            "epoch: 120 [2500/8892 (28%)]\t training loss: 31.4\n",
            "epoch: 120 [3000/8892 (34%)]\t training loss: 25.4\n",
            "epoch: 120 [3500/8892 (39%)]\t training loss: 19.8\n",
            "epoch: 120 [4000/8892 (45%)]\t training loss: 25.3\n",
            "epoch: 120 [4500/8892 (51%)]\t training loss: 30.1\n",
            "epoch: 120 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 120 [5500/8892 (62%)]\t training loss: 22.5\n",
            "epoch: 120 [6000/8892 (67%)]\t training loss: 22.3\n",
            "epoch: 120 [6500/8892 (73%)]\t training loss: 32.7\n",
            "epoch: 120 [7000/8892 (79%)]\t training loss: 24.5\n",
            "epoch: 120 [7500/8892 (84%)]\t training loss: 27.1\n",
            "epoch: 120 [8000/8892 (90%)]\t training loss: 22.6\n",
            "epoch: 120 [8500/8892 (96%)]\t training loss: 23.4\n",
            "\n",
            "Test dataset: Overall Loss: 1036.5,  (1.05%)\n",
            "\n",
            "epoch: 121 [0/8892 (0%)]\t training loss: 21.3\n",
            "epoch: 121 [500/8892 (6%)]\t training loss: 23.2\n",
            "epoch: 121 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 121 [1500/8892 (17%)]\t training loss: 24.9\n",
            "epoch: 121 [2000/8892 (22%)]\t training loss: 19.7\n",
            "epoch: 121 [2500/8892 (28%)]\t training loss: 22.5\n",
            "epoch: 121 [3000/8892 (34%)]\t training loss: 24.1\n",
            "epoch: 121 [3500/8892 (39%)]\t training loss: 27.1\n",
            "epoch: 121 [4000/8892 (45%)]\t training loss: 24.2\n",
            "epoch: 121 [4500/8892 (51%)]\t training loss: 29.7\n",
            "epoch: 121 [5000/8892 (56%)]\t training loss: 18.1\n",
            "epoch: 121 [5500/8892 (62%)]\t training loss: 23.4\n",
            "epoch: 121 [6000/8892 (67%)]\t training loss: 20.1\n",
            "epoch: 121 [6500/8892 (73%)]\t training loss: 25.5\n",
            "epoch: 121 [7000/8892 (79%)]\t training loss: 21.2\n",
            "epoch: 121 [7500/8892 (84%)]\t training loss: 31.9\n",
            "epoch: 121 [8000/8892 (90%)]\t training loss: 27.7\n",
            "epoch: 121 [8500/8892 (96%)]\t training loss: 25.0\n",
            "\n",
            "Test dataset: Overall Loss: 1030.6,  (1.04%)\n",
            "\n",
            "epoch: 122 [0/8892 (0%)]\t training loss: 27.1\n",
            "epoch: 122 [500/8892 (6%)]\t training loss: 24.9\n",
            "epoch: 122 [1000/8892 (11%)]\t training loss: 27.0\n",
            "epoch: 122 [1500/8892 (17%)]\t training loss: 25.4\n",
            "epoch: 122 [2000/8892 (22%)]\t training loss: 33.4\n",
            "epoch: 122 [2500/8892 (28%)]\t training loss: 37.3\n",
            "epoch: 122 [3000/8892 (34%)]\t training loss: 21.1\n",
            "epoch: 122 [3500/8892 (39%)]\t training loss: 25.2\n",
            "epoch: 122 [4000/8892 (45%)]\t training loss: 22.6\n",
            "epoch: 122 [4500/8892 (51%)]\t training loss: 23.8\n",
            "epoch: 122 [5000/8892 (56%)]\t training loss: 25.7\n",
            "epoch: 122 [5500/8892 (62%)]\t training loss: 19.8\n",
            "epoch: 122 [6000/8892 (67%)]\t training loss: 21.4\n",
            "epoch: 122 [6500/8892 (73%)]\t training loss: 23.7\n",
            "epoch: 122 [7000/8892 (79%)]\t training loss: 30.0\n",
            "epoch: 122 [7500/8892 (84%)]\t training loss: 24.1\n",
            "epoch: 122 [8000/8892 (90%)]\t training loss: 22.7\n",
            "epoch: 122 [8500/8892 (96%)]\t training loss: 24.8\n",
            "\n",
            "Test dataset: Overall Loss: 1031.7,  (1.04%)\n",
            "\n",
            "epoch: 123 [0/8892 (0%)]\t training loss: 24.1\n",
            "epoch: 123 [500/8892 (6%)]\t training loss: 26.6\n",
            "epoch: 123 [1000/8892 (11%)]\t training loss: 30.1\n",
            "epoch: 123 [1500/8892 (17%)]\t training loss: 23.6\n",
            "epoch: 123 [2000/8892 (22%)]\t training loss: 19.6\n",
            "epoch: 123 [2500/8892 (28%)]\t training loss: 23.9\n",
            "epoch: 123 [3000/8892 (34%)]\t training loss: 25.9\n",
            "epoch: 123 [3500/8892 (39%)]\t training loss: 28.3\n",
            "epoch: 123 [4000/8892 (45%)]\t training loss: 22.9\n",
            "epoch: 123 [4500/8892 (51%)]\t training loss: 24.9\n",
            "epoch: 123 [5000/8892 (56%)]\t training loss: 22.3\n",
            "epoch: 123 [5500/8892 (62%)]\t training loss: 29.6\n",
            "epoch: 123 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 123 [6500/8892 (73%)]\t training loss: 23.7\n",
            "epoch: 123 [7000/8892 (79%)]\t training loss: 31.0\n",
            "epoch: 123 [7500/8892 (84%)]\t training loss: 26.8\n",
            "epoch: 123 [8000/8892 (90%)]\t training loss: 25.6\n",
            "epoch: 123 [8500/8892 (96%)]\t training loss: 26.1\n",
            "\n",
            "Test dataset: Overall Loss: 1041.0,  (1.05%)\n",
            "\n",
            "epoch: 124 [0/8892 (0%)]\t training loss: 22.4\n",
            "epoch: 124 [500/8892 (6%)]\t training loss: 24.1\n",
            "epoch: 124 [1000/8892 (11%)]\t training loss: 24.6\n",
            "epoch: 124 [1500/8892 (17%)]\t training loss: 23.5\n",
            "epoch: 124 [2000/8892 (22%)]\t training loss: 25.0\n",
            "epoch: 124 [2500/8892 (28%)]\t training loss: 29.3\n",
            "epoch: 124 [3000/8892 (34%)]\t training loss: 26.4\n",
            "epoch: 124 [3500/8892 (39%)]\t training loss: 29.4\n",
            "epoch: 124 [4000/8892 (45%)]\t training loss: 25.2\n",
            "epoch: 124 [4500/8892 (51%)]\t training loss: 23.7\n",
            "epoch: 124 [5000/8892 (56%)]\t training loss: 23.0\n",
            "epoch: 124 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 124 [6000/8892 (67%)]\t training loss: 25.0\n",
            "epoch: 124 [6500/8892 (73%)]\t training loss: 31.3\n",
            "epoch: 124 [7000/8892 (79%)]\t training loss: 23.4\n",
            "epoch: 124 [7500/8892 (84%)]\t training loss: 21.4\n",
            "epoch: 124 [8000/8892 (90%)]\t training loss: 24.7\n",
            "epoch: 124 [8500/8892 (96%)]\t training loss: 32.3\n",
            "\n",
            "Test dataset: Overall Loss: 1035.9,  (1.05%)\n",
            "\n",
            "epoch: 125 [0/8892 (0%)]\t training loss: 23.8\n",
            "epoch: 125 [500/8892 (6%)]\t training loss: 27.2\n",
            "epoch: 125 [1000/8892 (11%)]\t training loss: 20.0\n",
            "epoch: 125 [1500/8892 (17%)]\t training loss: 28.9\n",
            "epoch: 125 [2000/8892 (22%)]\t training loss: 26.9\n",
            "epoch: 125 [2500/8892 (28%)]\t training loss: 23.9\n",
            "epoch: 125 [3000/8892 (34%)]\t training loss: 24.8\n",
            "epoch: 125 [3500/8892 (39%)]\t training loss: 18.9\n",
            "epoch: 125 [4000/8892 (45%)]\t training loss: 33.1\n",
            "epoch: 125 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 125 [5000/8892 (56%)]\t training loss: 27.7\n",
            "epoch: 125 [5500/8892 (62%)]\t training loss: 30.1\n",
            "epoch: 125 [6000/8892 (67%)]\t training loss: 25.3\n",
            "epoch: 125 [6500/8892 (73%)]\t training loss: 24.7\n",
            "epoch: 125 [7000/8892 (79%)]\t training loss: 29.5\n",
            "epoch: 125 [7500/8892 (84%)]\t training loss: 17.8\n",
            "epoch: 125 [8000/8892 (90%)]\t training loss: 30.0\n",
            "epoch: 125 [8500/8892 (96%)]\t training loss: 28.2\n",
            "\n",
            "Test dataset: Overall Loss: 1036.4,  (1.05%)\n",
            "\n",
            "epoch: 126 [0/8892 (0%)]\t training loss: 32.2\n",
            "epoch: 126 [500/8892 (6%)]\t training loss: 23.6\n",
            "epoch: 126 [1000/8892 (11%)]\t training loss: 32.2\n",
            "epoch: 126 [1500/8892 (17%)]\t training loss: 24.7\n",
            "epoch: 126 [2000/8892 (22%)]\t training loss: 21.5\n",
            "epoch: 126 [2500/8892 (28%)]\t training loss: 25.1\n",
            "epoch: 126 [3000/8892 (34%)]\t training loss: 33.5\n",
            "epoch: 126 [3500/8892 (39%)]\t training loss: 25.9\n",
            "epoch: 126 [4000/8892 (45%)]\t training loss: 21.0\n",
            "epoch: 126 [4500/8892 (51%)]\t training loss: 22.9\n",
            "epoch: 126 [5000/8892 (56%)]\t training loss: 31.2\n",
            "epoch: 126 [5500/8892 (62%)]\t training loss: 20.1\n",
            "epoch: 126 [6000/8892 (67%)]\t training loss: 27.2\n",
            "epoch: 126 [6500/8892 (73%)]\t training loss: 24.9\n",
            "epoch: 126 [7000/8892 (79%)]\t training loss: 24.3\n",
            "epoch: 126 [7500/8892 (84%)]\t training loss: 28.9\n",
            "epoch: 126 [8000/8892 (90%)]\t training loss: 29.2\n",
            "epoch: 126 [8500/8892 (96%)]\t training loss: 26.8\n",
            "\n",
            "Test dataset: Overall Loss: 1034.4,  (1.05%)\n",
            "\n",
            "epoch: 127 [0/8892 (0%)]\t training loss: 23.4\n",
            "epoch: 127 [500/8892 (6%)]\t training loss: 28.2\n",
            "epoch: 127 [1000/8892 (11%)]\t training loss: 27.5\n",
            "epoch: 127 [1500/8892 (17%)]\t training loss: 23.6\n",
            "epoch: 127 [2000/8892 (22%)]\t training loss: 22.4\n",
            "epoch: 127 [2500/8892 (28%)]\t training loss: 22.5\n",
            "epoch: 127 [3000/8892 (34%)]\t training loss: 21.0\n",
            "epoch: 127 [3500/8892 (39%)]\t training loss: 17.8\n",
            "epoch: 127 [4000/8892 (45%)]\t training loss: 31.7\n",
            "epoch: 127 [4500/8892 (51%)]\t training loss: 29.1\n",
            "epoch: 127 [5000/8892 (56%)]\t training loss: 23.5\n",
            "epoch: 127 [5500/8892 (62%)]\t training loss: 26.7\n",
            "epoch: 127 [6000/8892 (67%)]\t training loss: 26.8\n",
            "epoch: 127 [6500/8892 (73%)]\t training loss: 26.0\n",
            "epoch: 127 [7000/8892 (79%)]\t training loss: 27.2\n",
            "epoch: 127 [7500/8892 (84%)]\t training loss: 27.3\n",
            "epoch: 127 [8000/8892 (90%)]\t training loss: 35.0\n",
            "epoch: 127 [8500/8892 (96%)]\t training loss: 29.7\n",
            "\n",
            "Test dataset: Overall Loss: 1031.1,  (1.04%)\n",
            "\n",
            "epoch: 128 [0/8892 (0%)]\t training loss: 22.0\n",
            "epoch: 128 [500/8892 (6%)]\t training loss: 29.6\n",
            "epoch: 128 [1000/8892 (11%)]\t training loss: 25.5\n",
            "epoch: 128 [1500/8892 (17%)]\t training loss: 22.2\n",
            "epoch: 128 [2000/8892 (22%)]\t training loss: 29.4\n",
            "epoch: 128 [2500/8892 (28%)]\t training loss: 18.1\n",
            "epoch: 128 [3000/8892 (34%)]\t training loss: 22.7\n",
            "epoch: 128 [3500/8892 (39%)]\t training loss: 27.7\n",
            "epoch: 128 [4000/8892 (45%)]\t training loss: 20.9\n",
            "epoch: 128 [4500/8892 (51%)]\t training loss: 20.7\n",
            "epoch: 128 [5000/8892 (56%)]\t training loss: 30.1\n",
            "epoch: 128 [5500/8892 (62%)]\t training loss: 24.6\n",
            "epoch: 128 [6000/8892 (67%)]\t training loss: 25.6\n",
            "epoch: 128 [6500/8892 (73%)]\t training loss: 27.8\n",
            "epoch: 128 [7000/8892 (79%)]\t training loss: 25.7\n",
            "epoch: 128 [7500/8892 (84%)]\t training loss: 20.5\n",
            "epoch: 128 [8000/8892 (90%)]\t training loss: 31.3\n",
            "epoch: 128 [8500/8892 (96%)]\t training loss: 24.8\n",
            "\n",
            "Test dataset: Overall Loss: 1039.6,  (1.05%)\n",
            "\n",
            "epoch: 129 [0/8892 (0%)]\t training loss: 33.9\n",
            "epoch: 129 [500/8892 (6%)]\t training loss: 20.4\n",
            "epoch: 129 [1000/8892 (11%)]\t training loss: 19.6\n",
            "epoch: 129 [1500/8892 (17%)]\t training loss: 22.7\n",
            "epoch: 129 [2000/8892 (22%)]\t training loss: 27.9\n",
            "epoch: 129 [2500/8892 (28%)]\t training loss: 23.9\n",
            "epoch: 129 [3000/8892 (34%)]\t training loss: 29.0\n",
            "epoch: 129 [3500/8892 (39%)]\t training loss: 23.4\n",
            "epoch: 129 [4000/8892 (45%)]\t training loss: 24.0\n",
            "epoch: 129 [4500/8892 (51%)]\t training loss: 22.1\n",
            "epoch: 129 [5000/8892 (56%)]\t training loss: 17.8\n",
            "epoch: 129 [5500/8892 (62%)]\t training loss: 24.6\n",
            "epoch: 129 [6000/8892 (67%)]\t training loss: 25.1\n",
            "epoch: 129 [6500/8892 (73%)]\t training loss: 23.0\n",
            "epoch: 129 [7000/8892 (79%)]\t training loss: 34.3\n",
            "epoch: 129 [7500/8892 (84%)]\t training loss: 23.3\n",
            "epoch: 129 [8000/8892 (90%)]\t training loss: 21.5\n",
            "epoch: 129 [8500/8892 (96%)]\t training loss: 28.8\n",
            "\n",
            "Test dataset: Overall Loss: 1035.8,  (1.05%)\n",
            "\n",
            "epoch: 130 [0/8892 (0%)]\t training loss: 24.9\n",
            "epoch: 130 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 130 [1000/8892 (11%)]\t training loss: 27.5\n",
            "epoch: 130 [1500/8892 (17%)]\t training loss: 24.1\n",
            "epoch: 130 [2000/8892 (22%)]\t training loss: 27.3\n",
            "epoch: 130 [2500/8892 (28%)]\t training loss: 23.6\n",
            "epoch: 130 [3000/8892 (34%)]\t training loss: 23.0\n",
            "epoch: 130 [3500/8892 (39%)]\t training loss: 22.7\n",
            "epoch: 130 [4000/8892 (45%)]\t training loss: 24.2\n",
            "epoch: 130 [4500/8892 (51%)]\t training loss: 29.7\n",
            "epoch: 130 [5000/8892 (56%)]\t training loss: 29.4\n",
            "epoch: 130 [5500/8892 (62%)]\t training loss: 29.2\n",
            "epoch: 130 [6000/8892 (67%)]\t training loss: 27.6\n",
            "epoch: 130 [6500/8892 (73%)]\t training loss: 30.7\n",
            "epoch: 130 [7000/8892 (79%)]\t training loss: 22.8\n",
            "epoch: 130 [7500/8892 (84%)]\t training loss: 21.3\n",
            "epoch: 130 [8000/8892 (90%)]\t training loss: 21.1\n",
            "epoch: 130 [8500/8892 (96%)]\t training loss: 24.8\n",
            "\n",
            "Test dataset: Overall Loss: 1036.1,  (1.05%)\n",
            "\n",
            "epoch: 131 [0/8892 (0%)]\t training loss: 22.7\n",
            "epoch: 131 [500/8892 (6%)]\t training loss: 20.7\n",
            "epoch: 131 [1000/8892 (11%)]\t training loss: 25.8\n",
            "epoch: 131 [1500/8892 (17%)]\t training loss: 23.3\n",
            "epoch: 131 [2000/8892 (22%)]\t training loss: 31.3\n",
            "epoch: 131 [2500/8892 (28%)]\t training loss: 23.5\n",
            "epoch: 131 [3000/8892 (34%)]\t training loss: 23.8\n",
            "epoch: 131 [3500/8892 (39%)]\t training loss: 25.5\n",
            "epoch: 131 [4000/8892 (45%)]\t training loss: 26.3\n",
            "epoch: 131 [4500/8892 (51%)]\t training loss: 24.0\n",
            "epoch: 131 [5000/8892 (56%)]\t training loss: 22.1\n",
            "epoch: 131 [5500/8892 (62%)]\t training loss: 18.1\n",
            "epoch: 131 [6000/8892 (67%)]\t training loss: 18.0\n",
            "epoch: 131 [6500/8892 (73%)]\t training loss: 20.6\n",
            "epoch: 131 [7000/8892 (79%)]\t training loss: 21.3\n",
            "epoch: 131 [7500/8892 (84%)]\t training loss: 26.2\n",
            "epoch: 131 [8000/8892 (90%)]\t training loss: 25.3\n",
            "epoch: 131 [8500/8892 (96%)]\t training loss: 27.7\n",
            "\n",
            "Test dataset: Overall Loss: 1050.5,  (1.06%)\n",
            "\n",
            "epoch: 132 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 132 [500/8892 (6%)]\t training loss: 21.9\n",
            "epoch: 132 [1000/8892 (11%)]\t training loss: 22.3\n",
            "epoch: 132 [1500/8892 (17%)]\t training loss: 33.3\n",
            "epoch: 132 [2000/8892 (22%)]\t training loss: 29.0\n",
            "epoch: 132 [2500/8892 (28%)]\t training loss: 26.4\n",
            "epoch: 132 [3000/8892 (34%)]\t training loss: 24.9\n",
            "epoch: 132 [3500/8892 (39%)]\t training loss: 25.8\n",
            "epoch: 132 [4000/8892 (45%)]\t training loss: 27.1\n",
            "epoch: 132 [4500/8892 (51%)]\t training loss: 42.4\n",
            "epoch: 132 [5000/8892 (56%)]\t training loss: 27.5\n",
            "epoch: 132 [5500/8892 (62%)]\t training loss: 29.5\n",
            "epoch: 132 [6000/8892 (67%)]\t training loss: 25.8\n",
            "epoch: 132 [6500/8892 (73%)]\t training loss: 18.2\n",
            "epoch: 132 [7000/8892 (79%)]\t training loss: 22.3\n",
            "epoch: 132 [7500/8892 (84%)]\t training loss: 28.3\n",
            "epoch: 132 [8000/8892 (90%)]\t training loss: 27.2\n",
            "epoch: 132 [8500/8892 (96%)]\t training loss: 23.0\n",
            "\n",
            "Test dataset: Overall Loss: 1051.7,  (1.06%)\n",
            "\n",
            "epoch: 133 [0/8892 (0%)]\t training loss: 31.1\n",
            "epoch: 133 [500/8892 (6%)]\t training loss: 23.4\n",
            "epoch: 133 [1000/8892 (11%)]\t training loss: 25.8\n",
            "epoch: 133 [1500/8892 (17%)]\t training loss: 25.8\n",
            "epoch: 133 [2000/8892 (22%)]\t training loss: 27.8\n",
            "epoch: 133 [2500/8892 (28%)]\t training loss: 25.4\n",
            "epoch: 133 [3000/8892 (34%)]\t training loss: 34.6\n",
            "epoch: 133 [3500/8892 (39%)]\t training loss: 23.7\n",
            "epoch: 133 [4000/8892 (45%)]\t training loss: 30.0\n",
            "epoch: 133 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 133 [5000/8892 (56%)]\t training loss: 23.1\n",
            "epoch: 133 [5500/8892 (62%)]\t training loss: 22.3\n",
            "epoch: 133 [6000/8892 (67%)]\t training loss: 32.5\n",
            "epoch: 133 [6500/8892 (73%)]\t training loss: 24.1\n",
            "epoch: 133 [7000/8892 (79%)]\t training loss: 23.5\n",
            "epoch: 133 [7500/8892 (84%)]\t training loss: 19.8\n",
            "epoch: 133 [8000/8892 (90%)]\t training loss: 23.5\n",
            "epoch: 133 [8500/8892 (96%)]\t training loss: 31.0\n",
            "\n",
            "Test dataset: Overall Loss: 1028.5,  (1.04%)\n",
            "\n",
            "epoch: 134 [0/8892 (0%)]\t training loss: 26.1\n",
            "epoch: 134 [500/8892 (6%)]\t training loss: 31.1\n",
            "epoch: 134 [1000/8892 (11%)]\t training loss: 22.2\n",
            "epoch: 134 [1500/8892 (17%)]\t training loss: 36.7\n",
            "epoch: 134 [2000/8892 (22%)]\t training loss: 20.1\n",
            "epoch: 134 [2500/8892 (28%)]\t training loss: 30.2\n",
            "epoch: 134 [3000/8892 (34%)]\t training loss: 24.8\n",
            "epoch: 134 [3500/8892 (39%)]\t training loss: 23.7\n",
            "epoch: 134 [4000/8892 (45%)]\t training loss: 20.6\n",
            "epoch: 134 [4500/8892 (51%)]\t training loss: 27.6\n",
            "epoch: 134 [5000/8892 (56%)]\t training loss: 28.3\n",
            "epoch: 134 [5500/8892 (62%)]\t training loss: 26.1\n",
            "epoch: 134 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 134 [6500/8892 (73%)]\t training loss: 25.7\n",
            "epoch: 134 [7000/8892 (79%)]\t training loss: 26.7\n",
            "epoch: 134 [7500/8892 (84%)]\t training loss: 19.0\n",
            "epoch: 134 [8000/8892 (90%)]\t training loss: 21.6\n",
            "epoch: 134 [8500/8892 (96%)]\t training loss: 22.4\n",
            "\n",
            "Test dataset: Overall Loss: 1034.7,  (1.05%)\n",
            "\n",
            "epoch: 135 [0/8892 (0%)]\t training loss: 21.3\n",
            "epoch: 135 [500/8892 (6%)]\t training loss: 19.0\n",
            "epoch: 135 [1000/8892 (11%)]\t training loss: 31.9\n",
            "epoch: 135 [1500/8892 (17%)]\t training loss: 23.4\n",
            "epoch: 135 [2000/8892 (22%)]\t training loss: 23.0\n",
            "epoch: 135 [2500/8892 (28%)]\t training loss: 17.5\n",
            "epoch: 135 [3000/8892 (34%)]\t training loss: 24.8\n",
            "epoch: 135 [3500/8892 (39%)]\t training loss: 25.8\n",
            "epoch: 135 [4000/8892 (45%)]\t training loss: 25.6\n",
            "epoch: 135 [4500/8892 (51%)]\t training loss: 27.7\n",
            "epoch: 135 [5000/8892 (56%)]\t training loss: 19.3\n",
            "epoch: 135 [5500/8892 (62%)]\t training loss: 22.5\n",
            "epoch: 135 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 135 [6500/8892 (73%)]\t training loss: 19.2\n",
            "epoch: 135 [7000/8892 (79%)]\t training loss: 24.0\n",
            "epoch: 135 [7500/8892 (84%)]\t training loss: 26.9\n",
            "epoch: 135 [8000/8892 (90%)]\t training loss: 35.4\n",
            "epoch: 135 [8500/8892 (96%)]\t training loss: 30.1\n",
            "\n",
            "Test dataset: Overall Loss: 1037.7,  (1.05%)\n",
            "\n",
            "epoch: 136 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 136 [500/8892 (6%)]\t training loss: 21.3\n",
            "epoch: 136 [1000/8892 (11%)]\t training loss: 23.8\n",
            "epoch: 136 [1500/8892 (17%)]\t training loss: 28.2\n",
            "epoch: 136 [2000/8892 (22%)]\t training loss: 26.2\n",
            "epoch: 136 [2500/8892 (28%)]\t training loss: 27.8\n",
            "epoch: 136 [3000/8892 (34%)]\t training loss: 20.7\n",
            "epoch: 136 [3500/8892 (39%)]\t training loss: 24.8\n",
            "epoch: 136 [4000/8892 (45%)]\t training loss: 28.6\n",
            "epoch: 136 [4500/8892 (51%)]\t training loss: 34.7\n",
            "epoch: 136 [5000/8892 (56%)]\t training loss: 23.1\n",
            "epoch: 136 [5500/8892 (62%)]\t training loss: 21.9\n",
            "epoch: 136 [6000/8892 (67%)]\t training loss: 26.8\n",
            "epoch: 136 [6500/8892 (73%)]\t training loss: 22.2\n",
            "epoch: 136 [7000/8892 (79%)]\t training loss: 34.7\n",
            "epoch: 136 [7500/8892 (84%)]\t training loss: 26.4\n",
            "epoch: 136 [8000/8892 (90%)]\t training loss: 23.2\n",
            "epoch: 136 [8500/8892 (96%)]\t training loss: 29.7\n",
            "\n",
            "Test dataset: Overall Loss: 1032.9,  (1.05%)\n",
            "\n",
            "epoch: 137 [0/8892 (0%)]\t training loss: 22.1\n",
            "epoch: 137 [500/8892 (6%)]\t training loss: 27.9\n",
            "epoch: 137 [1000/8892 (11%)]\t training loss: 22.0\n",
            "epoch: 137 [1500/8892 (17%)]\t training loss: 24.5\n",
            "epoch: 137 [2000/8892 (22%)]\t training loss: 27.6\n",
            "epoch: 137 [2500/8892 (28%)]\t training loss: 23.0\n",
            "epoch: 137 [3000/8892 (34%)]\t training loss: 23.2\n",
            "epoch: 137 [3500/8892 (39%)]\t training loss: 25.6\n",
            "epoch: 137 [4000/8892 (45%)]\t training loss: 20.1\n",
            "epoch: 137 [4500/8892 (51%)]\t training loss: 25.6\n",
            "epoch: 137 [5000/8892 (56%)]\t training loss: 24.4\n",
            "epoch: 137 [5500/8892 (62%)]\t training loss: 32.3\n",
            "epoch: 137 [6000/8892 (67%)]\t training loss: 20.4\n",
            "epoch: 137 [6500/8892 (73%)]\t training loss: 30.3\n",
            "epoch: 137 [7000/8892 (79%)]\t training loss: 24.5\n",
            "epoch: 137 [7500/8892 (84%)]\t training loss: 20.7\n",
            "epoch: 137 [8000/8892 (90%)]\t training loss: 28.4\n",
            "epoch: 137 [8500/8892 (96%)]\t training loss: 30.9\n",
            "\n",
            "Test dataset: Overall Loss: 1033.0,  (1.05%)\n",
            "\n",
            "epoch: 138 [0/8892 (0%)]\t training loss: 23.1\n",
            "epoch: 138 [500/8892 (6%)]\t training loss: 21.9\n",
            "epoch: 138 [1000/8892 (11%)]\t training loss: 36.2\n",
            "epoch: 138 [1500/8892 (17%)]\t training loss: 21.7\n",
            "epoch: 138 [2000/8892 (22%)]\t training loss: 35.3\n",
            "epoch: 138 [2500/8892 (28%)]\t training loss: 24.4\n",
            "epoch: 138 [3000/8892 (34%)]\t training loss: 25.5\n",
            "epoch: 138 [3500/8892 (39%)]\t training loss: 25.5\n",
            "epoch: 138 [4000/8892 (45%)]\t training loss: 30.5\n",
            "epoch: 138 [4500/8892 (51%)]\t training loss: 27.9\n",
            "epoch: 138 [5000/8892 (56%)]\t training loss: 27.5\n",
            "epoch: 138 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 138 [6000/8892 (67%)]\t training loss: 30.7\n",
            "epoch: 138 [6500/8892 (73%)]\t training loss: 24.1\n",
            "epoch: 138 [7000/8892 (79%)]\t training loss: 28.9\n",
            "epoch: 138 [7500/8892 (84%)]\t training loss: 22.9\n",
            "epoch: 138 [8000/8892 (90%)]\t training loss: 31.6\n",
            "epoch: 138 [8500/8892 (96%)]\t training loss: 23.1\n",
            "\n",
            "Test dataset: Overall Loss: 1024.8,  (1.04%)\n",
            "\n",
            "epoch: 139 [0/8892 (0%)]\t training loss: 24.3\n",
            "epoch: 139 [500/8892 (6%)]\t training loss: 19.3\n",
            "epoch: 139 [1000/8892 (11%)]\t training loss: 24.1\n",
            "epoch: 139 [1500/8892 (17%)]\t training loss: 19.7\n",
            "epoch: 139 [2000/8892 (22%)]\t training loss: 23.4\n",
            "epoch: 139 [2500/8892 (28%)]\t training loss: 26.5\n",
            "epoch: 139 [3000/8892 (34%)]\t training loss: 21.1\n",
            "epoch: 139 [3500/8892 (39%)]\t training loss: 22.1\n",
            "epoch: 139 [4000/8892 (45%)]\t training loss: 20.6\n",
            "epoch: 139 [4500/8892 (51%)]\t training loss: 26.6\n",
            "epoch: 139 [5000/8892 (56%)]\t training loss: 25.8\n",
            "epoch: 139 [5500/8892 (62%)]\t training loss: 34.8\n",
            "epoch: 139 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 139 [6500/8892 (73%)]\t training loss: 28.8\n",
            "epoch: 139 [7000/8892 (79%)]\t training loss: 22.3\n",
            "epoch: 139 [7500/8892 (84%)]\t training loss: 24.6\n",
            "epoch: 139 [8000/8892 (90%)]\t training loss: 20.3\n",
            "epoch: 139 [8500/8892 (96%)]\t training loss: 28.6\n",
            "\n",
            "Test dataset: Overall Loss: 1045.2,  (1.06%)\n",
            "\n",
            "epoch: 140 [0/8892 (0%)]\t training loss: 22.2\n",
            "epoch: 140 [500/8892 (6%)]\t training loss: 23.6\n",
            "epoch: 140 [1000/8892 (11%)]\t training loss: 21.1\n",
            "epoch: 140 [1500/8892 (17%)]\t training loss: 20.9\n",
            "epoch: 140 [2000/8892 (22%)]\t training loss: 24.9\n",
            "epoch: 140 [2500/8892 (28%)]\t training loss: 16.8\n",
            "epoch: 140 [3000/8892 (34%)]\t training loss: 22.0\n",
            "epoch: 140 [3500/8892 (39%)]\t training loss: 19.6\n",
            "epoch: 140 [4000/8892 (45%)]\t training loss: 22.0\n",
            "epoch: 140 [4500/8892 (51%)]\t training loss: 22.9\n",
            "epoch: 140 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 140 [5500/8892 (62%)]\t training loss: 24.5\n",
            "epoch: 140 [6000/8892 (67%)]\t training loss: 21.6\n",
            "epoch: 140 [6500/8892 (73%)]\t training loss: 28.6\n",
            "epoch: 140 [7000/8892 (79%)]\t training loss: 19.3\n",
            "epoch: 140 [7500/8892 (84%)]\t training loss: 23.2\n",
            "epoch: 140 [8000/8892 (90%)]\t training loss: 30.8\n",
            "epoch: 140 [8500/8892 (96%)]\t training loss: 31.3\n",
            "\n",
            "Test dataset: Overall Loss: 1047.8,  (1.06%)\n",
            "\n",
            "epoch: 141 [0/8892 (0%)]\t training loss: 19.0\n",
            "epoch: 141 [500/8892 (6%)]\t training loss: 26.9\n",
            "epoch: 141 [1000/8892 (11%)]\t training loss: 30.1\n",
            "epoch: 141 [1500/8892 (17%)]\t training loss: 16.2\n",
            "epoch: 141 [2000/8892 (22%)]\t training loss: 25.0\n",
            "epoch: 141 [2500/8892 (28%)]\t training loss: 20.2\n",
            "epoch: 141 [3000/8892 (34%)]\t training loss: 21.4\n",
            "epoch: 141 [3500/8892 (39%)]\t training loss: 23.0\n",
            "epoch: 141 [4000/8892 (45%)]\t training loss: 19.6\n",
            "epoch: 141 [4500/8892 (51%)]\t training loss: 22.5\n",
            "epoch: 141 [5000/8892 (56%)]\t training loss: 25.5\n",
            "epoch: 141 [5500/8892 (62%)]\t training loss: 27.1\n",
            "epoch: 141 [6000/8892 (67%)]\t training loss: 23.4\n",
            "epoch: 141 [6500/8892 (73%)]\t training loss: 24.2\n",
            "epoch: 141 [7000/8892 (79%)]\t training loss: 25.4\n",
            "epoch: 141 [7500/8892 (84%)]\t training loss: 24.8\n",
            "epoch: 141 [8000/8892 (90%)]\t training loss: 31.3\n",
            "epoch: 141 [8500/8892 (96%)]\t training loss: 27.4\n",
            "\n",
            "Test dataset: Overall Loss: 1028.3,  (1.04%)\n",
            "\n",
            "epoch: 142 [0/8892 (0%)]\t training loss: 22.8\n",
            "epoch: 142 [500/8892 (6%)]\t training loss: 21.3\n",
            "epoch: 142 [1000/8892 (11%)]\t training loss: 21.8\n",
            "epoch: 142 [1500/8892 (17%)]\t training loss: 19.7\n",
            "epoch: 142 [2000/8892 (22%)]\t training loss: 22.5\n",
            "epoch: 142 [2500/8892 (28%)]\t training loss: 25.9\n",
            "epoch: 142 [3000/8892 (34%)]\t training loss: 22.9\n",
            "epoch: 142 [3500/8892 (39%)]\t training loss: 22.8\n",
            "epoch: 142 [4000/8892 (45%)]\t training loss: 22.0\n",
            "epoch: 142 [4500/8892 (51%)]\t training loss: 32.6\n",
            "epoch: 142 [5000/8892 (56%)]\t training loss: 26.7\n",
            "epoch: 142 [5500/8892 (62%)]\t training loss: 25.2\n",
            "epoch: 142 [6000/8892 (67%)]\t training loss: 31.0\n",
            "epoch: 142 [6500/8892 (73%)]\t training loss: 21.9\n",
            "epoch: 142 [7000/8892 (79%)]\t training loss: 27.2\n",
            "epoch: 142 [7500/8892 (84%)]\t training loss: 24.5\n",
            "epoch: 142 [8000/8892 (90%)]\t training loss: 21.0\n",
            "epoch: 142 [8500/8892 (96%)]\t training loss: 21.2\n",
            "\n",
            "Test dataset: Overall Loss: 1026.9,  (1.04%)\n",
            "\n",
            "epoch: 143 [0/8892 (0%)]\t training loss: 18.0\n",
            "epoch: 143 [500/8892 (6%)]\t training loss: 21.4\n",
            "epoch: 143 [1000/8892 (11%)]\t training loss: 22.8\n",
            "epoch: 143 [1500/8892 (17%)]\t training loss: 30.4\n",
            "epoch: 143 [2000/8892 (22%)]\t training loss: 21.2\n",
            "epoch: 143 [2500/8892 (28%)]\t training loss: 23.2\n",
            "epoch: 143 [3000/8892 (34%)]\t training loss: 21.4\n",
            "epoch: 143 [3500/8892 (39%)]\t training loss: 19.5\n",
            "epoch: 143 [4000/8892 (45%)]\t training loss: 26.6\n",
            "epoch: 143 [4500/8892 (51%)]\t training loss: 25.3\n",
            "epoch: 143 [5000/8892 (56%)]\t training loss: 22.7\n",
            "epoch: 143 [5500/8892 (62%)]\t training loss: 28.1\n",
            "epoch: 143 [6000/8892 (67%)]\t training loss: 28.3\n",
            "epoch: 143 [6500/8892 (73%)]\t training loss: 32.5\n",
            "epoch: 143 [7000/8892 (79%)]\t training loss: 30.6\n",
            "epoch: 143 [7500/8892 (84%)]\t training loss: 23.4\n",
            "epoch: 143 [8000/8892 (90%)]\t training loss: 19.6\n",
            "epoch: 143 [8500/8892 (96%)]\t training loss: 22.0\n",
            "\n",
            "Test dataset: Overall Loss: 1029.3,  (1.04%)\n",
            "\n",
            "epoch: 144 [0/8892 (0%)]\t training loss: 25.7\n",
            "epoch: 144 [500/8892 (6%)]\t training loss: 37.4\n",
            "epoch: 144 [1000/8892 (11%)]\t training loss: 24.4\n",
            "epoch: 144 [1500/8892 (17%)]\t training loss: 27.1\n",
            "epoch: 144 [2000/8892 (22%)]\t training loss: 27.9\n",
            "epoch: 144 [2500/8892 (28%)]\t training loss: 23.0\n",
            "epoch: 144 [3000/8892 (34%)]\t training loss: 29.8\n",
            "epoch: 144 [3500/8892 (39%)]\t training loss: 20.2\n",
            "epoch: 144 [4000/8892 (45%)]\t training loss: 29.0\n",
            "epoch: 144 [4500/8892 (51%)]\t training loss: 23.4\n",
            "epoch: 144 [5000/8892 (56%)]\t training loss: 21.9\n",
            "epoch: 144 [5500/8892 (62%)]\t training loss: 24.3\n",
            "epoch: 144 [6000/8892 (67%)]\t training loss: 20.5\n",
            "epoch: 144 [6500/8892 (73%)]\t training loss: 22.5\n",
            "epoch: 144 [7000/8892 (79%)]\t training loss: 28.7\n",
            "epoch: 144 [7500/8892 (84%)]\t training loss: 25.1\n",
            "epoch: 144 [8000/8892 (90%)]\t training loss: 31.2\n",
            "epoch: 144 [8500/8892 (96%)]\t training loss: 31.4\n",
            "\n",
            "Test dataset: Overall Loss: 1035.1,  (1.05%)\n",
            "\n",
            "epoch: 145 [0/8892 (0%)]\t training loss: 25.2\n",
            "epoch: 145 [500/8892 (6%)]\t training loss: 26.7\n",
            "epoch: 145 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 145 [1500/8892 (17%)]\t training loss: 18.0\n",
            "epoch: 145 [2000/8892 (22%)]\t training loss: 24.1\n",
            "epoch: 145 [2500/8892 (28%)]\t training loss: 22.9\n",
            "epoch: 145 [3000/8892 (34%)]\t training loss: 29.6\n",
            "epoch: 145 [3500/8892 (39%)]\t training loss: 23.1\n",
            "epoch: 145 [4000/8892 (45%)]\t training loss: 24.1\n",
            "epoch: 145 [4500/8892 (51%)]\t training loss: 27.2\n",
            "epoch: 145 [5000/8892 (56%)]\t training loss: 27.3\n",
            "epoch: 145 [5500/8892 (62%)]\t training loss: 23.2\n",
            "epoch: 145 [6000/8892 (67%)]\t training loss: 25.7\n",
            "epoch: 145 [6500/8892 (73%)]\t training loss: 26.0\n",
            "epoch: 145 [7000/8892 (79%)]\t training loss: 23.6\n",
            "epoch: 145 [7500/8892 (84%)]\t training loss: 20.0\n",
            "epoch: 145 [8000/8892 (90%)]\t training loss: 33.6\n",
            "epoch: 145 [8500/8892 (96%)]\t training loss: 16.6\n",
            "\n",
            "Test dataset: Overall Loss: 1041.8,  (1.05%)\n",
            "\n",
            "epoch: 146 [0/8892 (0%)]\t training loss: 16.2\n",
            "epoch: 146 [500/8892 (6%)]\t training loss: 32.7\n",
            "epoch: 146 [1000/8892 (11%)]\t training loss: 22.0\n",
            "epoch: 146 [1500/8892 (17%)]\t training loss: 16.9\n",
            "epoch: 146 [2000/8892 (22%)]\t training loss: 30.9\n",
            "epoch: 146 [2500/8892 (28%)]\t training loss: 27.4\n",
            "epoch: 146 [3000/8892 (34%)]\t training loss: 18.5\n",
            "epoch: 146 [3500/8892 (39%)]\t training loss: 24.5\n",
            "epoch: 146 [4000/8892 (45%)]\t training loss: 28.0\n",
            "epoch: 146 [4500/8892 (51%)]\t training loss: 27.5\n",
            "epoch: 146 [5000/8892 (56%)]\t training loss: 21.8\n",
            "epoch: 146 [5500/8892 (62%)]\t training loss: 21.5\n",
            "epoch: 146 [6000/8892 (67%)]\t training loss: 28.1\n",
            "epoch: 146 [6500/8892 (73%)]\t training loss: 21.5\n",
            "epoch: 146 [7000/8892 (79%)]\t training loss: 20.5\n",
            "epoch: 146 [7500/8892 (84%)]\t training loss: 20.6\n",
            "epoch: 146 [8000/8892 (90%)]\t training loss: 22.5\n",
            "epoch: 146 [8500/8892 (96%)]\t training loss: 22.7\n",
            "\n",
            "Test dataset: Overall Loss: 1034.5,  (1.05%)\n",
            "\n",
            "epoch: 147 [0/8892 (0%)]\t training loss: 26.3\n",
            "epoch: 147 [500/8892 (6%)]\t training loss: 23.4\n",
            "epoch: 147 [1000/8892 (11%)]\t training loss: 25.6\n",
            "epoch: 147 [1500/8892 (17%)]\t training loss: 20.5\n",
            "epoch: 147 [2000/8892 (22%)]\t training loss: 25.9\n",
            "epoch: 147 [2500/8892 (28%)]\t training loss: 25.6\n",
            "epoch: 147 [3000/8892 (34%)]\t training loss: 23.6\n",
            "epoch: 147 [3500/8892 (39%)]\t training loss: 25.3\n",
            "epoch: 147 [4000/8892 (45%)]\t training loss: 20.0\n",
            "epoch: 147 [4500/8892 (51%)]\t training loss: 35.2\n",
            "epoch: 147 [5000/8892 (56%)]\t training loss: 20.6\n",
            "epoch: 147 [5500/8892 (62%)]\t training loss: 25.3\n",
            "epoch: 147 [6000/8892 (67%)]\t training loss: 27.2\n",
            "epoch: 147 [6500/8892 (73%)]\t training loss: 22.1\n",
            "epoch: 147 [7000/8892 (79%)]\t training loss: 21.9\n",
            "epoch: 147 [7500/8892 (84%)]\t training loss: 30.9\n",
            "epoch: 147 [8000/8892 (90%)]\t training loss: 22.7\n",
            "epoch: 147 [8500/8892 (96%)]\t training loss: 24.0\n",
            "\n",
            "Test dataset: Overall Loss: 1028.0,  (1.04%)\n",
            "\n",
            "epoch: 148 [0/8892 (0%)]\t training loss: 25.6\n",
            "epoch: 148 [500/8892 (6%)]\t training loss: 29.0\n",
            "epoch: 148 [1000/8892 (11%)]\t training loss: 24.4\n",
            "epoch: 148 [1500/8892 (17%)]\t training loss: 22.0\n",
            "epoch: 148 [2000/8892 (22%)]\t training loss: 20.1\n",
            "epoch: 148 [2500/8892 (28%)]\t training loss: 20.1\n",
            "epoch: 148 [3000/8892 (34%)]\t training loss: 27.6\n",
            "epoch: 148 [3500/8892 (39%)]\t training loss: 19.6\n",
            "epoch: 148 [4000/8892 (45%)]\t training loss: 23.5\n",
            "epoch: 148 [4500/8892 (51%)]\t training loss: 32.7\n",
            "epoch: 148 [5000/8892 (56%)]\t training loss: 23.5\n",
            "epoch: 148 [5500/8892 (62%)]\t training loss: 25.4\n",
            "epoch: 148 [6000/8892 (67%)]\t training loss: 23.9\n",
            "epoch: 148 [6500/8892 (73%)]\t training loss: 27.5\n",
            "epoch: 148 [7000/8892 (79%)]\t training loss: 23.5\n",
            "epoch: 148 [7500/8892 (84%)]\t training loss: 21.4\n",
            "epoch: 148 [8000/8892 (90%)]\t training loss: 30.1\n",
            "epoch: 148 [8500/8892 (96%)]\t training loss: 27.0\n",
            "\n",
            "Test dataset: Overall Loss: 1028.3,  (1.04%)\n",
            "\n",
            "epoch: 149 [0/8892 (0%)]\t training loss: 23.6\n",
            "epoch: 149 [500/8892 (6%)]\t training loss: 29.4\n",
            "epoch: 149 [1000/8892 (11%)]\t training loss: 28.3\n",
            "epoch: 149 [1500/8892 (17%)]\t training loss: 25.2\n",
            "epoch: 149 [2000/8892 (22%)]\t training loss: 20.6\n",
            "epoch: 149 [2500/8892 (28%)]\t training loss: 23.5\n",
            "epoch: 149 [3000/8892 (34%)]\t training loss: 17.1\n",
            "epoch: 149 [3500/8892 (39%)]\t training loss: 24.5\n",
            "epoch: 149 [4000/8892 (45%)]\t training loss: 20.7\n",
            "epoch: 149 [4500/8892 (51%)]\t training loss: 31.3\n",
            "epoch: 149 [5000/8892 (56%)]\t training loss: 17.6\n",
            "epoch: 149 [5500/8892 (62%)]\t training loss: 23.1\n",
            "epoch: 149 [6000/8892 (67%)]\t training loss: 22.8\n",
            "epoch: 149 [6500/8892 (73%)]\t training loss: 29.4\n",
            "epoch: 149 [7000/8892 (79%)]\t training loss: 30.4\n",
            "epoch: 149 [7500/8892 (84%)]\t training loss: 20.2\n",
            "epoch: 149 [8000/8892 (90%)]\t training loss: 19.8\n",
            "epoch: 149 [8500/8892 (96%)]\t training loss: 29.5\n",
            "\n",
            "Test dataset: Overall Loss: 1026.7,  (1.04%)\n",
            "\n",
            "epoch: 150 [0/8892 (0%)]\t training loss: 29.0\n",
            "epoch: 150 [500/8892 (6%)]\t training loss: 21.5\n",
            "epoch: 150 [1000/8892 (11%)]\t training loss: 21.9\n",
            "epoch: 150 [1500/8892 (17%)]\t training loss: 26.4\n",
            "epoch: 150 [2000/8892 (22%)]\t training loss: 18.0\n",
            "epoch: 150 [2500/8892 (28%)]\t training loss: 19.9\n",
            "epoch: 150 [3000/8892 (34%)]\t training loss: 18.2\n",
            "epoch: 150 [3500/8892 (39%)]\t training loss: 34.4\n",
            "epoch: 150 [4000/8892 (45%)]\t training loss: 26.4\n",
            "epoch: 150 [4500/8892 (51%)]\t training loss: 24.3\n",
            "epoch: 150 [5000/8892 (56%)]\t training loss: 24.0\n",
            "epoch: 150 [5500/8892 (62%)]\t training loss: 19.1\n",
            "epoch: 150 [6000/8892 (67%)]\t training loss: 30.3\n",
            "epoch: 150 [6500/8892 (73%)]\t training loss: 20.1\n",
            "epoch: 150 [7000/8892 (79%)]\t training loss: 29.9\n",
            "epoch: 150 [7500/8892 (84%)]\t training loss: 24.5\n",
            "epoch: 150 [8000/8892 (90%)]\t training loss: 26.1\n",
            "epoch: 150 [8500/8892 (96%)]\t training loss: 24.3\n",
            "\n",
            "Test dataset: Overall Loss: 1038.9,  (1.05%)\n",
            "\n",
            "epoch: 151 [0/8892 (0%)]\t training loss: 31.4\n",
            "epoch: 151 [500/8892 (6%)]\t training loss: 21.8\n",
            "epoch: 151 [1000/8892 (11%)]\t training loss: 22.0\n",
            "epoch: 151 [1500/8892 (17%)]\t training loss: 25.7\n",
            "epoch: 151 [2000/8892 (22%)]\t training loss: 30.6\n",
            "epoch: 151 [2500/8892 (28%)]\t training loss: 25.5\n",
            "epoch: 151 [3000/8892 (34%)]\t training loss: 20.8\n",
            "epoch: 151 [3500/8892 (39%)]\t training loss: 22.7\n",
            "epoch: 151 [4000/8892 (45%)]\t training loss: 26.0\n",
            "epoch: 151 [4500/8892 (51%)]\t training loss: 23.0\n",
            "epoch: 151 [5000/8892 (56%)]\t training loss: 28.6\n",
            "epoch: 151 [5500/8892 (62%)]\t training loss: 17.4\n",
            "epoch: 151 [6000/8892 (67%)]\t training loss: 26.7\n",
            "epoch: 151 [6500/8892 (73%)]\t training loss: 27.3\n",
            "epoch: 151 [7000/8892 (79%)]\t training loss: 22.0\n",
            "epoch: 151 [7500/8892 (84%)]\t training loss: 24.9\n",
            "epoch: 151 [8000/8892 (90%)]\t training loss: 24.6\n",
            "epoch: 151 [8500/8892 (96%)]\t training loss: 29.9\n",
            "\n",
            "Test dataset: Overall Loss: 1026.7,  (1.04%)\n",
            "\n",
            "epoch: 152 [0/8892 (0%)]\t training loss: 25.7\n",
            "epoch: 152 [500/8892 (6%)]\t training loss: 19.9\n",
            "epoch: 152 [1000/8892 (11%)]\t training loss: 22.9\n",
            "epoch: 152 [1500/8892 (17%)]\t training loss: 22.7\n",
            "epoch: 152 [2000/8892 (22%)]\t training loss: 23.4\n",
            "epoch: 152 [2500/8892 (28%)]\t training loss: 32.4\n",
            "epoch: 152 [3000/8892 (34%)]\t training loss: 27.8\n",
            "epoch: 152 [3500/8892 (39%)]\t training loss: 31.7\n",
            "epoch: 152 [4000/8892 (45%)]\t training loss: 25.0\n",
            "epoch: 152 [4500/8892 (51%)]\t training loss: 20.5\n",
            "epoch: 152 [5000/8892 (56%)]\t training loss: 25.1\n",
            "epoch: 152 [5500/8892 (62%)]\t training loss: 22.1\n",
            "epoch: 152 [6000/8892 (67%)]\t training loss: 26.2\n",
            "epoch: 152 [6500/8892 (73%)]\t training loss: 34.7\n",
            "epoch: 152 [7000/8892 (79%)]\t training loss: 25.9\n",
            "epoch: 152 [7500/8892 (84%)]\t training loss: 26.2\n",
            "epoch: 152 [8000/8892 (90%)]\t training loss: 26.6\n",
            "epoch: 152 [8500/8892 (96%)]\t training loss: 20.1\n",
            "\n",
            "Test dataset: Overall Loss: 1027.3,  (1.04%)\n",
            "\n",
            "epoch: 153 [0/8892 (0%)]\t training loss: 26.4\n",
            "epoch: 153 [500/8892 (6%)]\t training loss: 30.3\n",
            "epoch: 153 [1000/8892 (11%)]\t training loss: 28.4\n",
            "epoch: 153 [1500/8892 (17%)]\t training loss: 24.6\n",
            "epoch: 153 [2000/8892 (22%)]\t training loss: 32.4\n",
            "epoch: 153 [2500/8892 (28%)]\t training loss: 29.5\n",
            "epoch: 153 [3000/8892 (34%)]\t training loss: 23.6\n",
            "epoch: 153 [3500/8892 (39%)]\t training loss: 25.6\n",
            "epoch: 153 [4000/8892 (45%)]\t training loss: 34.3\n",
            "epoch: 153 [4500/8892 (51%)]\t training loss: 21.4\n",
            "epoch: 153 [5000/8892 (56%)]\t training loss: 23.2\n",
            "epoch: 153 [5500/8892 (62%)]\t training loss: 29.7\n",
            "epoch: 153 [6000/8892 (67%)]\t training loss: 28.7\n",
            "epoch: 153 [6500/8892 (73%)]\t training loss: 23.3\n",
            "epoch: 153 [7000/8892 (79%)]\t training loss: 22.4\n",
            "epoch: 153 [7500/8892 (84%)]\t training loss: 25.8\n",
            "epoch: 153 [8000/8892 (90%)]\t training loss: 22.4\n",
            "epoch: 153 [8500/8892 (96%)]\t training loss: 28.9\n",
            "\n",
            "Test dataset: Overall Loss: 1038.0,  (1.05%)\n",
            "\n",
            "epoch: 154 [0/8892 (0%)]\t training loss: 21.8\n",
            "epoch: 154 [500/8892 (6%)]\t training loss: 22.6\n",
            "epoch: 154 [1000/8892 (11%)]\t training loss: 24.3\n",
            "epoch: 154 [1500/8892 (17%)]\t training loss: 22.4\n",
            "epoch: 154 [2000/8892 (22%)]\t training loss: 20.8\n",
            "epoch: 154 [2500/8892 (28%)]\t training loss: 20.1\n",
            "epoch: 154 [3000/8892 (34%)]\t training loss: 25.1\n",
            "epoch: 154 [3500/8892 (39%)]\t training loss: 18.8\n",
            "epoch: 154 [4000/8892 (45%)]\t training loss: 23.5\n",
            "epoch: 154 [4500/8892 (51%)]\t training loss: 20.7\n",
            "epoch: 154 [5000/8892 (56%)]\t training loss: 25.9\n",
            "epoch: 154 [5500/8892 (62%)]\t training loss: 25.7\n",
            "epoch: 154 [6000/8892 (67%)]\t training loss: 26.2\n",
            "epoch: 154 [6500/8892 (73%)]\t training loss: 24.7\n",
            "epoch: 154 [7000/8892 (79%)]\t training loss: 23.6\n",
            "epoch: 154 [7500/8892 (84%)]\t training loss: 23.0\n",
            "epoch: 154 [8000/8892 (90%)]\t training loss: 30.7\n",
            "epoch: 154 [8500/8892 (96%)]\t training loss: 27.5\n",
            "\n",
            "Test dataset: Overall Loss: 1036.5,  (1.05%)\n",
            "\n",
            "epoch: 155 [0/8892 (0%)]\t training loss: 21.9\n",
            "epoch: 155 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 155 [1000/8892 (11%)]\t training loss: 27.1\n",
            "epoch: 155 [1500/8892 (17%)]\t training loss: 27.2\n",
            "epoch: 155 [2000/8892 (22%)]\t training loss: 28.6\n",
            "epoch: 155 [2500/8892 (28%)]\t training loss: 23.5\n",
            "epoch: 155 [3000/8892 (34%)]\t training loss: 21.9\n",
            "epoch: 155 [3500/8892 (39%)]\t training loss: 24.2\n",
            "epoch: 155 [4000/8892 (45%)]\t training loss: 24.9\n",
            "epoch: 155 [4500/8892 (51%)]\t training loss: 25.3\n",
            "epoch: 155 [5000/8892 (56%)]\t training loss: 21.0\n",
            "epoch: 155 [5500/8892 (62%)]\t training loss: 22.7\n",
            "epoch: 155 [6000/8892 (67%)]\t training loss: 22.8\n",
            "epoch: 155 [6500/8892 (73%)]\t training loss: 25.4\n",
            "epoch: 155 [7000/8892 (79%)]\t training loss: 28.2\n",
            "epoch: 155 [7500/8892 (84%)]\t training loss: 21.9\n",
            "epoch: 155 [8000/8892 (90%)]\t training loss: 24.7\n",
            "epoch: 155 [8500/8892 (96%)]\t training loss: 29.1\n",
            "\n",
            "Test dataset: Overall Loss: 1044.2,  (1.06%)\n",
            "\n",
            "epoch: 156 [0/8892 (0%)]\t training loss: 23.6\n",
            "epoch: 156 [500/8892 (6%)]\t training loss: 22.6\n",
            "epoch: 156 [1000/8892 (11%)]\t training loss: 19.3\n",
            "epoch: 156 [1500/8892 (17%)]\t training loss: 21.2\n",
            "epoch: 156 [2000/8892 (22%)]\t training loss: 23.9\n",
            "epoch: 156 [2500/8892 (28%)]\t training loss: 19.2\n",
            "epoch: 156 [3000/8892 (34%)]\t training loss: 19.4\n",
            "epoch: 156 [3500/8892 (39%)]\t training loss: 21.5\n",
            "epoch: 156 [4000/8892 (45%)]\t training loss: 24.6\n",
            "epoch: 156 [4500/8892 (51%)]\t training loss: 27.0\n",
            "epoch: 156 [5000/8892 (56%)]\t training loss: 25.3\n",
            "epoch: 156 [5500/8892 (62%)]\t training loss: 20.0\n",
            "epoch: 156 [6000/8892 (67%)]\t training loss: 24.3\n",
            "epoch: 156 [6500/8892 (73%)]\t training loss: 20.4\n",
            "epoch: 156 [7000/8892 (79%)]\t training loss: 22.6\n",
            "epoch: 156 [7500/8892 (84%)]\t training loss: 29.9\n",
            "epoch: 156 [8000/8892 (90%)]\t training loss: 26.0\n",
            "epoch: 156 [8500/8892 (96%)]\t training loss: 26.8\n",
            "\n",
            "Test dataset: Overall Loss: 1045.5,  (1.06%)\n",
            "\n",
            "epoch: 157 [0/8892 (0%)]\t training loss: 24.8\n",
            "epoch: 157 [500/8892 (6%)]\t training loss: 23.9\n",
            "epoch: 157 [1000/8892 (11%)]\t training loss: 21.0\n",
            "epoch: 157 [1500/8892 (17%)]\t training loss: 31.8\n",
            "epoch: 157 [2000/8892 (22%)]\t training loss: 22.2\n",
            "epoch: 157 [2500/8892 (28%)]\t training loss: 18.2\n",
            "epoch: 157 [3000/8892 (34%)]\t training loss: 26.2\n",
            "epoch: 157 [3500/8892 (39%)]\t training loss: 30.5\n",
            "epoch: 157 [4000/8892 (45%)]\t training loss: 22.7\n",
            "epoch: 157 [4500/8892 (51%)]\t training loss: 27.5\n",
            "epoch: 157 [5000/8892 (56%)]\t training loss: 24.0\n",
            "epoch: 157 [5500/8892 (62%)]\t training loss: 28.0\n",
            "epoch: 157 [6000/8892 (67%)]\t training loss: 30.5\n",
            "epoch: 157 [6500/8892 (73%)]\t training loss: 27.9\n",
            "epoch: 157 [7000/8892 (79%)]\t training loss: 19.6\n",
            "epoch: 157 [7500/8892 (84%)]\t training loss: 21.3\n",
            "epoch: 157 [8000/8892 (90%)]\t training loss: 25.4\n",
            "epoch: 157 [8500/8892 (96%)]\t training loss: 23.1\n",
            "\n",
            "Test dataset: Overall Loss: 1039.5,  (1.05%)\n",
            "\n",
            "epoch: 158 [0/8892 (0%)]\t training loss: 17.8\n",
            "epoch: 158 [500/8892 (6%)]\t training loss: 25.9\n",
            "epoch: 158 [1000/8892 (11%)]\t training loss: 21.3\n",
            "epoch: 158 [1500/8892 (17%)]\t training loss: 23.4\n",
            "epoch: 158 [2000/8892 (22%)]\t training loss: 23.2\n",
            "epoch: 158 [2500/8892 (28%)]\t training loss: 22.0\n",
            "epoch: 158 [3000/8892 (34%)]\t training loss: 24.5\n",
            "epoch: 158 [3500/8892 (39%)]\t training loss: 21.5\n",
            "epoch: 158 [4000/8892 (45%)]\t training loss: 23.7\n",
            "epoch: 158 [4500/8892 (51%)]\t training loss: 29.0\n",
            "epoch: 158 [5000/8892 (56%)]\t training loss: 28.1\n",
            "epoch: 158 [5500/8892 (62%)]\t training loss: 23.9\n",
            "epoch: 158 [6000/8892 (67%)]\t training loss: 23.1\n",
            "epoch: 158 [6500/8892 (73%)]\t training loss: 22.1\n",
            "epoch: 158 [7000/8892 (79%)]\t training loss: 20.9\n",
            "epoch: 158 [7500/8892 (84%)]\t training loss: 18.7\n",
            "epoch: 158 [8000/8892 (90%)]\t training loss: 28.1\n",
            "epoch: 158 [8500/8892 (96%)]\t training loss: 25.1\n",
            "\n",
            "Test dataset: Overall Loss: 1050.0,  (1.06%)\n",
            "\n",
            "epoch: 159 [0/8892 (0%)]\t training loss: 22.3\n",
            "epoch: 159 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 159 [1000/8892 (11%)]\t training loss: 23.4\n",
            "epoch: 159 [1500/8892 (17%)]\t training loss: 22.6\n",
            "epoch: 159 [2000/8892 (22%)]\t training loss: 28.0\n",
            "epoch: 159 [2500/8892 (28%)]\t training loss: 23.8\n",
            "epoch: 159 [3000/8892 (34%)]\t training loss: 22.7\n",
            "epoch: 159 [3500/8892 (39%)]\t training loss: 26.3\n",
            "epoch: 159 [4000/8892 (45%)]\t training loss: 18.7\n",
            "epoch: 159 [4500/8892 (51%)]\t training loss: 21.6\n",
            "epoch: 159 [5000/8892 (56%)]\t training loss: 30.1\n",
            "epoch: 159 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 159 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 159 [6500/8892 (73%)]\t training loss: 22.0\n",
            "epoch: 159 [7000/8892 (79%)]\t training loss: 23.4\n",
            "epoch: 159 [7500/8892 (84%)]\t training loss: 21.9\n",
            "epoch: 159 [8000/8892 (90%)]\t training loss: 20.5\n",
            "epoch: 159 [8500/8892 (96%)]\t training loss: 25.8\n",
            "\n",
            "Test dataset: Overall Loss: 1036.7,  (1.05%)\n",
            "\n",
            "epoch: 160 [0/8892 (0%)]\t training loss: 22.7\n",
            "epoch: 160 [500/8892 (6%)]\t training loss: 23.7\n",
            "epoch: 160 [1000/8892 (11%)]\t training loss: 28.8\n",
            "epoch: 160 [1500/8892 (17%)]\t training loss: 29.1\n",
            "epoch: 160 [2000/8892 (22%)]\t training loss: 26.4\n",
            "epoch: 160 [2500/8892 (28%)]\t training loss: 23.0\n",
            "epoch: 160 [3000/8892 (34%)]\t training loss: 23.3\n",
            "epoch: 160 [3500/8892 (39%)]\t training loss: 22.7\n",
            "epoch: 160 [4000/8892 (45%)]\t training loss: 27.1\n",
            "epoch: 160 [4500/8892 (51%)]\t training loss: 19.1\n",
            "epoch: 160 [5000/8892 (56%)]\t training loss: 25.8\n",
            "epoch: 160 [5500/8892 (62%)]\t training loss: 27.6\n",
            "epoch: 160 [6000/8892 (67%)]\t training loss: 24.5\n",
            "epoch: 160 [6500/8892 (73%)]\t training loss: 28.4\n",
            "epoch: 160 [7000/8892 (79%)]\t training loss: 25.3\n",
            "epoch: 160 [7500/8892 (84%)]\t training loss: 29.9\n",
            "epoch: 160 [8000/8892 (90%)]\t training loss: 28.5\n",
            "epoch: 160 [8500/8892 (96%)]\t training loss: 24.0\n",
            "\n",
            "Test dataset: Overall Loss: 1031.2,  (1.04%)\n",
            "\n",
            "epoch: 161 [0/8892 (0%)]\t training loss: 24.6\n",
            "epoch: 161 [500/8892 (6%)]\t training loss: 22.7\n",
            "epoch: 161 [1000/8892 (11%)]\t training loss: 27.3\n",
            "epoch: 161 [1500/8892 (17%)]\t training loss: 22.7\n",
            "epoch: 161 [2000/8892 (22%)]\t training loss: 24.3\n",
            "epoch: 161 [2500/8892 (28%)]\t training loss: 28.4\n",
            "epoch: 161 [3000/8892 (34%)]\t training loss: 25.2\n",
            "epoch: 161 [3500/8892 (39%)]\t training loss: 27.6\n",
            "epoch: 161 [4000/8892 (45%)]\t training loss: 25.7\n",
            "epoch: 161 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 161 [5000/8892 (56%)]\t training loss: 18.6\n",
            "epoch: 161 [5500/8892 (62%)]\t training loss: 24.6\n",
            "epoch: 161 [6000/8892 (67%)]\t training loss: 22.0\n",
            "epoch: 161 [6500/8892 (73%)]\t training loss: 25.0\n",
            "epoch: 161 [7000/8892 (79%)]\t training loss: 19.9\n",
            "epoch: 161 [7500/8892 (84%)]\t training loss: 20.7\n",
            "epoch: 161 [8000/8892 (90%)]\t training loss: 31.4\n",
            "epoch: 161 [8500/8892 (96%)]\t training loss: 22.5\n",
            "\n",
            "Test dataset: Overall Loss: 1032.4,  (1.04%)\n",
            "\n",
            "epoch: 162 [0/8892 (0%)]\t training loss: 14.5\n",
            "epoch: 162 [500/8892 (6%)]\t training loss: 22.6\n",
            "epoch: 162 [1000/8892 (11%)]\t training loss: 20.1\n",
            "epoch: 162 [1500/8892 (17%)]\t training loss: 29.6\n",
            "epoch: 162 [2000/8892 (22%)]\t training loss: 29.0\n",
            "epoch: 162 [2500/8892 (28%)]\t training loss: 28.0\n",
            "epoch: 162 [3000/8892 (34%)]\t training loss: 21.2\n",
            "epoch: 162 [3500/8892 (39%)]\t training loss: 23.1\n",
            "epoch: 162 [4000/8892 (45%)]\t training loss: 20.9\n",
            "epoch: 162 [4500/8892 (51%)]\t training loss: 18.7\n",
            "epoch: 162 [5000/8892 (56%)]\t training loss: 24.2\n",
            "epoch: 162 [5500/8892 (62%)]\t training loss: 22.9\n",
            "epoch: 162 [6000/8892 (67%)]\t training loss: 27.7\n",
            "epoch: 162 [6500/8892 (73%)]\t training loss: 24.1\n",
            "epoch: 162 [7000/8892 (79%)]\t training loss: 22.5\n",
            "epoch: 162 [7500/8892 (84%)]\t training loss: 21.7\n",
            "epoch: 162 [8000/8892 (90%)]\t training loss: 24.1\n",
            "epoch: 162 [8500/8892 (96%)]\t training loss: 24.2\n",
            "\n",
            "Test dataset: Overall Loss: 1034.2,  (1.05%)\n",
            "\n",
            "epoch: 163 [0/8892 (0%)]\t training loss: 23.1\n",
            "epoch: 163 [500/8892 (6%)]\t training loss: 19.7\n",
            "epoch: 163 [1000/8892 (11%)]\t training loss: 18.3\n",
            "epoch: 163 [1500/8892 (17%)]\t training loss: 25.6\n",
            "epoch: 163 [2000/8892 (22%)]\t training loss: 24.6\n",
            "epoch: 163 [2500/8892 (28%)]\t training loss: 27.3\n",
            "epoch: 163 [3000/8892 (34%)]\t training loss: 24.5\n",
            "epoch: 163 [3500/8892 (39%)]\t training loss: 23.6\n",
            "epoch: 163 [4000/8892 (45%)]\t training loss: 22.8\n",
            "epoch: 163 [4500/8892 (51%)]\t training loss: 24.9\n",
            "epoch: 163 [5000/8892 (56%)]\t training loss: 25.3\n",
            "epoch: 163 [5500/8892 (62%)]\t training loss: 23.7\n",
            "epoch: 163 [6000/8892 (67%)]\t training loss: 23.1\n",
            "epoch: 163 [6500/8892 (73%)]\t training loss: 23.8\n",
            "epoch: 163 [7000/8892 (79%)]\t training loss: 29.4\n",
            "epoch: 163 [7500/8892 (84%)]\t training loss: 25.7\n",
            "epoch: 163 [8000/8892 (90%)]\t training loss: 26.5\n",
            "epoch: 163 [8500/8892 (96%)]\t training loss: 21.2\n",
            "\n",
            "Test dataset: Overall Loss: 1027.2,  (1.04%)\n",
            "\n",
            "epoch: 164 [0/8892 (0%)]\t training loss: 21.5\n",
            "epoch: 164 [500/8892 (6%)]\t training loss: 21.8\n",
            "epoch: 164 [1000/8892 (11%)]\t training loss: 25.9\n",
            "epoch: 164 [1500/8892 (17%)]\t training loss: 24.1\n",
            "epoch: 164 [2000/8892 (22%)]\t training loss: 26.0\n",
            "epoch: 164 [2500/8892 (28%)]\t training loss: 26.5\n",
            "epoch: 164 [3000/8892 (34%)]\t training loss: 25.2\n",
            "epoch: 164 [3500/8892 (39%)]\t training loss: 28.0\n",
            "epoch: 164 [4000/8892 (45%)]\t training loss: 18.4\n",
            "epoch: 164 [4500/8892 (51%)]\t training loss: 19.9\n",
            "epoch: 164 [5000/8892 (56%)]\t training loss: 25.2\n",
            "epoch: 164 [5500/8892 (62%)]\t training loss: 19.7\n",
            "epoch: 164 [6000/8892 (67%)]\t training loss: 21.5\n",
            "epoch: 164 [6500/8892 (73%)]\t training loss: 23.9\n",
            "epoch: 164 [7000/8892 (79%)]\t training loss: 21.4\n",
            "epoch: 164 [7500/8892 (84%)]\t training loss: 30.6\n",
            "epoch: 164 [8000/8892 (90%)]\t training loss: 24.7\n",
            "epoch: 164 [8500/8892 (96%)]\t training loss: 24.6\n",
            "\n",
            "Test dataset: Overall Loss: 1033.6,  (1.05%)\n",
            "\n",
            "epoch: 165 [0/8892 (0%)]\t training loss: 20.6\n",
            "epoch: 165 [500/8892 (6%)]\t training loss: 24.5\n",
            "epoch: 165 [1000/8892 (11%)]\t training loss: 38.8\n",
            "epoch: 165 [1500/8892 (17%)]\t training loss: 20.7\n",
            "epoch: 165 [2000/8892 (22%)]\t training loss: 21.4\n",
            "epoch: 165 [2500/8892 (28%)]\t training loss: 26.1\n",
            "epoch: 165 [3000/8892 (34%)]\t training loss: 24.2\n",
            "epoch: 165 [3500/8892 (39%)]\t training loss: 30.9\n",
            "epoch: 165 [4000/8892 (45%)]\t training loss: 20.5\n",
            "epoch: 165 [4500/8892 (51%)]\t training loss: 18.9\n",
            "epoch: 165 [5000/8892 (56%)]\t training loss: 26.5\n",
            "epoch: 165 [5500/8892 (62%)]\t training loss: 25.4\n",
            "epoch: 165 [6000/8892 (67%)]\t training loss: 26.8\n",
            "epoch: 165 [6500/8892 (73%)]\t training loss: 29.5\n",
            "epoch: 165 [7000/8892 (79%)]\t training loss: 24.1\n",
            "epoch: 165 [7500/8892 (84%)]\t training loss: 23.9\n",
            "epoch: 165 [8000/8892 (90%)]\t training loss: 23.0\n",
            "epoch: 165 [8500/8892 (96%)]\t training loss: 22.8\n",
            "\n",
            "Test dataset: Overall Loss: 1034.4,  (1.05%)\n",
            "\n",
            "epoch: 166 [0/8892 (0%)]\t training loss: 24.8\n",
            "epoch: 166 [500/8892 (6%)]\t training loss: 20.9\n",
            "epoch: 166 [1000/8892 (11%)]\t training loss: 17.2\n",
            "epoch: 166 [1500/8892 (17%)]\t training loss: 23.5\n",
            "epoch: 166 [2000/8892 (22%)]\t training loss: 20.6\n",
            "epoch: 166 [2500/8892 (28%)]\t training loss: 17.2\n",
            "epoch: 166 [3000/8892 (34%)]\t training loss: 23.6\n",
            "epoch: 166 [3500/8892 (39%)]\t training loss: 23.1\n",
            "epoch: 166 [4000/8892 (45%)]\t training loss: 26.4\n",
            "epoch: 166 [4500/8892 (51%)]\t training loss: 19.8\n",
            "epoch: 166 [5000/8892 (56%)]\t training loss: 18.7\n",
            "epoch: 166 [5500/8892 (62%)]\t training loss: 23.2\n",
            "epoch: 166 [6000/8892 (67%)]\t training loss: 24.5\n",
            "epoch: 166 [6500/8892 (73%)]\t training loss: 19.3\n",
            "epoch: 166 [7000/8892 (79%)]\t training loss: 24.0\n",
            "epoch: 166 [7500/8892 (84%)]\t training loss: 28.4\n",
            "epoch: 166 [8000/8892 (90%)]\t training loss: 18.7\n",
            "epoch: 166 [8500/8892 (96%)]\t training loss: 25.6\n",
            "\n",
            "Test dataset: Overall Loss: 1034.0,  (1.05%)\n",
            "\n",
            "epoch: 167 [0/8892 (0%)]\t training loss: 23.9\n",
            "epoch: 167 [500/8892 (6%)]\t training loss: 27.9\n",
            "epoch: 167 [1000/8892 (11%)]\t training loss: 28.4\n",
            "epoch: 167 [1500/8892 (17%)]\t training loss: 21.7\n",
            "epoch: 167 [2000/8892 (22%)]\t training loss: 24.8\n",
            "epoch: 167 [2500/8892 (28%)]\t training loss: 26.4\n",
            "epoch: 167 [3000/8892 (34%)]\t training loss: 23.9\n",
            "epoch: 167 [3500/8892 (39%)]\t training loss: 26.4\n",
            "epoch: 167 [4000/8892 (45%)]\t training loss: 19.8\n",
            "epoch: 167 [4500/8892 (51%)]\t training loss: 19.3\n",
            "epoch: 167 [5000/8892 (56%)]\t training loss: 23.7\n",
            "epoch: 167 [5500/8892 (62%)]\t training loss: 21.8\n",
            "epoch: 167 [6000/8892 (67%)]\t training loss: 29.5\n",
            "epoch: 167 [6500/8892 (73%)]\t training loss: 29.3\n",
            "epoch: 167 [7000/8892 (79%)]\t training loss: 24.4\n",
            "epoch: 167 [7500/8892 (84%)]\t training loss: 21.2\n",
            "epoch: 167 [8000/8892 (90%)]\t training loss: 18.9\n",
            "epoch: 167 [8500/8892 (96%)]\t training loss: 31.8\n",
            "\n",
            "Test dataset: Overall Loss: 1029.7,  (1.04%)\n",
            "\n",
            "epoch: 168 [0/8892 (0%)]\t training loss: 30.2\n",
            "epoch: 168 [500/8892 (6%)]\t training loss: 28.2\n",
            "epoch: 168 [1000/8892 (11%)]\t training loss: 29.8\n",
            "epoch: 168 [1500/8892 (17%)]\t training loss: 21.7\n",
            "epoch: 168 [2000/8892 (22%)]\t training loss: 18.5\n",
            "epoch: 168 [2500/8892 (28%)]\t training loss: 20.1\n",
            "epoch: 168 [3000/8892 (34%)]\t training loss: 22.2\n",
            "epoch: 168 [3500/8892 (39%)]\t training loss: 20.5\n",
            "epoch: 168 [4000/8892 (45%)]\t training loss: 25.5\n",
            "epoch: 168 [4500/8892 (51%)]\t training loss: 23.2\n",
            "epoch: 168 [5000/8892 (56%)]\t training loss: 22.9\n",
            "epoch: 168 [5500/8892 (62%)]\t training loss: 25.2\n",
            "epoch: 168 [6000/8892 (67%)]\t training loss: 26.9\n",
            "epoch: 168 [6500/8892 (73%)]\t training loss: 27.4\n",
            "epoch: 168 [7000/8892 (79%)]\t training loss: 20.7\n",
            "epoch: 168 [7500/8892 (84%)]\t training loss: 29.2\n",
            "epoch: 168 [8000/8892 (90%)]\t training loss: 27.8\n",
            "epoch: 168 [8500/8892 (96%)]\t training loss: 19.7\n",
            "\n",
            "Test dataset: Overall Loss: 1033.6,  (1.05%)\n",
            "\n",
            "epoch: 169 [0/8892 (0%)]\t training loss: 21.7\n",
            "epoch: 169 [500/8892 (6%)]\t training loss: 19.1\n",
            "epoch: 169 [1000/8892 (11%)]\t training loss: 28.3\n",
            "epoch: 169 [1500/8892 (17%)]\t training loss: 19.8\n",
            "epoch: 169 [2000/8892 (22%)]\t training loss: 24.2\n",
            "epoch: 169 [2500/8892 (28%)]\t training loss: 22.5\n",
            "epoch: 169 [3000/8892 (34%)]\t training loss: 24.8\n",
            "epoch: 169 [3500/8892 (39%)]\t training loss: 24.7\n",
            "epoch: 169 [4000/8892 (45%)]\t training loss: 22.8\n",
            "epoch: 169 [4500/8892 (51%)]\t training loss: 26.3\n",
            "epoch: 169 [5000/8892 (56%)]\t training loss: 20.1\n",
            "epoch: 169 [5500/8892 (62%)]\t training loss: 22.7\n",
            "epoch: 169 [6000/8892 (67%)]\t training loss: 28.7\n",
            "epoch: 169 [6500/8892 (73%)]\t training loss: 28.8\n",
            "epoch: 169 [7000/8892 (79%)]\t training loss: 21.6\n",
            "epoch: 169 [7500/8892 (84%)]\t training loss: 28.3\n",
            "epoch: 169 [8000/8892 (90%)]\t training loss: 18.2\n",
            "epoch: 169 [8500/8892 (96%)]\t training loss: 21.2\n",
            "\n",
            "Test dataset: Overall Loss: 1028.2,  (1.04%)\n",
            "\n",
            "epoch: 170 [0/8892 (0%)]\t training loss: 27.8\n",
            "epoch: 170 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 170 [1000/8892 (11%)]\t training loss: 18.5\n",
            "epoch: 170 [1500/8892 (17%)]\t training loss: 23.6\n",
            "epoch: 170 [2000/8892 (22%)]\t training loss: 29.9\n",
            "epoch: 170 [2500/8892 (28%)]\t training loss: 22.8\n",
            "epoch: 170 [3000/8892 (34%)]\t training loss: 17.5\n",
            "epoch: 170 [3500/8892 (39%)]\t training loss: 29.8\n",
            "epoch: 170 [4000/8892 (45%)]\t training loss: 28.7\n",
            "epoch: 170 [4500/8892 (51%)]\t training loss: 18.8\n",
            "epoch: 170 [5000/8892 (56%)]\t training loss: 29.7\n",
            "epoch: 170 [5500/8892 (62%)]\t training loss: 18.3\n",
            "epoch: 170 [6000/8892 (67%)]\t training loss: 20.0\n",
            "epoch: 170 [6500/8892 (73%)]\t training loss: 26.7\n",
            "epoch: 170 [7000/8892 (79%)]\t training loss: 25.4\n",
            "epoch: 170 [7500/8892 (84%)]\t training loss: 26.6\n",
            "epoch: 170 [8000/8892 (90%)]\t training loss: 21.6\n",
            "epoch: 170 [8500/8892 (96%)]\t training loss: 26.4\n",
            "\n",
            "Test dataset: Overall Loss: 1036.0,  (1.05%)\n",
            "\n",
            "epoch: 171 [0/8892 (0%)]\t training loss: 28.2\n",
            "epoch: 171 [500/8892 (6%)]\t training loss: 23.1\n",
            "epoch: 171 [1000/8892 (11%)]\t training loss: 25.2\n",
            "epoch: 171 [1500/8892 (17%)]\t training loss: 18.5\n",
            "epoch: 171 [2000/8892 (22%)]\t training loss: 26.2\n",
            "epoch: 171 [2500/8892 (28%)]\t training loss: 25.8\n",
            "epoch: 171 [3000/8892 (34%)]\t training loss: 25.4\n",
            "epoch: 171 [3500/8892 (39%)]\t training loss: 19.6\n",
            "epoch: 171 [4000/8892 (45%)]\t training loss: 25.8\n",
            "epoch: 171 [4500/8892 (51%)]\t training loss: 29.4\n",
            "epoch: 171 [5000/8892 (56%)]\t training loss: 20.8\n",
            "epoch: 171 [5500/8892 (62%)]\t training loss: 20.0\n",
            "epoch: 171 [6000/8892 (67%)]\t training loss: 19.9\n",
            "epoch: 171 [6500/8892 (73%)]\t training loss: 18.7\n",
            "epoch: 171 [7000/8892 (79%)]\t training loss: 25.8\n",
            "epoch: 171 [7500/8892 (84%)]\t training loss: 24.8\n",
            "epoch: 171 [8000/8892 (90%)]\t training loss: 20.4\n",
            "epoch: 171 [8500/8892 (96%)]\t training loss: 28.6\n",
            "\n",
            "Test dataset: Overall Loss: 1039.1,  (1.05%)\n",
            "\n",
            "epoch: 172 [0/8892 (0%)]\t training loss: 27.4\n",
            "epoch: 172 [500/8892 (6%)]\t training loss: 20.1\n",
            "epoch: 172 [1000/8892 (11%)]\t training loss: 23.6\n",
            "epoch: 172 [1500/8892 (17%)]\t training loss: 16.4\n",
            "epoch: 172 [2000/8892 (22%)]\t training loss: 24.1\n",
            "epoch: 172 [2500/8892 (28%)]\t training loss: 18.4\n",
            "epoch: 172 [3000/8892 (34%)]\t training loss: 27.8\n",
            "epoch: 172 [3500/8892 (39%)]\t training loss: 23.2\n",
            "epoch: 172 [4000/8892 (45%)]\t training loss: 26.5\n",
            "epoch: 172 [4500/8892 (51%)]\t training loss: 18.0\n",
            "epoch: 172 [5000/8892 (56%)]\t training loss: 30.6\n",
            "epoch: 172 [5500/8892 (62%)]\t training loss: 24.3\n",
            "epoch: 172 [6000/8892 (67%)]\t training loss: 24.4\n",
            "epoch: 172 [6500/8892 (73%)]\t training loss: 20.9\n",
            "epoch: 172 [7000/8892 (79%)]\t training loss: 22.7\n",
            "epoch: 172 [7500/8892 (84%)]\t training loss: 21.2\n",
            "epoch: 172 [8000/8892 (90%)]\t training loss: 20.9\n",
            "epoch: 172 [8500/8892 (96%)]\t training loss: 29.4\n",
            "\n",
            "Test dataset: Overall Loss: 1026.9,  (1.04%)\n",
            "\n",
            "epoch: 173 [0/8892 (0%)]\t training loss: 26.5\n",
            "epoch: 173 [500/8892 (6%)]\t training loss: 18.9\n",
            "epoch: 173 [1000/8892 (11%)]\t training loss: 22.8\n",
            "epoch: 173 [1500/8892 (17%)]\t training loss: 22.5\n",
            "epoch: 173 [2000/8892 (22%)]\t training loss: 28.8\n",
            "epoch: 173 [2500/8892 (28%)]\t training loss: 24.1\n",
            "epoch: 173 [3000/8892 (34%)]\t training loss: 23.6\n",
            "epoch: 173 [3500/8892 (39%)]\t training loss: 27.1\n",
            "epoch: 173 [4000/8892 (45%)]\t training loss: 22.0\n",
            "epoch: 173 [4500/8892 (51%)]\t training loss: 18.3\n",
            "epoch: 173 [5000/8892 (56%)]\t training loss: 20.6\n",
            "epoch: 173 [5500/8892 (62%)]\t training loss: 34.1\n",
            "epoch: 173 [6000/8892 (67%)]\t training loss: 27.9\n",
            "epoch: 173 [6500/8892 (73%)]\t training loss: 23.8\n",
            "epoch: 173 [7000/8892 (79%)]\t training loss: 23.1\n",
            "epoch: 173 [7500/8892 (84%)]\t training loss: 23.3\n",
            "epoch: 173 [8000/8892 (90%)]\t training loss: 22.1\n",
            "epoch: 173 [8500/8892 (96%)]\t training loss: 17.6\n",
            "\n",
            "Test dataset: Overall Loss: 1027.3,  (1.04%)\n",
            "\n",
            "epoch: 174 [0/8892 (0%)]\t training loss: 30.4\n",
            "epoch: 174 [500/8892 (6%)]\t training loss: 22.7\n",
            "epoch: 174 [1000/8892 (11%)]\t training loss: 25.7\n",
            "epoch: 174 [1500/8892 (17%)]\t training loss: 25.5\n",
            "epoch: 174 [2000/8892 (22%)]\t training loss: 17.9\n",
            "epoch: 174 [2500/8892 (28%)]\t training loss: 19.6\n",
            "epoch: 174 [3000/8892 (34%)]\t training loss: 22.6\n",
            "epoch: 174 [3500/8892 (39%)]\t training loss: 26.7\n",
            "epoch: 174 [4000/8892 (45%)]\t training loss: 28.7\n",
            "epoch: 174 [4500/8892 (51%)]\t training loss: 25.9\n",
            "epoch: 174 [5000/8892 (56%)]\t training loss: 25.0\n",
            "epoch: 174 [5500/8892 (62%)]\t training loss: 23.3\n",
            "epoch: 174 [6000/8892 (67%)]\t training loss: 24.5\n",
            "epoch: 174 [6500/8892 (73%)]\t training loss: 24.8\n",
            "epoch: 174 [7000/8892 (79%)]\t training loss: 20.7\n",
            "epoch: 174 [7500/8892 (84%)]\t training loss: 22.0\n",
            "epoch: 174 [8000/8892 (90%)]\t training loss: 24.0\n",
            "epoch: 174 [8500/8892 (96%)]\t training loss: 22.6\n",
            "\n",
            "Test dataset: Overall Loss: 1033.5,  (1.05%)\n",
            "\n",
            "epoch: 175 [0/8892 (0%)]\t training loss: 21.0\n",
            "epoch: 175 [500/8892 (6%)]\t training loss: 25.3\n",
            "epoch: 175 [1000/8892 (11%)]\t training loss: 19.9\n",
            "epoch: 175 [1500/8892 (17%)]\t training loss: 26.9\n",
            "epoch: 175 [2000/8892 (22%)]\t training loss: 25.6\n",
            "epoch: 175 [2500/8892 (28%)]\t training loss: 30.2\n",
            "epoch: 175 [3000/8892 (34%)]\t training loss: 28.7\n",
            "epoch: 175 [3500/8892 (39%)]\t training loss: 25.7\n",
            "epoch: 175 [4000/8892 (45%)]\t training loss: 21.7\n",
            "epoch: 175 [4500/8892 (51%)]\t training loss: 28.7\n",
            "epoch: 175 [5000/8892 (56%)]\t training loss: 25.4\n",
            "epoch: 175 [5500/8892 (62%)]\t training loss: 21.1\n",
            "epoch: 175 [6000/8892 (67%)]\t training loss: 23.7\n",
            "epoch: 175 [6500/8892 (73%)]\t training loss: 21.8\n",
            "epoch: 175 [7000/8892 (79%)]\t training loss: 25.6\n",
            "epoch: 175 [7500/8892 (84%)]\t training loss: 19.5\n",
            "epoch: 175 [8000/8892 (90%)]\t training loss: 21.2\n",
            "epoch: 175 [8500/8892 (96%)]\t training loss: 24.1\n",
            "\n",
            "Test dataset: Overall Loss: 1032.9,  (1.05%)\n",
            "\n",
            "epoch: 176 [0/8892 (0%)]\t training loss: 22.2\n",
            "epoch: 176 [500/8892 (6%)]\t training loss: 23.3\n",
            "epoch: 176 [1000/8892 (11%)]\t training loss: 37.0\n",
            "epoch: 176 [1500/8892 (17%)]\t training loss: 22.2\n",
            "epoch: 176 [2000/8892 (22%)]\t training loss: 21.7\n",
            "epoch: 176 [2500/8892 (28%)]\t training loss: 29.4\n",
            "epoch: 176 [3000/8892 (34%)]\t training loss: 19.8\n",
            "epoch: 176 [3500/8892 (39%)]\t training loss: 27.1\n",
            "epoch: 176 [4000/8892 (45%)]\t training loss: 29.0\n",
            "epoch: 176 [4500/8892 (51%)]\t training loss: 20.4\n",
            "epoch: 176 [5000/8892 (56%)]\t training loss: 23.2\n",
            "epoch: 176 [5500/8892 (62%)]\t training loss: 23.0\n",
            "epoch: 176 [6000/8892 (67%)]\t training loss: 38.2\n",
            "epoch: 176 [6500/8892 (73%)]\t training loss: 22.7\n",
            "epoch: 176 [7000/8892 (79%)]\t training loss: 22.4\n",
            "epoch: 176 [7500/8892 (84%)]\t training loss: 17.3\n",
            "epoch: 176 [8000/8892 (90%)]\t training loss: 21.4\n",
            "epoch: 176 [8500/8892 (96%)]\t training loss: 20.2\n",
            "\n",
            "Test dataset: Overall Loss: 1039.1,  (1.05%)\n",
            "\n",
            "epoch: 177 [0/8892 (0%)]\t training loss: 19.9\n",
            "epoch: 177 [500/8892 (6%)]\t training loss: 23.3\n",
            "epoch: 177 [1000/8892 (11%)]\t training loss: 32.0\n",
            "epoch: 177 [1500/8892 (17%)]\t training loss: 19.5\n",
            "epoch: 177 [2000/8892 (22%)]\t training loss: 23.5\n",
            "epoch: 177 [2500/8892 (28%)]\t training loss: 25.5\n",
            "epoch: 177 [3000/8892 (34%)]\t training loss: 18.9\n",
            "epoch: 177 [3500/8892 (39%)]\t training loss: 19.6\n",
            "epoch: 177 [4000/8892 (45%)]\t training loss: 26.3\n",
            "epoch: 177 [4500/8892 (51%)]\t training loss: 21.9\n",
            "epoch: 177 [5000/8892 (56%)]\t training loss: 27.8\n",
            "epoch: 177 [5500/8892 (62%)]\t training loss: 26.1\n",
            "epoch: 177 [6000/8892 (67%)]\t training loss: 30.4\n",
            "epoch: 177 [6500/8892 (73%)]\t training loss: 24.6\n",
            "epoch: 177 [7000/8892 (79%)]\t training loss: 26.0\n",
            "epoch: 177 [7500/8892 (84%)]\t training loss: 28.7\n",
            "epoch: 177 [8000/8892 (90%)]\t training loss: 19.0\n",
            "epoch: 177 [8500/8892 (96%)]\t training loss: 29.2\n",
            "\n",
            "Test dataset: Overall Loss: 1026.7,  (1.04%)\n",
            "\n",
            "epoch: 178 [0/8892 (0%)]\t training loss: 27.9\n",
            "epoch: 178 [500/8892 (6%)]\t training loss: 20.4\n",
            "epoch: 178 [1000/8892 (11%)]\t training loss: 22.2\n",
            "epoch: 178 [1500/8892 (17%)]\t training loss: 18.1\n",
            "epoch: 178 [2000/8892 (22%)]\t training loss: 28.4\n",
            "epoch: 178 [2500/8892 (28%)]\t training loss: 26.8\n",
            "epoch: 178 [3000/8892 (34%)]\t training loss: 21.2\n",
            "epoch: 178 [3500/8892 (39%)]\t training loss: 20.3\n",
            "epoch: 178 [4000/8892 (45%)]\t training loss: 23.8\n",
            "epoch: 178 [4500/8892 (51%)]\t training loss: 28.6\n",
            "epoch: 178 [5000/8892 (56%)]\t training loss: 26.1\n",
            "epoch: 178 [5500/8892 (62%)]\t training loss: 21.0\n",
            "epoch: 178 [6000/8892 (67%)]\t training loss: 20.5\n",
            "epoch: 178 [6500/8892 (73%)]\t training loss: 25.4\n",
            "epoch: 178 [7000/8892 (79%)]\t training loss: 26.7\n",
            "epoch: 178 [7500/8892 (84%)]\t training loss: 23.3\n",
            "epoch: 178 [8000/8892 (90%)]\t training loss: 27.5\n",
            "epoch: 178 [8500/8892 (96%)]\t training loss: 22.4\n",
            "\n",
            "Test dataset: Overall Loss: 1032.5,  (1.05%)\n",
            "\n",
            "epoch: 179 [0/8892 (0%)]\t training loss: 32.1\n",
            "epoch: 179 [500/8892 (6%)]\t training loss: 20.2\n",
            "epoch: 179 [1000/8892 (11%)]\t training loss: 27.2\n",
            "epoch: 179 [1500/8892 (17%)]\t training loss: 28.7\n",
            "epoch: 179 [2000/8892 (22%)]\t training loss: 25.8\n",
            "epoch: 179 [2500/8892 (28%)]\t training loss: 21.2\n",
            "epoch: 179 [3000/8892 (34%)]\t training loss: 26.0\n",
            "epoch: 179 [3500/8892 (39%)]\t training loss: 25.4\n",
            "epoch: 179 [4000/8892 (45%)]\t training loss: 19.8\n",
            "epoch: 179 [4500/8892 (51%)]\t training loss: 30.4\n",
            "epoch: 179 [5000/8892 (56%)]\t training loss: 26.6\n",
            "epoch: 179 [5500/8892 (62%)]\t training loss: 27.0\n",
            "epoch: 179 [6000/8892 (67%)]\t training loss: 25.1\n",
            "epoch: 179 [6500/8892 (73%)]\t training loss: 23.6\n",
            "epoch: 179 [7000/8892 (79%)]\t training loss: 24.4\n",
            "epoch: 179 [7500/8892 (84%)]\t training loss: 21.6\n",
            "epoch: 179 [8000/8892 (90%)]\t training loss: 26.6\n",
            "epoch: 179 [8500/8892 (96%)]\t training loss: 19.8\n",
            "\n",
            "Test dataset: Overall Loss: 1028.6,  (1.04%)\n",
            "\n",
            "epoch: 180 [0/8892 (0%)]\t training loss: 23.8\n",
            "epoch: 180 [500/8892 (6%)]\t training loss: 21.8\n",
            "epoch: 180 [1000/8892 (11%)]\t training loss: 25.3\n",
            "epoch: 180 [1500/8892 (17%)]\t training loss: 20.0\n",
            "epoch: 180 [2000/8892 (22%)]\t training loss: 19.8\n",
            "epoch: 180 [2500/8892 (28%)]\t training loss: 20.5\n",
            "epoch: 180 [3000/8892 (34%)]\t training loss: 18.3\n",
            "epoch: 180 [3500/8892 (39%)]\t training loss: 20.7\n",
            "epoch: 180 [4000/8892 (45%)]\t training loss: 27.1\n",
            "epoch: 180 [4500/8892 (51%)]\t training loss: 23.0\n",
            "epoch: 180 [5000/8892 (56%)]\t training loss: 21.3\n",
            "epoch: 180 [5500/8892 (62%)]\t training loss: 21.9\n",
            "epoch: 180 [6000/8892 (67%)]\t training loss: 24.9\n",
            "epoch: 180 [6500/8892 (73%)]\t training loss: 21.5\n",
            "epoch: 180 [7000/8892 (79%)]\t training loss: 25.5\n",
            "epoch: 180 [7500/8892 (84%)]\t training loss: 32.9\n",
            "epoch: 180 [8000/8892 (90%)]\t training loss: 21.1\n",
            "epoch: 180 [8500/8892 (96%)]\t training loss: 25.7\n",
            "\n",
            "Test dataset: Overall Loss: 1028.2,  (1.04%)\n",
            "\n",
            "epoch: 181 [0/8892 (0%)]\t training loss: 19.5\n",
            "epoch: 181 [500/8892 (6%)]\t training loss: 22.7\n",
            "epoch: 181 [1000/8892 (11%)]\t training loss: 22.6\n",
            "epoch: 181 [1500/8892 (17%)]\t training loss: 18.9\n",
            "epoch: 181 [2000/8892 (22%)]\t training loss: 27.4\n",
            "epoch: 181 [2500/8892 (28%)]\t training loss: 25.2\n",
            "epoch: 181 [3000/8892 (34%)]\t training loss: 24.6\n",
            "epoch: 181 [3500/8892 (39%)]\t training loss: 19.2\n",
            "epoch: 181 [4000/8892 (45%)]\t training loss: 30.7\n",
            "epoch: 181 [4500/8892 (51%)]\t training loss: 20.3\n",
            "epoch: 181 [5000/8892 (56%)]\t training loss: 23.0\n",
            "epoch: 181 [5500/8892 (62%)]\t training loss: 21.8\n",
            "epoch: 181 [6000/8892 (67%)]\t training loss: 21.0\n",
            "epoch: 181 [6500/8892 (73%)]\t training loss: 27.6\n",
            "epoch: 181 [7000/8892 (79%)]\t training loss: 22.9\n",
            "epoch: 181 [7500/8892 (84%)]\t training loss: 21.3\n",
            "epoch: 181 [8000/8892 (90%)]\t training loss: 19.3\n",
            "epoch: 181 [8500/8892 (96%)]\t training loss: 23.3\n",
            "\n",
            "Test dataset: Overall Loss: 1037.8,  (1.05%)\n",
            "\n",
            "epoch: 182 [0/8892 (0%)]\t training loss: 22.1\n",
            "epoch: 182 [500/8892 (6%)]\t training loss: 29.8\n",
            "epoch: 182 [1000/8892 (11%)]\t training loss: 20.0\n",
            "epoch: 182 [1500/8892 (17%)]\t training loss: 26.6\n",
            "epoch: 182 [2000/8892 (22%)]\t training loss: 22.1\n",
            "epoch: 182 [2500/8892 (28%)]\t training loss: 23.6\n",
            "epoch: 182 [3000/8892 (34%)]\t training loss: 23.4\n",
            "epoch: 182 [3500/8892 (39%)]\t training loss: 24.6\n",
            "epoch: 182 [4000/8892 (45%)]\t training loss: 21.5\n",
            "epoch: 182 [4500/8892 (51%)]\t training loss: 19.9\n",
            "epoch: 182 [5000/8892 (56%)]\t training loss: 23.3\n",
            "epoch: 182 [5500/8892 (62%)]\t training loss: 18.1\n",
            "epoch: 182 [6000/8892 (67%)]\t training loss: 28.1\n",
            "epoch: 182 [6500/8892 (73%)]\t training loss: 24.3\n",
            "epoch: 182 [7000/8892 (79%)]\t training loss: 23.0\n",
            "epoch: 182 [7500/8892 (84%)]\t training loss: 27.3\n",
            "epoch: 182 [8000/8892 (90%)]\t training loss: 21.5\n",
            "epoch: 182 [8500/8892 (96%)]\t training loss: 23.8\n",
            "\n",
            "Test dataset: Overall Loss: 1030.7,  (1.04%)\n",
            "\n",
            "epoch: 183 [0/8892 (0%)]\t training loss: 21.8\n",
            "epoch: 183 [500/8892 (6%)]\t training loss: 19.2\n",
            "epoch: 183 [1000/8892 (11%)]\t training loss: 22.1\n",
            "epoch: 183 [1500/8892 (17%)]\t training loss: 25.4\n",
            "epoch: 183 [2000/8892 (22%)]\t training loss: 19.4\n",
            "epoch: 183 [2500/8892 (28%)]\t training loss: 25.7\n",
            "epoch: 183 [3000/8892 (34%)]\t training loss: 16.7\n",
            "epoch: 183 [3500/8892 (39%)]\t training loss: 18.5\n",
            "epoch: 183 [4000/8892 (45%)]\t training loss: 22.5\n",
            "epoch: 183 [4500/8892 (51%)]\t training loss: 24.8\n",
            "epoch: 183 [5000/8892 (56%)]\t training loss: 21.5\n",
            "epoch: 183 [5500/8892 (62%)]\t training loss: 22.2\n",
            "epoch: 183 [6000/8892 (67%)]\t training loss: 24.9\n",
            "epoch: 183 [6500/8892 (73%)]\t training loss: 18.8\n",
            "epoch: 183 [7000/8892 (79%)]\t training loss: 19.7\n",
            "epoch: 183 [7500/8892 (84%)]\t training loss: 22.9\n",
            "epoch: 183 [8000/8892 (90%)]\t training loss: 25.5\n",
            "epoch: 183 [8500/8892 (96%)]\t training loss: 27.9\n",
            "\n",
            "Test dataset: Overall Loss: 1030.3,  (1.04%)\n",
            "\n",
            "epoch: 184 [0/8892 (0%)]\t training loss: 23.2\n",
            "epoch: 184 [500/8892 (6%)]\t training loss: 24.7\n",
            "epoch: 184 [1000/8892 (11%)]\t training loss: 19.8\n",
            "epoch: 184 [1500/8892 (17%)]\t training loss: 25.6\n",
            "epoch: 184 [2000/8892 (22%)]\t training loss: 17.5\n",
            "epoch: 184 [2500/8892 (28%)]\t training loss: 22.6\n",
            "epoch: 184 [3000/8892 (34%)]\t training loss: 20.6\n",
            "epoch: 184 [3500/8892 (39%)]\t training loss: 27.0\n",
            "epoch: 184 [4000/8892 (45%)]\t training loss: 19.6\n",
            "epoch: 184 [4500/8892 (51%)]\t training loss: 24.8\n",
            "epoch: 184 [5000/8892 (56%)]\t training loss: 27.5\n",
            "epoch: 184 [5500/8892 (62%)]\t training loss: 30.3\n",
            "epoch: 184 [6000/8892 (67%)]\t training loss: 29.0\n",
            "epoch: 184 [6500/8892 (73%)]\t training loss: 21.0\n",
            "epoch: 184 [7000/8892 (79%)]\t training loss: 22.7\n",
            "epoch: 184 [7500/8892 (84%)]\t training loss: 26.0\n",
            "epoch: 184 [8000/8892 (90%)]\t training loss: 19.7\n",
            "epoch: 184 [8500/8892 (96%)]\t training loss: 24.2\n",
            "\n",
            "Test dataset: Overall Loss: 1039.0,  (1.05%)\n",
            "\n",
            "epoch: 185 [0/8892 (0%)]\t training loss: 16.9\n",
            "epoch: 185 [500/8892 (6%)]\t training loss: 26.2\n",
            "epoch: 185 [1000/8892 (11%)]\t training loss: 23.0\n",
            "epoch: 185 [1500/8892 (17%)]\t training loss: 23.7\n",
            "epoch: 185 [2000/8892 (22%)]\t training loss: 21.6\n",
            "epoch: 185 [2500/8892 (28%)]\t training loss: 21.1\n",
            "epoch: 185 [3000/8892 (34%)]\t training loss: 29.2\n",
            "epoch: 185 [3500/8892 (39%)]\t training loss: 25.8\n",
            "epoch: 185 [4000/8892 (45%)]\t training loss: 19.3\n",
            "epoch: 185 [4500/8892 (51%)]\t training loss: 25.8\n",
            "epoch: 185 [5000/8892 (56%)]\t training loss: 24.9\n",
            "epoch: 185 [5500/8892 (62%)]\t training loss: 24.4\n",
            "epoch: 185 [6000/8892 (67%)]\t training loss: 29.5\n",
            "epoch: 185 [6500/8892 (73%)]\t training loss: 21.2\n",
            "epoch: 185 [7000/8892 (79%)]\t training loss: 21.1\n",
            "epoch: 185 [7500/8892 (84%)]\t training loss: 22.2\n",
            "epoch: 185 [8000/8892 (90%)]\t training loss: 26.4\n",
            "epoch: 185 [8500/8892 (96%)]\t training loss: 19.4\n",
            "\n",
            "Test dataset: Overall Loss: 1028.8,  (1.04%)\n",
            "\n",
            "epoch: 186 [0/8892 (0%)]\t training loss: 22.0\n",
            "epoch: 186 [500/8892 (6%)]\t training loss: 27.1\n",
            "epoch: 186 [1000/8892 (11%)]\t training loss: 32.2\n",
            "epoch: 186 [1500/8892 (17%)]\t training loss: 24.4\n",
            "epoch: 186 [2000/8892 (22%)]\t training loss: 20.1\n",
            "epoch: 186 [2500/8892 (28%)]\t training loss: 19.0\n",
            "epoch: 186 [3000/8892 (34%)]\t training loss: 26.7\n",
            "epoch: 186 [3500/8892 (39%)]\t training loss: 17.4\n",
            "epoch: 186 [4000/8892 (45%)]\t training loss: 23.7\n",
            "epoch: 186 [4500/8892 (51%)]\t training loss: 29.4\n",
            "epoch: 186 [5000/8892 (56%)]\t training loss: 17.3\n",
            "epoch: 186 [5500/8892 (62%)]\t training loss: 26.0\n",
            "epoch: 186 [6000/8892 (67%)]\t training loss: 29.3\n",
            "epoch: 186 [6500/8892 (73%)]\t training loss: 29.8\n",
            "epoch: 186 [7000/8892 (79%)]\t training loss: 27.2\n",
            "epoch: 186 [7500/8892 (84%)]\t training loss: 27.9\n",
            "epoch: 186 [8000/8892 (90%)]\t training loss: 27.4\n",
            "epoch: 186 [8500/8892 (96%)]\t training loss: 21.4\n",
            "\n",
            "Test dataset: Overall Loss: 1037.2,  (1.05%)\n",
            "\n",
            "epoch: 187 [0/8892 (0%)]\t training loss: 22.3\n",
            "epoch: 187 [500/8892 (6%)]\t training loss: 20.3\n",
            "epoch: 187 [1000/8892 (11%)]\t training loss: 21.7\n",
            "epoch: 187 [1500/8892 (17%)]\t training loss: 24.6\n",
            "epoch: 187 [2000/8892 (22%)]\t training loss: 28.6\n",
            "epoch: 187 [2500/8892 (28%)]\t training loss: 20.0\n",
            "epoch: 187 [3000/8892 (34%)]\t training loss: 23.4\n",
            "epoch: 187 [3500/8892 (39%)]\t training loss: 18.9\n",
            "epoch: 187 [4000/8892 (45%)]\t training loss: 28.9\n",
            "epoch: 187 [4500/8892 (51%)]\t training loss: 46.7\n",
            "epoch: 187 [5000/8892 (56%)]\t training loss: 22.5\n",
            "epoch: 187 [5500/8892 (62%)]\t training loss: 32.0\n",
            "epoch: 187 [6000/8892 (67%)]\t training loss: 19.5\n",
            "epoch: 187 [6500/8892 (73%)]\t training loss: 24.3\n",
            "epoch: 187 [7000/8892 (79%)]\t training loss: 23.8\n",
            "epoch: 187 [7500/8892 (84%)]\t training loss: 23.6\n",
            "epoch: 187 [8000/8892 (90%)]\t training loss: 21.7\n",
            "epoch: 187 [8500/8892 (96%)]\t training loss: 32.3\n",
            "\n",
            "Test dataset: Overall Loss: 1043.5,  (1.06%)\n",
            "\n",
            "epoch: 188 [0/8892 (0%)]\t training loss: 22.7\n",
            "epoch: 188 [500/8892 (6%)]\t training loss: 27.1\n",
            "epoch: 188 [1000/8892 (11%)]\t training loss: 19.0\n",
            "epoch: 188 [1500/8892 (17%)]\t training loss: 20.1\n",
            "epoch: 188 [2000/8892 (22%)]\t training loss: 25.8\n",
            "epoch: 188 [2500/8892 (28%)]\t training loss: 22.8\n",
            "epoch: 188 [3000/8892 (34%)]\t training loss: 20.3\n",
            "epoch: 188 [3500/8892 (39%)]\t training loss: 22.3\n",
            "epoch: 188 [4000/8892 (45%)]\t training loss: 19.1\n",
            "epoch: 188 [4500/8892 (51%)]\t training loss: 20.0\n",
            "epoch: 188 [5000/8892 (56%)]\t training loss: 26.2\n",
            "epoch: 188 [5500/8892 (62%)]\t training loss: 23.2\n",
            "epoch: 188 [6000/8892 (67%)]\t training loss: 23.6\n",
            "epoch: 188 [6500/8892 (73%)]\t training loss: 22.7\n",
            "epoch: 188 [7000/8892 (79%)]\t training loss: 23.9\n",
            "epoch: 188 [7500/8892 (84%)]\t training loss: 21.4\n",
            "epoch: 188 [8000/8892 (90%)]\t training loss: 26.3\n",
            "epoch: 188 [8500/8892 (96%)]\t training loss: 26.8\n",
            "\n",
            "Test dataset: Overall Loss: 1028.5,  (1.04%)\n",
            "\n",
            "epoch: 189 [0/8892 (0%)]\t training loss: 22.5\n",
            "epoch: 189 [500/8892 (6%)]\t training loss: 24.8\n",
            "epoch: 189 [1000/8892 (11%)]\t training loss: 21.4\n",
            "epoch: 189 [1500/8892 (17%)]\t training loss: 23.0\n",
            "epoch: 189 [2000/8892 (22%)]\t training loss: 25.8\n",
            "epoch: 189 [2500/8892 (28%)]\t training loss: 28.8\n",
            "epoch: 189 [3000/8892 (34%)]\t training loss: 24.1\n",
            "epoch: 189 [3500/8892 (39%)]\t training loss: 14.3\n",
            "epoch: 189 [4000/8892 (45%)]\t training loss: 26.0\n",
            "epoch: 189 [4500/8892 (51%)]\t training loss: 23.6\n",
            "epoch: 189 [5000/8892 (56%)]\t training loss: 25.0\n",
            "epoch: 189 [5500/8892 (62%)]\t training loss: 31.5\n",
            "epoch: 189 [6000/8892 (67%)]\t training loss: 25.3\n",
            "epoch: 189 [6500/8892 (73%)]\t training loss: 18.7\n",
            "epoch: 189 [7000/8892 (79%)]\t training loss: 27.5\n",
            "epoch: 189 [7500/8892 (84%)]\t training loss: 28.4\n",
            "epoch: 189 [8000/8892 (90%)]\t training loss: 25.9\n",
            "epoch: 189 [8500/8892 (96%)]\t training loss: 24.4\n",
            "\n",
            "Test dataset: Overall Loss: 1028.1,  (1.04%)\n",
            "\n",
            "epoch: 190 [0/8892 (0%)]\t training loss: 18.6\n",
            "epoch: 190 [500/8892 (6%)]\t training loss: 16.1\n",
            "epoch: 190 [1000/8892 (11%)]\t training loss: 22.5\n",
            "epoch: 190 [1500/8892 (17%)]\t training loss: 19.4\n",
            "epoch: 190 [2000/8892 (22%)]\t training loss: 21.9\n",
            "epoch: 190 [2500/8892 (28%)]\t training loss: 27.6\n",
            "epoch: 190 [3000/8892 (34%)]\t training loss: 21.8\n",
            "epoch: 190 [3500/8892 (39%)]\t training loss: 22.0\n",
            "epoch: 190 [4000/8892 (45%)]\t training loss: 24.9\n",
            "epoch: 190 [4500/8892 (51%)]\t training loss: 30.3\n",
            "epoch: 190 [5000/8892 (56%)]\t training loss: 21.1\n",
            "epoch: 190 [5500/8892 (62%)]\t training loss: 20.7\n",
            "epoch: 190 [6000/8892 (67%)]\t training loss: 20.6\n",
            "epoch: 190 [6500/8892 (73%)]\t training loss: 26.6\n",
            "epoch: 190 [7000/8892 (79%)]\t training loss: 23.2\n",
            "epoch: 190 [7500/8892 (84%)]\t training loss: 22.8\n",
            "epoch: 190 [8000/8892 (90%)]\t training loss: 26.0\n",
            "epoch: 190 [8500/8892 (96%)]\t training loss: 32.3\n",
            "\n",
            "Test dataset: Overall Loss: 1031.5,  (1.04%)\n",
            "\n",
            "epoch: 191 [0/8892 (0%)]\t training loss: 22.3\n",
            "epoch: 191 [500/8892 (6%)]\t training loss: 32.7\n",
            "epoch: 191 [1000/8892 (11%)]\t training loss: 29.3\n",
            "epoch: 191 [1500/8892 (17%)]\t training loss: 20.9\n",
            "epoch: 191 [2000/8892 (22%)]\t training loss: 20.9\n",
            "epoch: 191 [2500/8892 (28%)]\t training loss: 28.5\n",
            "epoch: 191 [3000/8892 (34%)]\t training loss: 23.5\n",
            "epoch: 191 [3500/8892 (39%)]\t training loss: 25.7\n",
            "epoch: 191 [4000/8892 (45%)]\t training loss: 21.3\n",
            "epoch: 191 [4500/8892 (51%)]\t training loss: 23.8\n",
            "epoch: 191 [5000/8892 (56%)]\t training loss: 21.9\n",
            "epoch: 191 [5500/8892 (62%)]\t training loss: 22.5\n",
            "epoch: 191 [6000/8892 (67%)]\t training loss: 24.1\n",
            "epoch: 191 [6500/8892 (73%)]\t training loss: 20.3\n",
            "epoch: 191 [7000/8892 (79%)]\t training loss: 23.0\n",
            "epoch: 191 [7500/8892 (84%)]\t training loss: 20.6\n",
            "epoch: 191 [8000/8892 (90%)]\t training loss: 19.1\n",
            "epoch: 191 [8500/8892 (96%)]\t training loss: 19.1\n",
            "\n",
            "Test dataset: Overall Loss: 1034.9,  (1.05%)\n",
            "\n",
            "epoch: 192 [0/8892 (0%)]\t training loss: 15.4\n",
            "epoch: 192 [500/8892 (6%)]\t training loss: 25.7\n",
            "epoch: 192 [1000/8892 (11%)]\t training loss: 27.3\n",
            "epoch: 192 [1500/8892 (17%)]\t training loss: 23.5\n",
            "epoch: 192 [2000/8892 (22%)]\t training loss: 21.8\n",
            "epoch: 192 [2500/8892 (28%)]\t training loss: 18.7\n",
            "epoch: 192 [3000/8892 (34%)]\t training loss: 23.9\n",
            "epoch: 192 [3500/8892 (39%)]\t training loss: 21.6\n",
            "epoch: 192 [4000/8892 (45%)]\t training loss: 17.6\n",
            "epoch: 192 [4500/8892 (51%)]\t training loss: 18.8\n",
            "epoch: 192 [5000/8892 (56%)]\t training loss: 25.6\n",
            "epoch: 192 [5500/8892 (62%)]\t training loss: 22.2\n",
            "epoch: 192 [6000/8892 (67%)]\t training loss: 23.8\n",
            "epoch: 192 [6500/8892 (73%)]\t training loss: 20.0\n",
            "epoch: 192 [7000/8892 (79%)]\t training loss: 30.1\n",
            "epoch: 192 [7500/8892 (84%)]\t training loss: 21.4\n",
            "epoch: 192 [8000/8892 (90%)]\t training loss: 26.0\n",
            "epoch: 192 [8500/8892 (96%)]\t training loss: 29.4\n",
            "\n",
            "Test dataset: Overall Loss: 1028.6,  (1.04%)\n",
            "\n",
            "epoch: 193 [0/8892 (0%)]\t training loss: 20.3\n",
            "epoch: 193 [500/8892 (6%)]\t training loss: 30.1\n",
            "epoch: 193 [1000/8892 (11%)]\t training loss: 23.9\n",
            "epoch: 193 [1500/8892 (17%)]\t training loss: 21.7\n",
            "epoch: 193 [2000/8892 (22%)]\t training loss: 25.6\n",
            "epoch: 193 [2500/8892 (28%)]\t training loss: 30.8\n",
            "epoch: 193 [3000/8892 (34%)]\t training loss: 23.3\n",
            "epoch: 193 [3500/8892 (39%)]\t training loss: 28.6\n",
            "epoch: 193 [4000/8892 (45%)]\t training loss: 16.2\n",
            "epoch: 193 [4500/8892 (51%)]\t training loss: 22.9\n",
            "epoch: 193 [5000/8892 (56%)]\t training loss: 22.1\n",
            "epoch: 193 [5500/8892 (62%)]\t training loss: 16.5\n",
            "epoch: 193 [6000/8892 (67%)]\t training loss: 22.7\n",
            "epoch: 193 [6500/8892 (73%)]\t training loss: 19.9\n",
            "epoch: 193 [7000/8892 (79%)]\t training loss: 18.5\n",
            "epoch: 193 [7500/8892 (84%)]\t training loss: 23.6\n",
            "epoch: 193 [8000/8892 (90%)]\t training loss: 28.8\n",
            "epoch: 193 [8500/8892 (96%)]\t training loss: 26.2\n",
            "\n",
            "Test dataset: Overall Loss: 1020.7,  (1.03%)\n",
            "\n",
            "epoch: 194 [0/8892 (0%)]\t training loss: 21.4\n",
            "epoch: 194 [500/8892 (6%)]\t training loss: 22.0\n",
            "epoch: 194 [1000/8892 (11%)]\t training loss: 22.9\n",
            "epoch: 194 [1500/8892 (17%)]\t training loss: 27.0\n",
            "epoch: 194 [2000/8892 (22%)]\t training loss: 28.5\n",
            "epoch: 194 [2500/8892 (28%)]\t training loss: 19.9\n",
            "epoch: 194 [3000/8892 (34%)]\t training loss: 21.4\n",
            "epoch: 194 [3500/8892 (39%)]\t training loss: 26.6\n",
            "epoch: 194 [4000/8892 (45%)]\t training loss: 33.2\n",
            "epoch: 194 [4500/8892 (51%)]\t training loss: 16.9\n",
            "epoch: 194 [5000/8892 (56%)]\t training loss: 22.5\n",
            "epoch: 194 [5500/8892 (62%)]\t training loss: 23.0\n",
            "epoch: 194 [6000/8892 (67%)]\t training loss: 21.0\n",
            "epoch: 194 [6500/8892 (73%)]\t training loss: 24.0\n",
            "epoch: 194 [7000/8892 (79%)]\t training loss: 23.0\n",
            "epoch: 194 [7500/8892 (84%)]\t training loss: 28.5\n",
            "epoch: 194 [8000/8892 (90%)]\t training loss: 28.0\n",
            "epoch: 194 [8500/8892 (96%)]\t training loss: 27.6\n",
            "\n",
            "Test dataset: Overall Loss: 1034.5,  (1.05%)\n",
            "\n",
            "epoch: 195 [0/8892 (0%)]\t training loss: 22.5\n",
            "epoch: 195 [500/8892 (6%)]\t training loss: 20.6\n",
            "epoch: 195 [1000/8892 (11%)]\t training loss: 27.5\n",
            "epoch: 195 [1500/8892 (17%)]\t training loss: 27.5\n",
            "epoch: 195 [2000/8892 (22%)]\t training loss: 16.0\n",
            "epoch: 195 [2500/8892 (28%)]\t training loss: 19.1\n",
            "epoch: 195 [3000/8892 (34%)]\t training loss: 22.1\n",
            "epoch: 195 [3500/8892 (39%)]\t training loss: 30.5\n",
            "epoch: 195 [4000/8892 (45%)]\t training loss: 19.1\n",
            "epoch: 195 [4500/8892 (51%)]\t training loss: 24.0\n",
            "epoch: 195 [5000/8892 (56%)]\t training loss: 26.6\n",
            "epoch: 195 [5500/8892 (62%)]\t training loss: 25.1\n",
            "epoch: 195 [6000/8892 (67%)]\t training loss: 26.1\n",
            "epoch: 195 [6500/8892 (73%)]\t training loss: 19.7\n",
            "epoch: 195 [7000/8892 (79%)]\t training loss: 21.5\n",
            "epoch: 195 [7500/8892 (84%)]\t training loss: 22.1\n",
            "epoch: 195 [8000/8892 (90%)]\t training loss: 20.4\n",
            "epoch: 195 [8500/8892 (96%)]\t training loss: 27.3\n",
            "\n",
            "Test dataset: Overall Loss: 1038.1,  (1.05%)\n",
            "\n",
            "epoch: 196 [0/8892 (0%)]\t training loss: 22.3\n",
            "epoch: 196 [500/8892 (6%)]\t training loss: 21.1\n",
            "epoch: 196 [1000/8892 (11%)]\t training loss: 18.3\n",
            "epoch: 196 [1500/8892 (17%)]\t training loss: 28.2\n",
            "epoch: 196 [2000/8892 (22%)]\t training loss: 29.0\n",
            "epoch: 196 [2500/8892 (28%)]\t training loss: 25.8\n",
            "epoch: 196 [3000/8892 (34%)]\t training loss: 23.0\n",
            "epoch: 196 [3500/8892 (39%)]\t training loss: 25.2\n",
            "epoch: 196 [4000/8892 (45%)]\t training loss: 24.0\n",
            "epoch: 196 [4500/8892 (51%)]\t training loss: 29.8\n",
            "epoch: 196 [5000/8892 (56%)]\t training loss: 21.3\n",
            "epoch: 196 [5500/8892 (62%)]\t training loss: 24.4\n",
            "epoch: 196 [6000/8892 (67%)]\t training loss: 27.4\n",
            "epoch: 196 [6500/8892 (73%)]\t training loss: 23.2\n",
            "epoch: 196 [7000/8892 (79%)]\t training loss: 29.1\n",
            "epoch: 196 [7500/8892 (84%)]\t training loss: 27.6\n",
            "epoch: 196 [8000/8892 (90%)]\t training loss: 22.3\n",
            "epoch: 196 [8500/8892 (96%)]\t training loss: 20.4\n",
            "\n",
            "Test dataset: Overall Loss: 1019.2,  (1.03%)\n",
            "\n",
            "epoch: 197 [0/8892 (0%)]\t training loss: 27.1\n",
            "epoch: 197 [500/8892 (6%)]\t training loss: 25.2\n",
            "epoch: 197 [1000/8892 (11%)]\t training loss: 27.0\n",
            "epoch: 197 [1500/8892 (17%)]\t training loss: 36.5\n",
            "epoch: 197 [2000/8892 (22%)]\t training loss: 26.7\n",
            "epoch: 197 [2500/8892 (28%)]\t training loss: 24.3\n",
            "epoch: 197 [3000/8892 (34%)]\t training loss: 18.9\n",
            "epoch: 197 [3500/8892 (39%)]\t training loss: 26.2\n",
            "epoch: 197 [4000/8892 (45%)]\t training loss: 18.9\n",
            "epoch: 197 [4500/8892 (51%)]\t training loss: 24.6\n",
            "epoch: 197 [5000/8892 (56%)]\t training loss: 21.1\n",
            "epoch: 197 [5500/8892 (62%)]\t training loss: 26.5\n",
            "epoch: 197 [6000/8892 (67%)]\t training loss: 27.5\n",
            "epoch: 197 [6500/8892 (73%)]\t training loss: 24.7\n",
            "epoch: 197 [7000/8892 (79%)]\t training loss: 22.3\n",
            "epoch: 197 [7500/8892 (84%)]\t training loss: 31.6\n",
            "epoch: 197 [8000/8892 (90%)]\t training loss: 25.5\n",
            "epoch: 197 [8500/8892 (96%)]\t training loss: 25.3\n",
            "\n",
            "Test dataset: Overall Loss: 1030.8,  (1.04%)\n",
            "\n",
            "epoch: 198 [0/8892 (0%)]\t training loss: 19.3\n",
            "epoch: 198 [500/8892 (6%)]\t training loss: 22.9\n",
            "epoch: 198 [1000/8892 (11%)]\t training loss: 25.5\n",
            "epoch: 198 [1500/8892 (17%)]\t training loss: 19.0\n",
            "epoch: 198 [2000/8892 (22%)]\t training loss: 23.0\n",
            "epoch: 198 [2500/8892 (28%)]\t training loss: 22.2\n",
            "epoch: 198 [3000/8892 (34%)]\t training loss: 28.0\n",
            "epoch: 198 [3500/8892 (39%)]\t training loss: 21.6\n",
            "epoch: 198 [4000/8892 (45%)]\t training loss: 32.9\n",
            "epoch: 198 [4500/8892 (51%)]\t training loss: 34.5\n",
            "epoch: 198 [5000/8892 (56%)]\t training loss: 17.3\n",
            "epoch: 198 [5500/8892 (62%)]\t training loss: 20.0\n",
            "epoch: 198 [6000/8892 (67%)]\t training loss: 29.6\n",
            "epoch: 198 [6500/8892 (73%)]\t training loss: 23.3\n",
            "epoch: 198 [7000/8892 (79%)]\t training loss: 22.5\n",
            "epoch: 198 [7500/8892 (84%)]\t training loss: 27.7\n",
            "epoch: 198 [8000/8892 (90%)]\t training loss: 21.5\n",
            "epoch: 198 [8500/8892 (96%)]\t training loss: 23.0\n",
            "\n",
            "Test dataset: Overall Loss: 1033.7,  (1.05%)\n",
            "\n",
            "epoch: 199 [0/8892 (0%)]\t training loss: 21.9\n",
            "epoch: 199 [500/8892 (6%)]\t training loss: 21.3\n",
            "epoch: 199 [1000/8892 (11%)]\t training loss: 23.4\n",
            "epoch: 199 [1500/8892 (17%)]\t training loss: 25.7\n",
            "epoch: 199 [2000/8892 (22%)]\t training loss: 22.7\n",
            "epoch: 199 [2500/8892 (28%)]\t training loss: 19.8\n",
            "epoch: 199 [3000/8892 (34%)]\t training loss: 21.9\n",
            "epoch: 199 [3500/8892 (39%)]\t training loss: 21.8\n",
            "epoch: 199 [4000/8892 (45%)]\t training loss: 19.2\n",
            "epoch: 199 [4500/8892 (51%)]\t training loss: 23.3\n",
            "epoch: 199 [5000/8892 (56%)]\t training loss: 27.8\n",
            "epoch: 199 [5500/8892 (62%)]\t training loss: 19.9\n",
            "epoch: 199 [6000/8892 (67%)]\t training loss: 19.4\n",
            "epoch: 199 [6500/8892 (73%)]\t training loss: 35.6\n",
            "epoch: 199 [7000/8892 (79%)]\t training loss: 23.3\n",
            "epoch: 199 [7500/8892 (84%)]\t training loss: 23.0\n",
            "epoch: 199 [8000/8892 (90%)]\t training loss: 33.4\n",
            "epoch: 199 [8500/8892 (96%)]\t training loss: 20.0\n",
            "\n",
            "Test dataset: Overall Loss: 1028.7,  (1.04%)\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "learning_rate = 0.0001 \n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "model = FCNN(input_size = data_set.input_size, hidden_size1=1000,hidden_size2=500, output_size=1) \n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate) \n",
        "\n",
        "losses_train = []\n",
        "losses_val = []\n",
        "\n",
        "for epoch in range(1, 200): \n",
        "    train_loss = train(model, device, train_loader, optimizer)\n",
        "    losses_train.append(train_loss)\n",
        "\n",
        "    val_loss = validate(model, device, val_loader, epoch)\n",
        "    losses_val.append(val_loss)\n",
        "\n",
        "plt.plot(losses_train, label ='Train losses')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Train losses')\n",
        "\n",
        "plt.plot(losses_val, label ='Validation losses')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Losses')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t-cnCtpuZkwx"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 36px;\">â€¢Model Statistics</span>  \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SGAmo1A7Zkwx"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Training</span>    \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">This code evaluates the performance of the trained model on the training dataset. First, the predict function is called to obtain the predicted probabilities (pred_prob_all) and the actual target values (target_all) for all input vectors in the train_loader. Then, several evaluation metrics are calculated using the sklearn library, including the R-squared score (r2), mean absolute error (mae), root mean squared error (rmse), and Pearson correlation coefficient (r) (Scipy libriy used).</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Finally, a scatter plot is created with the actual target values on the x-axis and the predicted values on the y-axis. The plot also includes a diagonal line representing perfect predictions and a legend with the calculated evaluation metrics. The plot shows how well the model predictions match the actual target values, with the closer the points are to the diagonal line indicating better predictions.</span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "O2Rm0kpzZkwx",
        "outputId": "42a7edec-9941-42f6-fc55-820fdddc184a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_all, target_all, pred_prob_all = predict(model, device, train_loader)\n",
        "\n",
        "r2 = r2_score(target_all, pred_prob_all)\n",
        "mae = mean_absolute_error(target_all, pred_prob_all)\n",
        "rmse = mean_squared_error(target_all, pred_prob_all, squared=False)\n",
        "r, _ = pearsonr(target_all, pred_prob_all)\n",
        "\n",
        "legend_text = \"R2 Score: {:.4f}%\\nMAE: {:.4f}\\nRMSE: {:.4f}\\nR Pearson: {:.4f}%\".format(r2*100, mae, rmse, r*100)\n",
        "\n",
        "plt.figure(figsize=(4, 4), dpi=100)\n",
        "plt.scatter(target_all, pred_prob_all, alpha=0.3)\n",
        "plt.plot([min(target_all), max(target_all)], [min(target_all),\n",
        "        max(target_all)], color=\"k\", ls=\"--\")\n",
        "plt.xlim([min(target_all), max(target_all)])\n",
        "plt.title('Training')\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.legend([legend_text], loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "YfpYAILxZkwy"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Validation</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">This code predicts the target values for the validation set using the trained model and evaluates the model's performance same as the training data set</span>    \n",
        "<span style=\"font-family: cursive; font-size: 16px;\"></span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "VzOBGdmDZkwy",
        "outputId": "40f50445-f326-49f8-bc11-e0267cb0cdc9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "input_all, target_all, pred_prob_all = predict(model, device, val_loader)\n",
        "\n",
        "r2 = r2_score(target_all, pred_prob_all)\n",
        "mae = mean_absolute_error(target_all, pred_prob_all)\n",
        "rmse = mean_squared_error(target_all, pred_prob_all, squared=False)\n",
        "r, _ = pearsonr(target_all, pred_prob_all)\n",
        "\n",
        "legend_text = \"R2 Score: {:.4f}%\\nMAE: {:.4f}\\nRMSE: {:.4f}\\nR Pearson: {:.4f}%\".format(r2*100, mae, rmse, r*100)\n",
        "\n",
        "plt.figure(figsize=(4, 4), dpi=100)\n",
        "plt.scatter(target_all, pred_prob_all, alpha=0.3)\n",
        "plt.plot([min(target_all), max(target_all)], [min(target_all),\n",
        "        max(target_all)], color=\"k\", ls=\"--\")\n",
        "plt.xlim([min(target_all), max(target_all)])\n",
        "plt.title('Validation')\n",
        "plt.xlabel(\"True Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.legend([legend_text], loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ-eEaQDZkwy"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Computing Time</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">The code was run in a destkop computer of Bilodeau Group:</span> \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">OS : Rocky Linux 8.7</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Memory : 251.5 GiB</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Proccessor : AMDÂ® Ryzen threadripper pro 5965wx 24-cores Ã— 48</span>  \n",
        "<span style=\"font-family: cursive; font-size: 16px;\">CUDA : NVIDIA GeForce RTX 3090/PCIe/SSE2</span>  \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Computing time is printed above:</span>  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OO-mb32PZkwy",
        "outputId": "a64950a4-5d26-4e8f-e0c4-3a81ffddfa10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " //// Process finished: 161.968930 seconds ////\n"
          ]
        }
      ],
      "source": [
        "finish_time = time.time()\n",
        "time = finish_time -start_time\n",
        "print(\"\\n //// Process finished: {:3f} seconds ////\".format(time))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ufk5wk1cZkwy"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 36px;\">â€¢Conclusion</span>  "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UrdilyxWZkwy"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 16px;\">Based on the results presented, can be concluded that the Daniel NN model outperformed all other models on the test set, achieving the lowest RMSE of 0.5719. This suggests that the Daniel NN model is a good approach for the prediction task. However, it is important to note that the performance of the model on the validation set was not as good as some training routine, which could indicate overfitting.</span> \n",
        "\n",
        "![Texto alternativo](benchmarks.png)\n",
        "\n",
        "\n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Further investigation and experimentation may be needed to confirm the effectiveness and generalizability of the Daniel NN model. Overall, the results indicate that deep learning approaches can provide accurate predictions for the task at hand, and further optimization and refinement of these models could lead to even better performance.</span> "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_jvuh-dwZkwy"
      },
      "source": [
        "<span style=\"font-family: cursive; font-size: 28px;\">Reference</span> \n",
        "\n",
        "<span style=\"font-family: cursive; font-size: 16px;\">Jha, A.R. (2020). Mastering PyTorch. Packt Publishing.</span> "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "beer_py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
